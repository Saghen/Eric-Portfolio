[{"title":"test","image":"placeholder.png","length":"test","previewcontent":"Test","content":"```chsarp\r\nconsole.WriteLine(\"Help me\");\r\n```","tag":"Test","id":3,"author":"Eric Dyer","dateposted":"March 12, 2018"},{"title":"test","image":"placeholder.png","length":"test","previewcontent":"Test","content":"```javascript\r\nconsole.log(\"Woah\")\r\n```","tag":"Test","id":2,"author":"Eric Dyer","dateposted":"March 12, 2018"},{"title":"test","image":"placeholder.png","length":"test","previewcontent":"Test","content":"`console.log(\"Woah\")`","tag":"Test","id":1,"author":"Eric Dyer","dateposted":"March 12, 2018"},{"title":"Future of Ecmascript and Typescript","image":"maxresdefault.jpg","length":"10 mins","previewcontent":"Since ES6 came out, they streamlined the proposal revisioning process to meet modern expectations. The new process uses a superset of HTML to format the proposals. They use GitHub pull requests, which helped boost participation from the community and the number of proposals being made also increased. The specification is now more of a living standard, meaning that proposals see adoption faster, and we don’t spend years waiting for a new edition of the specification to come out.","content":"# Stage 0\r\n\r\nAny discussion, idea, change, or addition which has not yet been submitted as a formal proposal is considered to be a “strawman” proposal at Stage 0. Only members of TC39 can create these proposals, and there’s over a dozen active strawman proposals today.\r\n\r\nProposals currently in Stage 0 include cancellation tokens for asynchronous operations, Zones as the ones originally hailed by the Angular team, along with many proposals that never made it into Stage 1.\r\n\r\nLater in this article, we’ll take a closer look at individual proposals.\r\n# Stage 1\r\n\r\nAt Stage 1 a proposal is formalized and expected to address cross-cutting concerns, interactions with other proposals, and implementation concerns. Proposals in this stage identify a discrete problem and offer a concrete solution to that problem.\r\n\r\nA Stage 1 proposal often includes a high level API description, usage examples and a discussion of internal semantics and algorithms. These proposals are likely to change significantly as they make their way through the process.\r\n\r\nExamples of proposals currently in Stage 1 include: Observable, do expressions, generator arrow functions, and Promise.try.\r\n# Stage 2\r\n\r\nProposals in Stage 2 should offer an initial draft of the specification.\r\n\r\nAt this point, it’s reasonable for implementers to begin experimenting with actual implementations in runtimes. The implementation could come in the form of a polyfill, user code that mangles the runtime into adhering to the proposal; an engine implementation, which natively provides support for the proposal; or it could be support by a build-time compiler like Babel.\r\n\r\nIn Stage 2 we currently have public class fields, private class fields, decorators, and Promise#finally, to name a few.\r\n# Stage 3\r\n\r\nProposals in Stage 3 are candidate recommendations. At this advanced stage, the specification editor and designated reviewers must have signed off on the final specification. A Stage 3 proposal is unlikely to change beyond fixes to issues identified in the wild.\r\n\r\nImplementors should have expressed interest in the proposal as well — a proposal without support from implementors is dead in the water. In practice, proposals move to this level with at least one browser implementation, a high-fidelity polyfill or when supported by a build-time transpiler like Babel.\r\n\r\nStage 3 has exciting features like object rest and spread, asynchronous iteration, the import() method, and better Unicode support for regular expressions.\r\n# Stage 4\r\n\r\nFinally, proposals get to Stage 4 when there are at least two independent implementations that pass acceptance tests.\r\n\r\nProposals that make their way through to stage four will be included in the next revision of ECMAScript.\r\n\r\nAsync functions, Array#includes, and the exponentiation operator are some examples that made it to stage 4 since the revision process was overhauled.\r\nStaying Up To Date\r\n\r\nI made a website that shows a list of currently active proposals. It describes what stage they’re in and links to each proposal so that you can learn more about them.\r\n\r\nIt lives at prop-tc39.now.sh.\r\n\r\nNew formal specification releases are now expected every year, but the streamlined process also means formal releases are becoming less relevant. The focus is now on proposal stages, and we can expect references to specific revisions of the standard to become uncommon after ES6.\r\nProposals\r\n\r\nLet’s look at some of the most interesting proposals that are currently in development.\r\nArray#includes (Stage 4)\r\n\r\nBefore Array#includes was introduced, we had to rely on Array#indexOf and checking whether the index was out of bounds to figure out whether an element belonged to an array.\r\n\r\nWith Array#includes now in stage 4, we can use that instead. It complements Array#find and Array#findIndex, which were introduced in ES6.\r\n\r\n[1, 2].indexOf(2) !== -1 // true\r\n[1, 2].indexOf(3) !== -1 // false\r\n[1, 2].includes(2) // true\r\n[1, 2].includes(3) // false\r\n\r\nAsync Functions (Stage 4)\r\n\r\nWhen working with promises, we often think in terms of execution threads where we have an async task, like fetch, and other tasks which depend on the response, but are blocked until that data is received.\r\n\r\nIn the following example we’re fetching a list of products from our API, which returns a Promise. This promise will resolve with the response to our request. We then read the response stream as JSON and update a view with data from the response. If any errors happened during this process, we could log them to the console, to understand what’s going on.\r\n\r\nfetch('/api/products')\r\n  .then(response => response.json())\r\n  .then(data => {\r\n    updateView(data)\r\n  })\r\n  .catch(err => {\r\n    console.log('Update failed', err)\r\n  })\r\n\r\nAsync functions are sugar that can be used to improve how we write Promise-based code. Let’s start transforming our promise-based code line-by-line. We can prefix any expression using the await keyword. When we await on a promise, we get an expression that evaluates to that promise’s fulfillment value.\r\n\r\nPromises gave a meaning to our code that was like “I want to run this operation, and then I want to use its result within this other operation”.\r\n\r\nMeanwhile, await effectively inverts that meaning, making it more like “I want to get back the result of this operation”, which I like, because it sounds simpler.\r\n\r\nIn our example, the response object is what we’re after, so we’ll flip things over and assign the result of await fetch to the response variable, instead of using a promise reaction.\r\n\r\n+ const response = await fetch('/api/products')\r\n- fetch('/api/products')\r\n    .then(response => response.json())\r\n    .then(data => {\r\n      updateView(data)\r\n    })\r\n    .catch(err => {\r\n      console.log('Update failed', err)\r\n    })\r\n\r\nWe give response.json() the same treatment. We await on its promise and assign that to the data variable.\r\n\r\n  const response = await fetch('/api/products')\r\n+ const data = await response.json()\r\n-   .then(response => response.json())\r\n    .then(data => {\r\n      updateView(data)\r\n    })\r\n    .catch(err => {\r\n      console.log('Update failed', err)\r\n    })\r\n\r\nNow that the reactions are gone, updateView is its own statement, since we don’t need to await on any other promises, given we’ve reached the end of our old promise chain.\r\n\r\n  const response = await fetch('/api/products')\r\n  const data = await response.json()\r\n+ updateView(data)\r\n-   .then(data => {\r\n-     updateView(data)\r\n-   })\r\n    .catch(err => {\r\n      console.log('Update failed', err)\r\n    })\r\n\r\nWe can now just use try/catch blocks instead of the .catch reaction we used in the promise-based code, leading us to more semantic code.\r\n\r\n+ try {\r\n    const response = await fetch('/api/products')\r\n    const data = await response.json()\r\n    updateView(data)\r\n+ } catch(err) {\r\n- .catch(err => {\r\n    console.log('Update failed', err)\r\n+ }\r\n- )}\r\n\r\nOne limitation is that await only works inside async functions.\r\n\r\n+ async function run() {\r\n    try {\r\n      const response = await fetch('/api/products')\r\n      const data = await response.json()\r\n      updateView(data)\r\n    } catch(err) {\r\n      console.log('Update failed', err)\r\n    }\r\n+ }\r\n\r\nWe could, however, turn our async function into a self-invoking function expression. If we wrap our top-level code in an expression like this, we can use await expressions anywhere in our codebase.\r\n\r\nSome of the community wants native top level await, while some others think it would have a negative effect in user-land, making it all too easy for libraries to block on asynchronous operations while loading, considerably slowing down the load time of our applications.\r\n\r\n+ (async () => {\r\n- async function run() {\r\n    try {\r\n      const response = await fetch('/api/products')\r\n      const data = await response.json()\r\n      updateView(data)\r\n    } catch(err) {\r\n      console.log('Update failed', err)\r\n    }\r\n+ })()\r\n- }\r\n\r\nPersonally, I think there’s more than enough room already to do silly things in the JavaScript performance space, and libraries that block initialization with await will never thrive and become popular.\r\n\r\nNote that you could also await on non-promise values, even writing code like await (2 + 3). In this case, the result of the (2 + 3) expression is boxed in a promise, and that promise’s fulfillment value, which is 5, becomes the result of the await expression.\r\n\r\nNote that await plus any JavaScript expression is also an expression. This means we aren’t limited to awaiting for values that get assigned to variables, but that we can also, for instance, await on a function call as part of a template literal interpolation.\r\n\r\n`Price: ${ await getPrice() }`\r\n\r\nOr as part of another function call…\r\n\r\nrenderView(await getPrice())\r\n\r\nOr even as part of a mathematical equation.\r\n\r\n2 * (await getPrice())\r\n\r\nFinally, regardless of their contents, async functions always return a promise. This means we can add .then or .catch reactions to an async function, and it also means we can await on its result.\r\n\r\nconst sleep = delay => new Promise(resolve =>\r\n  setTimeout(resolve, delay)\r\n)\r\nconst slowLog = async (...terms) => {\r\n  await sleep(2000)\r\n  console.log(...terms)\r\n}\r\nslowLog('Well that was underwhelming')\r\n  .then(() => console.log('Nailed it!'))\r\n  .catch(reason => console.error('Failed', reason))\r\n\r\nAs you would expect, the returned promise settles with the value returned from the async function, or is rejected with any uncaught exceptions that arised inside the async function.\r\nAsync Iteration (Stage 3)\r\n\r\nMoving onto Stage 3, we have async iteration. Before diving into it, let’s talk briefly about iterables, which were introduced in ES6. An iterable can be any object which adheres to the iterator protocol.\r\n\r\nTo make an object iterable, we define a Symbol.iterator method. The iterator method should return an object that has a next method. This object describes the sequence for our iterable. When an object is being iterated, the next method will be called each time we need to read the next element in the sequence. Each value from the returned objects is used to construct the sequence. When the returned object is marked as done, the sequence ends.\r\n\r\nconst list = {\r\n  [Symbol.iterator]() {\r\n    let i = 0\r\n    return {\r\n      next: () => ({\r\n        value: i++,\r\n        done: i > 5\r\n      })\r\n    }\r\n  }\r\n}\r\n[...list]\r\n// <- [0, 1, 2, 3, 4]\r\nArray.from(list)\r\n// <- [0, 1, 2, 3, 4]\r\nfor (const i of list) {\r\n  // <- 0, 1, 2, 3, 4\r\n}\r\n\r\nIterables can be consumed all at once with Array.from or by using the spread operator. They can also be consumed element by element using a for..of loop.\r\n\r\nAsync iterators are only a little bit different. Under this proposal, an object can use Symbol.asyncIterator to advertise that they are iterable asynchronously. The contract for an async iterator is only slightly different from that for a regular iterator: the next method needs to return a Promise for a { value, done } pair instead of returning { value, done } directly.\r\n\r\nconst list = {\r\n  [Symbol.asyncIterator]() {\r\n    let i = 0\r\n    return {\r\n      next: () => Promise.resolve({\r\n        value: i++,\r\n        done: i > 5\r\n      })\r\n    }\r\n  }\r\n}\r\n\r\nThis simple change is sufficient and elegant, since promises can easily represent the eventual elements of the sequence.\r\n\r\nAn async iterable can’t be consumed with the array spread operator, nor with Array.from, nor with for..of, since all three were exclusively purpose-built for synchronous iteration.\r\n\r\nThis proposal introduces a new for await..of construct as well. It can be used to semantically iterate over an asynchronously iterable sequence.\r\n\r\nfor await (const i of items) {\r\n  // <- 0, 1, 2, 3, 4\r\n}\r\n\r\nNote that the for await..of construct can only be used inside async functions. Otherwise we’ll get syntax errors. Just like with any other async functions, we could also use try/catch blocks around or inside our for await..of loops.\r\n\r\nasync function readItems() {\r\n  for await (const i of items) {\r\n    // <- 0, 1, 2, 3, 4\r\n  }\r\n}\r\n\r\nThe rabbit hole goes deeper of course. There’s also async generator functions. These are somewhat similar to plain generator functions, except async generator functions support async await semantics, allowing await statements as well as for await..of.\r\n\r\nasync function* getProducts(categoryUrl) {\r\n  const listReq = await fetch(categoryUrl)\r\n  const list = await listReq.json()\r\n  for (const product of list) {\r\n    const productReq = await fetch(product.url)\r\n    const product = await productReq.json()\r\n    yield product\r\n  }\r\n}\r\n\r\nInside async generator functions, we can use yield* with other async generators and with plain generators as well. When invoked, async generator functions return async generator objects, whose methods return promises for { value, done } pairs, instead of the plain { value, done } pairs returned by plain generators.\r\n\r\nFinally, an async generator object can be consumed with for await..of, just like an async iterable. This is because async generator objects are async iterables, just like plain generator objects are plain iterables.\r\n\r\nasync function readProducts() {\r\n  const g = getProducts(category)\r\n  for await (const product of g) {\r\n    // use product details\r\n  }\r\n}\r\n\r\nObject Rest and Spread (Stage 3)\r\n\r\nStarting with ES6, we can use Object.assign to copy the properties from one or more source objects onto one target object. In the next example we’re copying a few properties onto an empty object, and getting that same object back.\r\n\r\nObject.assign(\r\n {},\r\n { a: 'a' },\r\n { b: 'b' },\r\n { a: 'c' }\r\n)\r\n\r\nThe object spread proposal allows us to write equivalent code using plain syntax. We start with an empty object where Object.assign is implicitly buried in the syntax. Every object we spread onto an object literal acts as a source for assigning its own properties to that object literal.\r\n\r\n{\r\n ...{ a: 'a' },\r\n ...{ b: 'b' },\r\n ...{ a: 'c' }\r\n}\r\n// <- { a: 'c', b: 'b' }\r\n\r\nThere’s also a rest counterpart to object spread, just like with spread in arrays and rest parameters. When destructuring an object, we can use the object spread operator to destructure any own properties not explicitly named in the pattern into another object.\r\n\r\nIn the following example, the id is explicitly named and will not be included in the rest object. Object rest can be read literally as “everything else goes to an object named rest”, and of course, the variable name is for you to choose.\r\n\r\nconst item = {\r\n id: '4fe09c27',\r\n name: 'Banana',\r\n amount: 3\r\n}\r\nconst { id, ...rest } = item\r\n// <- { name: 'Banana', amount: 3 }\r\n\r\nWhen destructuring an object in a function’s parameter list, we can use object rest as well.\r\n\r\nfunction print({ id, ...rest }) {\r\n  console.log(rest)\r\n}\r\nprint({ id: '4fe09c27', name: 'Banana' })\r\n// <- { name: 'Banana' }\r\n\r\nDynamic import() (Stage 3)\r\n\r\nES6 introduced native JavaScript modules. Unlike CommonJS and similar, JavaScript modules opted for static statements. Tooling has an easier time analyzing and building dependency trees out of static source code, which makes it a great default.\r\n\r\nimport markdown from './markdown'\r\n// …\r\nexport default compile\r\n\r\nHowever, as developers we don’t always know the modules we need to import ahead of time. For these cases, such as when we depend on localization to load a module with strings under the user’s language, the dynamic import() proposal in Stage 3 comes into play.\r\n\r\nDynamic import() loads modules at runtime. It returns a promise for the module’s namespace object, which resolves after fetching, parsing, and executing the requested module and all of its dependencies. If the module fails to load, the promise will be rejected.\r\n\r\nimport(`./i18n.${ navigator.language }.js`)\r\n  .then(module => console.log(module.messages))\r\n  .catch(reason => console.error(reason))\r\n\r\nNamed Captures (Stage 3)\r\n\r\nRegular expressions are not that hard to write, but they’re many times harder to read. The expression on the next bit of code can be used to capture parts of a URL. I took the liberty of adding non-normative spaces and line breaks so that the expression isn’t as daunting to read, feel free to remove these if you want to try out the regular expression.\r\n\r\nconst urlRegExp = /\r\n  ^\r\n  (?:(http[s]?|ftp):\\/)?\r\n  \\/?\r\n  ([^:\\/\\s]+)\r\n  ((?:\\/\\w+)*\\/)\r\n  ([\\w\\-\\.]+[^#?\\s]+)\r\n  ([^#]*)?\r\n  (#[\\w\\-]+)?\r\n  $\r\n/\r\n\r\nWhich parts are captured? Well, you’ll probably have to try a few matches to figure that out. Or maybe you can put the regular expression through a tool that tells you what it does.\r\n\r\nThe named captures proposal allows us to name capture groups so that expressions become a little bit easier to read and use.\r\n\r\nIn the following piece, the highlighted parts are the names I gave to each interesting capture group in the expression. Note I had to turn on the Unicode flag /u in order to use named captures.\r\n\r\nconst urlRegExp = /\r\n  ^\r\n  (?:(?<protocol>http[s]?|ftp):\\/)?\r\n  \\/?\r\n  (?<host>[^:\\/\\s]+)\r\n  (?<path>(?:\\/\\w+)*\\/)\r\n  (?<file>[\\w\\-\\.]+[^#?\\s]+)\r\n  (?<query>[^#]*)?\r\n  (?<hash>#[\\w\\-]+)?\r\n  $\r\n/u\r\n\r\nReading the expression is a little better now that the important groups have names.\r\n\r\nWhen matching against a regular expression, the resulting array will now also contain a groups property with key/value pairs matching each of the groups named in the regular expression.\r\n\r\nconst url = 'https://commits.com/8b48e3/diff?w=1#readme'\r\nconst { groups } = urlRegExp.exec(url)\r\n\r\nThe snippet shown above produces the following object:\r\n\r\n{\r\n  protocol: 'https',\r\n  host: 'commits.com',\r\n  path: '/8b48e3/',\r\n  file: 'diff',\r\n  query: '?w=1',\r\n  hash: '#readme'\r\n}\r\n\r\nWhen doing String#replace, we can use named capture groups instead of numbered capture groups, making our code easier to follow than if we used indices. Our code is now less brittle too, because new capturing groups might change the indices of the captures we care about, they won’t affect their names.\r\n\r\nconst url = 'https://commits.com/8b48e3/diff?w=1#readme'\r\nconst pattern = '$<protocol>://github.com/$<file>'\r\nconst replaced = url.replace(urlRegExp, pattern)\r\nconsole.log(replaced)\r\n// <- 'https://github.com/diff'\r\n\r\nNamed captures can be reused to capture the same pattern later in the same regular expression, just like we could do with numbered backreferences.\r\n\r\nconst duplicateRegExp = /^(.*)=\\1$/\r\nconst duplicateRegExp = /^(?<thing>.*)=\\k<thing>$/u\r\nduplicateRegExp.test('a=b') // <- false\r\nduplicateRegExp.test('a=a') // <- true\r\nduplicateRegExp.test('aa=a') // <- false\r\nduplicateRegExp.test('bbb=bbb') // <- true\r\n\r\nUnicode Escapes (Stage 3)\r\n\r\nThe Unicode escapes proposal adds a pattern to test whether the input has a certain Unicode property value. It can be used to match certain Unicode properties of a symbol, such as the Script that symbol belongs to.\r\n\r\nThe examples in the next piece of code show how you can use the lowercase \\p escape to test whether π is a greek symbol. The uppercase \\P escape negates the condition: in the example, it matches everything except for greek symbols.\r\n\r\n/^\\p{Script=Greek}$/u.test('π')\r\n// <- true\r\n/^\\P{Script=Greek}$/u.test('π')\r\n// <- false\r\n\r\nLookbehind Assertions (Stage 3)\r\n\r\nLookbehind assertions test whether a pattern is matched to the left of the current position. They look like the highlighted patterns in the code snippet, which test against the Yuan symbol.\r\n\r\n/\\d+/.test('¥1245') // <- true\r\n/(?<=¥)\\d+/.test('¥1245') // <- true\r\n/(?<=¥)\\d+/.test('$1245') // <- false\r\n/(?<!¥)\\d+/.test('¥1245') // <- false\r\n/(?<!¥)\\d+/.test('$1245') // <- true\r\n\r\nThe less than means this is a lookbehind expression and not a lookahead. The equals sign means this is a positive lookbehind assertion. If the pattern is matched then the regular expression will match. In the first example the Yuan is matched in the input, so the positive lookbehind assertion succeeds. In the second, the Yuan is not matched and the assertion fails.\r\n\r\nWhen the equals sign is an exclamation point instead – like in the third and fourth highlighted examples – then the assertion would be a negative lookbehind. It will match when the pattern is not matched.\r\nClass Decorators (Stage 2)\r\n\r\nDecorators are in Stage 2. They can be applied to classes or to statically defined properties of classes.\r\n\r\n@pure\r\n@decorators.elastic()\r\nclass View {\r\n  @throttle(200)\r\n  reconcile() {\r\n  }\r\n}\r\n\r\nDecorators are implemented as a function and can be used to make a property readonly or wrap a method with error-logging.\r\n\r\nHere we have a readonly decorator which simply transforms the descriptor to be nonwritable. When we decorate a property as @readonly it will become non-writable.\r\n\r\nfunction readonly({ descriptor, ...rest }) {\r\n  return {\r\n    ...rest,\r\n    descriptor: {\r\n      ...descriptor,\r\n      writable: false\r\n    }\r\n  }\r\n}\r\n\r\nPromise#finally (Stage 2)\r\n\r\nFinally, the last proposal we’ll discuss is Promise#finally. This proposal is very simple. It helps us avoid repetition when we want to run a callback after a promise settles, regardless of whether it resolved or was rejected.\r\n\r\nWe can think of Promise#finally(fn) as the equivalent of Promise#then(fn, fn), except Promise#finally does not receive any arguments.\r\n\r\n  showSpinner()\r\n  fetch(productUrl)\r\n    .then(renderProduct)\r\n+   .finally(\r\n-   .then(\r\n-     hideSpinner,\r\n      hideSpinner\r\n    )\r\n\r\nFuture of JavaScript\r\n\r\nTC39 is currently working on over 30 active proposals. What else does the future hold in store?\r\n\r\nThese days we download our packages from npm. We use webpack to manage the complexity of our applications. We use Babel to get the latest language features. We use tools like uglifyjs and rollup to optimize the size of our payloads. We use eslint and prettier to uphold code quality and a consistent coding style. We use Node.js and Electron to run our JavaScript code everywhere.\r\nTranspilation and the ECMAScript Standard\r\n\r\nAll of ES6 will soon be available in the majority of runtime engines, but thanks to Babel we’ve been using ES6 features for a long time already. Babel has long started evolving away from being just an ES6 compiler: today, you can play around with most late stage proposals thanks to Babel plugins. As browser support for ES6 becomes more prominent, we can expect Babel to stop transpiling ES6 features. By that time, we’ll already be using newer features like async functions or class decorators, that will still need transpiling.\r\n\r\nIn this sense, we can think of transpilation as a moving window where we transpile only the absolute necessary in order to maximize browser support for production. A key aspect of modern web development is evergreen browsers, which auto-update. Auto-updating browsers keep Babel thin. As browsers rush to implement the latest features, there’s less code for Babel to transpile. However, Babel still plays a key role as well, by providing easy access to proposals while they’re in development.\r\n\r\nThis simplifies the feedback loop between practising web developers and implementors, preventing proposals from being developed in a vacuum.\r\nLinting and Code Quality\r\n\r\nIn the past we had linters like JSLint and JSHint, which were a little too concerned with enforcing a coding style. ESLint arose as a solution which is entirely configurable, allowing us to control exactly which aspects of our codebase we want linted in addition to syntax errors.\r\n\r\nIn the future, we can expect more innovative tools like Prettier, which automatically formats our code to follow a certain coding style, making it consistent throughout the codebase.\r\nBundling, Bloat, and complexity\r\n\r\nBy bringing true CommonJS modules to the browser, Browserify reshaped front-end development. Webpack won over browserify by offering a wealth of features like automated code splitting and the ability to manage CSS or images, becoming not just a JavaScript bundler but the bundler for all front-end assets.\r\n\r\nThis centralization is interesting because webpack makes it easy to build bloated apps but is also uniquely positioned to combat the web of bloat. In the future, I wish webpack becomes as simple as some other tools we’ve discussed, or is replaced by a simpler tool.\r\nExperimentation\r\n\r\nLast, we have Prepack, a new tool from Facebook. It is quite unique in that it’s a full-blown JavaScript interpreter specifically aimed to reducing the amount of indirection in our code.\r\n\r\nIts goal is to reduce initialization costs by precomputing code away during the build step. For example, we might originally have the following piece of code:\r\n\r\n(function () {\r\n  function fibonacci(x) {\r\n    return x <= 1 ? x : fibonacci(x - 1) + fibonacci(x - 2)\r\n  }\r\n  global.x = fibonacci(23)\r\n})()\r\n\r\nPrepack would interpret our code using a full-blown interpreter during our build, and produce code like the following:\r\n\r\n(function () {\r\n  x = 28657\r\n})()\r\n\r\nPrepack might eventually become the gold standard, but for now it’s just an experiment.","tag":"Programming","id":0,"author":"Eric Dyer","dateposted":"March 12, 2018"}]