[
    {
        "title": "Writing a Simple Linux Kernel Module",
        "image": "https://saghen.com/uploads/linux-kernel-module.png",
        "author": "Eric Dyer",
        "length": "7 mins",
        "previewcontent": "Linux provides a powerful and expansive API for applications, but sometimes that’s not enough. Interacting with a piece of hardware or conducting operations that require accessed to privileged information in the system require a kernel module.",
        "content": "<h3>Grabbing the Golden&nbsp;Ring-0</h3><p>Linux provides a powerful and expansive API for applications, but sometimes that’s not enough. Interacting with a piece of hardware or conducting operations that require accessed to privileged information in the system require a kernel module.</p><p><br></p><p>A Linux kernel module is a piece of compiled binary code that is inserted directly into the Linux kernel, running at ring 0, the lowest and least protected ring of execution in the x86–64 processor. Code here runs completely unchecked but operates at incredible speed and has access to everything in the system.</p><h3>Not for Mere&nbsp;Mortals</h3><p>Writing a Linux kernel module is not for the faint of heart. By altering the kernel, you risk data loss and system corruption. Kernel code doesn’t have the usual safety net that regular Linux applications enjoy. If you have a fault, it will lock up the entire system.</p><p><br></p><p>To make matters worse, your issue may not become immediately apparent. Your module locking up immediately upon loading is probably the best-case scenario for failure. As you add more code to your module, you run the risk of introducing runaway loops and memory leaks. If you’re not careful, these can continue to grow as your machine continues to run. Eventually important memory structures and even buffers can be overwritten.</p><p>Traditional application development paradigms can be largely discarded. Other than loading and unloading of your module, you’ll be writing code that responds to system events rather than operates in a sequential pattern. With kernel development, you’re writing APIs, not applications themselves.</p><p>You also have no access to the standard library. While the kernel provides some functions like printk (which serves as a replacement for printf) and kmalloc (which operates in a similar fashion to malloc), you are largely left to your own devices. Additionally, when your module unloads, you are responsible for completely cleaning up after yourself. There is no garbage collection.</p><h3>Prerequisites</h3><p>Before we get started, we need to make sure we have the correct tools for the job. Most importantly, you’ll need a Linux machine. I know that comes as a complete surprise! While any Linux distribution will do, I am using Ubuntu 16.04 LTS in this example, so if you’re using a different distribution you may need to slightly adjust your installation commands.</p><p><br></p><p>Secondly, you’ll need either a separate physical machine or a virtual machine. I prefer to do my work in a virtual machine, but this is entirely up to you. I don’t suggest using your primary machine because data loss can occur when you make a mistake. I say when, not if, because you undoubtedly will lock up your machine at least a few times during the process. Your latest code changes may still be in the write buffer when the kernel panics, so it’s possible that your source files can become corrupted. Testing in a virtual machine eliminates this risk.</p><p>And finally, you’ll need to know at least some C. The C++ runtime is far too large for the kernel, so writing bare metal C is essential. For interaction with hardware, knowing some assembly might be helpful.</p><h3>Installing the Development Environment</h3><p>On Ubuntu, we need to run:</p><p><br></p><pre class=\"ql-syntax\" spellcheck=\"false\">apt-get <span class=\"hljs-keyword\">install</span> <span class=\"hljs-keyword\">build</span>-essential linux-headers-<span class=\"hljs-string\">`uname -r`</span>\n</pre><p>This will install the essential development tools and the kernel headers necessary for this example.</p><p>The examples below assume you are running as a regular user and not root, but that you have sudo privileges. Sudo is mandatory for loading kernel modules, but we want to work outside of root whenever possible.</p><h3>Getting Started</h3><p>Let’s start writing some code. Let’s prepare our environment:</p><p><br></p><pre class=\"ql-syntax\" spellcheck=\"false\">mkdir ~<span class=\"hljs-regexp\">/src/</span>lkm_example\ncd ~<span class=\"hljs-regexp\">/src/</span>lkm_example\n</pre><p>Fire up your favorite editor (in my case, this is vim) and create the file lkm_example.c with the following contents:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-meta\">#include &lt;linux/init.h&gt;</span>\n<span class=\"hljs-meta\">#include &lt;linux/module.h&gt;</span>\n<span class=\"hljs-meta\">#include &lt;linux/kernel.h&gt;</span>\nMODULE_LICENSE(“GPL”);\nMODULE_AUTHOR(“Robert W. Oliver II”);\nMODULE_DESCRIPTION(“A simple example Linux <span class=\"hljs-keyword\">module</span>.”);\nMODULE_VERSION(“<span class=\"hljs-number\">0.01</span>”);\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> __<span class=\"hljs-function\">init <span class=\"hljs-title\">lkm_example_init</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>{\n printk(KERN_INFO “Hello, World!\\n”);\n <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n}\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> __<span class=\"hljs-function\"><span class=\"hljs-built_in\">exit</span> <span class=\"hljs-title\">lkm_example_exit</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>{\n printk(KERN_INFO “Goodbye, World!\\n”);\n}\nmodule_init(lkm_example_init);\nmodule_exit(lkm_example_exit);\n</pre><p><br></p><p>Now that we’ve constructed the simplest possible module, let’s example the important parts in detail:</p><p>· The “includes” cover the required header files necessary for Linux kernel development.</p><p>· MODULE_LICENSE can be set to a variety of values depending on the license of the module. To see a full list, run:&nbsp;</p><p>&nbsp;grep “MODULE_LICENSE” -B 27 /usr/src/linux-headers-`uname -r`/include/linux/module.h</p><p>· We define both the init (loading) and exit (unloading) functions as static and returning an int.</p><p>· Note the use of printk instead of printf. Also, printk doesn’t share the same parameters as printf. For example, the KERN_INFO, which is a flag to declare what priority of logging should be set for this line, is defined without a comma. The kernel sorts this out inside the printk function to save stack memory.</p><p>· At the end of the file, we call module_init and module_exit to tell the kernel which functions are or loading and unloading functions. This gives us the freedom to name the functions whatever we like.</p><p>We can’t compile this file yet, though. We need a Makefile. This basic example will work for now. Note that make is very picky about spaces and tabs, so ensure you use tab instead of space where appropriate.</p><pre class=\"ql-syntax\" spellcheck=\"false\">obj-m += lkm_example.o\n<span class=\"hljs-section\">all:</span>\n make -C /lib/modules/<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> uname -r)</span>/build M=<span class=\"hljs-variable\">$(PWD)</span> modules\n<span class=\"hljs-section\">clean:</span>\n make -C /lib/modules/<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> uname -r)</span>/build M=<span class=\"hljs-variable\">$(PWD)</span> clean\n</pre><p><br></p><p>If we run “make”, it should compile your module successfully. The resulting file is “lkm_example.ko”. If you receive any errors, check that your quotation marks in the example source file are correct and not pasted accidentally as UTF-8 characters.</p><p>Now we can insert the module to test it. To do this, run:</p><pre class=\"ql-syntax\" spellcheck=\"false\">sudo insmod lkm_example.ko\n</pre><p>If all goes well, you won’t see a thing. The printk function doesn’t output to the console but rather the kernel log. To see that, we’ll need to run:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-attribute\">sudo</span> dmesg\n</pre><p>You should see the “Hello, World!” line prefixed by a timestamp. This means our kernel module loaded and successfully printed to the kernel log. We can also check to see if the module is still loaded:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-attribute\">lsmod</span> | grep “lkm_example”\n</pre><p>To remove the module, run:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-attribute\">sudo</span> rmmod lkm_example\n</pre><p>If you run dmesg again, you’ll see “Goodbye, World!” in the logs. You can also use lsmod again to confirm it was unloaded.</p><p>As you can see, this testing workflow is a bit tedious, so to automate this we can add:</p><pre class=\"ql-syntax\" spellcheck=\"false\">test:\n sudo dmesg -C\n sudo insmod lkm_example.ko\n sudo rmmod lkm_example.ko\n dmesg\n</pre><p>at the end of our Makefile and now run:</p><pre class=\"ql-syntax\" spellcheck=\"false\">make <span class=\"hljs-built_in\">test</span>\n</pre><p>to test our module and see the output of the kernel log without having to run separate commands.</p><p>Now we have a fully functional, yet completely trivial, kernel module!</p><h3>A Bit More Interesting</h3><p>Let’s dive a bit deeper. While kernel modules can accomplish all sorts of tasks, interacting with applications is one of their most common uses.</p><p><br></p><p>Since applications are restricted from viewing the contents of kernel space memory, applications must use an API to communicate with them. While there are technically multiple ways to accomplish this, the most common is to create a device file.</p><p>You’ve likely interacted with device files before. Commands that use /dev/zero, /dev/null, or similar are interacting with a device named “zero” and “null” that return the expected values.</p><p>In our example, we’ll return “Hello, World”. While this isn’t a particularly useful function to provide applications, it will nevertheless show the process of responding to an application via a device file.</p><p>Here’s our complete listing:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-meta\">#include &lt;linux/init.h&gt;</span>\n<span class=\"hljs-meta\">#include &lt;linux/module.h&gt;</span>\n<span class=\"hljs-meta\">#include &lt;linux/kernel.h&gt;</span>\n<span class=\"hljs-meta\">#include &lt;linux/fs.h&gt;</span>\n<span class=\"hljs-meta\">#include &lt;asm/uaccess.h&gt;</span>\nMODULE_LICENSE(“GPL”);\nMODULE_AUTHOR(“Robert W. Oliver II”);\nMODULE_DESCRIPTION(“A simple example Linux <span class=\"hljs-keyword\">module</span>.”);\nMODULE_VERSION(“<span class=\"hljs-number\">0.01</span>”);\n<span class=\"hljs-meta\">#define DEVICE_NAME “lkm_example”</span>\n<span class=\"hljs-meta\">#define EXAMPLE_MSG “Hello, World!\\n”</span>\n<span class=\"hljs-meta\">#define MSG_BUFFER_LEN 15</span>\n<span class=\"hljs-comment\">/* Prototypes for device functions */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">device_open</span><span class=\"hljs-params\">(struct inode *, struct file *)</span></span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">device_release</span><span class=\"hljs-params\">(struct inode *, struct file *)</span></span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> ssize_t <span class=\"hljs-title\">device_read</span><span class=\"hljs-params\">(struct file *, <span class=\"hljs-keyword\">char</span> *, <span class=\"hljs-keyword\">size_t</span>, <span class=\"hljs-keyword\">loff_t</span> *)</span></span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> ssize_t <span class=\"hljs-title\">device_write</span><span class=\"hljs-params\">(struct file *, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *, <span class=\"hljs-keyword\">size_t</span>, <span class=\"hljs-keyword\">loff_t</span> *)</span></span>;\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> major_num;\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> device_open_count = <span class=\"hljs-number\">0</span>;\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">char</span> msg_buffer[MSG_BUFFER_LEN];\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">char</span> *msg_ptr;\n<span class=\"hljs-comment\">/* This structure points to all of the device functions */</span>\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">file_operations</span> <span class=\"hljs-title\">file_ops</span> = {</span>\n .read = device_read,\n .write = device_write,\n .open = device_open,\n .release = device_release\n};\n<span class=\"hljs-comment\">/* When a process reads from our device, this gets called. */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> ssize_t <span class=\"hljs-title\">device_read</span><span class=\"hljs-params\">(struct file *flip, <span class=\"hljs-keyword\">char</span> *buffer, <span class=\"hljs-keyword\">size_t</span> len, <span class=\"hljs-keyword\">loff_t</span> *offset)</span> </span>{\n <span class=\"hljs-keyword\">int</span> bytes_read = <span class=\"hljs-number\">0</span>;\n <span class=\"hljs-comment\">/* If we’re at the end, loop back to the beginning */</span>\n <span class=\"hljs-keyword\">if</span> (*msg_ptr == <span class=\"hljs-number\">0</span>) {\n msg_ptr = msg_buffer;\n }\n <span class=\"hljs-comment\">/* Put data in the buffer */</span>\n <span class=\"hljs-keyword\">while</span> (len &amp;&amp; *msg_ptr) {\n <span class=\"hljs-comment\">/* Buffer is in user data, not kernel, so you can’t just reference\n * with a pointer. The function put_user handles this for us */</span>\n put_user(*(msg_ptr++), buffer++);\n len--;\n bytes_read++;\n }\n <span class=\"hljs-keyword\">return</span> bytes_read;\n}\n<span class=\"hljs-comment\">/* Called when a process tries to write to our device */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> ssize_t <span class=\"hljs-title\">device_write</span><span class=\"hljs-params\">(struct file *flip, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *buffer, <span class=\"hljs-keyword\">size_t</span> len, <span class=\"hljs-keyword\">loff_t</span> *offset)</span> </span>{\n <span class=\"hljs-comment\">/* This is a read-only device */</span>\n printk(KERN_ALERT “This operation is <span class=\"hljs-keyword\">not</span> supported.\\n”);\n <span class=\"hljs-keyword\">return</span> -EINVAL;\n}\n<span class=\"hljs-comment\">/* Called when a process opens our device */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">device_open</span><span class=\"hljs-params\">(struct inode *inode, struct file *file)</span> </span>{\n <span class=\"hljs-comment\">/* If device is open, return busy */</span>\n <span class=\"hljs-keyword\">if</span> (device_open_count) {\n <span class=\"hljs-keyword\">return</span> -EBUSY;\n }\n device_open_count++;\n try_module_get(THIS_MODULE);\n <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n}\n<span class=\"hljs-comment\">/* Called when a process closes our device */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">device_release</span><span class=\"hljs-params\">(struct inode *inode, struct file *file)</span> </span>{\n <span class=\"hljs-comment\">/* Decrement the open counter and usage count. Without this, the module would not unload. */</span>\n device_open_count--;\n module_put(THIS_MODULE);\n <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n}\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> __<span class=\"hljs-function\">init <span class=\"hljs-title\">lkm_example_init</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>{\n <span class=\"hljs-comment\">/* Fill buffer with our message */</span>\n <span class=\"hljs-built_in\">strncpy</span>(msg_buffer, EXAMPLE_MSG, MSG_BUFFER_LEN);\n <span class=\"hljs-comment\">/* Set the msg_ptr to the buffer */</span>\n msg_ptr = msg_buffer;\n <span class=\"hljs-comment\">/* Try to register character device */</span>\n major_num = register_chrdev(<span class=\"hljs-number\">0</span>, “lkm_example”, &amp;file_ops);\n <span class=\"hljs-keyword\">if</span> (major_num &lt; <span class=\"hljs-number\">0</span>) {\n printk(KERN_ALERT “Could <span class=\"hljs-keyword\">not</span> <span class=\"hljs-keyword\">register</span> device: %d\\n”, major_num);\n <span class=\"hljs-keyword\">return</span> major_num;\n } <span class=\"hljs-keyword\">else</span> {\n printk(KERN_INFO “lkm_example <span class=\"hljs-keyword\">module</span> loaded with device major number %d\\n”, major_num);\n <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n }\n}\n<span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> __<span class=\"hljs-function\"><span class=\"hljs-built_in\">exit</span> <span class=\"hljs-title\">lkm_example_exit</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>{\n <span class=\"hljs-comment\">/* Remember — we have to clean up after ourselves. Unregister the character device. */</span>\n unregister_chrdev(major_num, DEVICE_NAME);\n printk(KERN_INFO “Goodbye, World!\\n”);\n}\n<span class=\"hljs-comment\">/* Register module functions */</span>\nmodule_init(lkm_example_init);\nmodule_exit(lkm_example_exit);\n</pre><p><br></p><h3>Testing Our Enhanced&nbsp;Example</h3><p>Now that our example does something more than simply print a message upon loading and unloading, we need a less restrictive test routine. Let’s modify our Makefile to only load the module and not unload it.</p><p><br></p><pre class=\"ql-syntax\" spellcheck=\"false\">obj-m += lkm_example.o\n<span class=\"hljs-section\">all:</span>\n  make -C /lib/modules/<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> uname -r)</span>/build M=<span class=\"hljs-variable\">$(PWD)</span> modules\n<span class=\"hljs-section\">clean:</span>\n  make -C /lib/modules/<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> uname -r)</span>/build M=<span class=\"hljs-variable\">$(PWD)</span> clean\n<span class=\"hljs-section\">test:</span>\n  <span class=\"hljs-comment\"># We put a — in front of the rmmod command to tell make to ignore</span>\n  <span class=\"hljs-comment\"># an error in case the module isn’t loaded.</span>\n  -sudo rmmod lkm_example\n  <span class=\"hljs-comment\"># Clear the kernel log without echo</span>\n  sudo dmesg -C\n  <span class=\"hljs-comment\"># Insert the module</span>\n  sudo insmod lkm_example.ko\n  <span class=\"hljs-comment\"># Display the kernel log</span>\n  dmesg\n</pre><p>Now when you run “make test”, you’ll see the output of the device’s major number. In our example, this is automatically assigned by the kernel. However, you’ll need this value to create the device.</p><p>Take the value you obtain from “make test” and use it to create a device file so that we can communicate with our kernel module from user space.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-attribute\">sudo</span> mknod /dev/lkm_example c MAJOR <span class=\"hljs-number\">0</span>\n</pre><p>(in the above example, replace MAJOR with the value you obtain from “make test” or “dmesg”)</p><p>The “c” in the mknod command tells mknod that we need a character device file created.</p><p>Now we can grab content from the device:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-attribute\">cat</span> /dev/lkm_example\n</pre><p>or even via the “dd” command:</p><pre class=\"ql-syntax\" spellcheck=\"false\">dd <span class=\"hljs-keyword\">if</span>=<span class=\"hljs-regexp\">/dev/</span>lkm_example <span class=\"hljs-keyword\">of</span>=test bs=<span class=\"hljs-number\">14</span> count=<span class=\"hljs-number\">100</span>\n</pre><p>You can also access this device via applications. They don’t have to be compiled applications — even Python, Ruby, and PHP scripts can access this data.</p><p>When we’re done with the device, delete it and unload the module:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-attribute\">sudo</span> rm /dev/lkm_example\nsudo rmmod lkm_example\n</pre><h3>Conclusion</h3><p>I hope you’ve enjoyed our romp through kernel land. Though the examples I’ve provided are basic, you can use this structure to construct your own module that does very complex tasks.</p><p>Just remember that you are completely on your own in kernel land. There are no backstops or second chances for your code. If you’re quoting a project for a client, be sure to double, if not triple, the anticipated debugging time. Kernel code has to be as perfect as possible to ensure the integrity and reliability of the systems that will run it.</p>",
        "topic": "Programming",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 10
    },
    {
        "title": "WTF is The Blockchain?",
        "image": "https://saghen.com/uploads/blockchain.png",
        "author": "Eric Dyer",
        "length": "29 mins",
        "previewcontent": "Unless you’re hiding under the rock, I am sure you’d have heard of Bitcoins and Blockchain. After all, they are the trending and media’s favorite topics these days — the buzzwords of the year. Even the people who’ve never mined a cryptocurrency or understand how it works, are talking about it. I have more non-technical friends than technical ones. They have been bugging me for weeks to explain this new buzzword to them. I guess there are thousands out there who feel the same.",
        "content": "<p><strong>Unless you’re hiding under the rock,</strong>&nbsp;I am sure you’d have heard of Bitcoins and Blockchain. After all, they are the trending and media’s favorite topics these days — the buzzwords of the year. Even the people who’ve never mined a cryptocurrency or understand how it works, are talking about it. I have more non-technical friends than technical ones. They have been bugging me for weeks to explain this new buzzword to them. I guess there are thousands out there who feel the same. And when that happens, there comes a time to write something to which everyone can point the other lost souls to — that’s the purpose of this post — written in plain english that any regular internet user understands.</p><blockquote><em>By the way, I am curator of a weekly newsletter,&nbsp;</em><a href=\"https://unmade.email/\" target=\"_blank\" style=\"color: inherit;\"><em>Unmade</em></a><em>, which delivers one idea from the future to your inboxes.</em></blockquote><h3><br></h3><h3>Blockchain: why do we even need something this&nbsp;complex?</h3><blockquote><em style=\"background-color: transparent;\">“For every complex problem there is an answer that is clear, simple, and wrong.” — H. L.&nbsp;Mencken</em></blockquote><p><strong>Unlike every other post on the internet,</strong>&nbsp;instead of first defining the Blockchain, we’ll understand the problem it solves.</p><p>Imagine, Joe is your best friend. He is traveling overseas, and on the fifth day of his vacation, he calls you and says, “Dude, I need some money. I have run out of it.”</p><p>You reply, “Sending some right away,” and hung up.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*BV9t2KZxRV6_ADIsV9OybQ.png\"></p><p>You then call your account manager at your bank and tell him, “Please transfer $1000 from my account to Joe’s account.”</p><p>Your account manager replies, “Yes, sir.”</p><p>He opens up the register, checks your account balance to see if you have enough balance to transfer $1000 to Joe. Because you’re a rich man, you have plenty; thus, he makes an entry in the register like the following:</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*PJ8pYM3jjJAEEkxwOxoRdg.png\"></p><p>The Transaction Register</p><blockquote><strong><em>Note:</em></strong><em>&nbsp;We’re not talking about computers only to keep things simple.</em></blockquote><p>You call Joe and tell him, “I’ve transferred the money. Next time, you’d go to your bank, you can withdraw the $1000 that I have just transferred.”</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*nS_5WE-WmhuNioLX8ki4lA.png\"></p><p>What just happened? You and Joe both trusted the&nbsp;<em>bank</em>&nbsp;to manage your money. There was no real movement of physical bills to transfer the money. All that was needed was an entry in the register. Or more precisely, an entry in the register that neither you nor Joe controls or owns.</p><p>And that is the problem of the current systems.</p><blockquote><em>To establish trust between ourselves, we depend on individual third-parties.</em></blockquote><p>For years, we’ve depended on these middlemen to trust each other. You might ask, “what is the problem depending on them?”</p><p>The problem is that they are singular in number. If a chaos has to be injected in the society, all it requires is one person/organization to go corrupt, intentionally or unintentionally.</p><ul><li>What if that register in which the transaction was logged gets burnt in a fire?</li><li>What if, by mistake, your account manager had written $1500 instead of $1000?</li><li>What if he did that on purpose?</li></ul><blockquote><em style=\"background-color: transparent;\">For years, we have been putting all our eggs in one basket and that too in someone&nbsp;else’s.</em></blockquote><p>Could there be a system where we can still transfer money without needing the bank?</p><p>To answer this question, we’ll need to drill down further and ask ourselves a better question (after all, only better questions lead to better answers).</p><p>Think about it for a second, what does transferring money means? Just an entry in the register. The better question would then be —</p><blockquote><strong><em>Is there a way to maintain the register among ourselves instead of someone else doing it for us?</em></strong></blockquote><p>Now, that is a question worth exploring. And the answer is what you might have already guessed. The blockchain is the answer to the profound question.</p><p>It is a method to maintain that register among ourselves instead of depending on someone else to do it for us.</p><p>Are you still with me? Good. Because now, when several questions have started popping in your mind, we will learn how this distributed register works.</p><p><br></p><h3>Yes, but tell me, how does it&nbsp;work?</h3><p><strong>The requirement of this method</strong>&nbsp;is that there must be enough people who would like not to depend on a third-party. Only then this group can maintain the register on their own.</p><blockquote><em>“It might make sense just to get some Bitcoin in case it catches on. If enough people think the same way, that becomes a self-fulfilling prophecy.” — Satoshi Nakamoto in&nbsp;2009</em></blockquote><p>How many are enough?&nbsp;<em>At least three</em>. For our example, we will assume ten individuals want to give up on banks or any third-party. Upon mutual agreement, they have details of each other’s accounts all the time — without knowing the other’s identity.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*0uFEch5XGG_Gqex1wXTFWg.png\"></p><h4>1. An Empty&nbsp;Folder</h4><p>Everyone contains an empty folder with themselves to start with. As we’ll progress, all these ten individuals will keep adding pages to their currently empty folders. And this collection of pages will form the register that tracks the transactions.</p><h4>2. When A Transaction Happens</h4><p>Next, everyone in the network sits with a blank page and a pen in their hands. Everyone is ready to write any transaction that occurs within the system.</p><p>Now, if #2 wants to send $10 to #9.</p><p>To make the transaction, #2 shouts and tells everyone, “I want to transfer $10 to #9. So, everyone, please make a note of it on your pages.”</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*IJPEjo45XSbkB7nGA854FQ.png\"></p><p>Everyone checks whether #2 has enough balance to transfer $10 to #9. If she has enough balance, everyone then makes a note of the transaction on their blank pages.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*m0lFIWh2bmurf_6rPXoozw.png\"></p><p>First transaction on the&nbsp;page</p><p>The transaction is then considered to be complete.</p><h4>3. Transactions Continue Happening</h4><p>As the time passes, more people in the network feel the need to transfer money to others. Whenever they want to make a transaction, they announce it to everyone else. As soon as a person listens to the announcement, (s)he writes it on his/her page.</p><p>This exercise continues until everyone runs out of space on the current page. Assuming a page has space to record ten transactions, as soon as the tenth transaction is made, everybody runs out of the space.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*mauQPdASOcD_xIZCN_cXDA.png\"></p><p>When page gets&nbsp;filled</p><p>It’s time to put the page away in the folder and bring out a new page and repeat the process from the step 2 above.</p><h4>4. Putting Away The&nbsp;Page</h4><p>Before we put away the page in our folders, we need to&nbsp;<em>seal</em>&nbsp;it with a&nbsp;<em>unique key&nbsp;</em>that everyone in the network agrees upon. By sealing it, we will make sure that no one can make any changes to it once its copies have been put away in everyone’s folder — not today, not tomorrow and not even after a year. Once in the folder, it will always stay in the folder — sealed. Moreover, if everyone trusts the seal, everyone trusts the contents of the page. And this sealing of the page is the&nbsp;<em>crux of this method.</em></p><blockquote><strong><em>[Jargon Box]</em></strong><em>&nbsp;It is called ‘mining’ on the page to secure it, but for the simplicity of it, we’ll keep calling it ‘sealing.’</em></blockquote><blockquote><em>Earlier the third-party/middleman gave us the trust that whatever they have written in the register will never be altered. In a distributed and decentralized system like ours, this seal will provide the trust&nbsp;instead.</em></blockquote><p><br></p><h3>Interesting! How do we seal the page&nbsp;then?</h3><p>Before we learn how we can seal the page, we’ll know how the seal works, in general. And as a pre-requisite to it is learning about something that I like to call…</p><h4>The Magic&nbsp;Machine</h4><p>Imagine a machine surrounded by thick walls. If you send a box with something inside it from the left, it will spit out a box containing something else.</p><blockquote><strong><em>[Jargon Box]&nbsp;</em></strong><em>This machine is called ‘Hash Function,’ but we aren’t in a mood to be too technical. So, for today, these are ‘The Magic Machines.’</em></blockquote><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*ox9O7DmN1I1AiyNygulCrw.png\"></p><p>The Magic Machine (aka Hashing Function)</p><p>Suppose, you send the number 4 inside it from the left, we’d find that it spat out the following word on its right: ‘dcbea.’</p><p>How did it convert the number 4 to this word? No one knows. Moreover, it is an irreversible process. Given the word, ‘dcbea,’ it is impossible to tell what the machine was fed on the left. But every time you’d feed the number 4 to the machine, it will always spit out the same word, ‘dcbea.’</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*G9UsASIX8eX_3xU1_3pg-w.png\"></p><p>hash(4) ==&nbsp;dcbea</p><p>Given the word, ‘dcbea,’ it is impossible to tell what the machine was fed on the left. But every time you’d feed the number 4 to the machine, it will always spit out the same word, ‘dcbea.’</p><p>Let’s try sending in a different number. How about 26?</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*HR3OyX1P-eeiwaOalY-W5A.png\"></p><p>hash(26) ==&nbsp;94c8e</p><p>We got ‘94c8e’ this time. Interesting! So, the words can contain the numbers too.</p><p>What if I ask you the following question now:</p><blockquote><strong><em>“Can you tell me what should I send from the left side of the machine such that I get a word that starts with three leading zeroes from the right side of it? For example, 000ab or 00098 or 000fa or anything among the others.”</em></strong></blockquote><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*1p-LJxci-vdJ7JObPDcaUg.png\"></p><p>Predicting the&nbsp;input</p><p>Think about the question for a moment.</p><p>I’ve told you the machine has a property that we cannot calculate what we must send from the left after we’re given the expected output on the right. With such a machine given to us, how can we answer the question I asked?</p><p>I can think of one method. Why not try every number in the universe one by one until we get a word that starts with three leading zeroes?</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*NanhTPqi85WkwQoEpGQGHw.png\"></p><p>Try everything to calculate the&nbsp;input</p><p>Being optimistic, after several thousand attempts, we’ll end up with a number that will yield the required output on the right.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*_BOLJbfmKu8U1LNTtS_UMw.png\"></p><p>It was extremely difficult to calculate the input given the output. But at the same time, it will always be incredibly easy to verify if the predicted input yields the required output. Remember that the machine spits out the same word for a number every time.</p><p>How difficult do you think the answer is if I give you a number, say 72533, and ask you the question, “Does this number, when fed into the machine, yields a word that starts with three leading zeroes?”</p><p>All you need to do is, throw the number in the machine and see what did you get on the right side of it. That’s it.</p><p>The most important property of such machines is that — “Given an output, it is extremely difficult to calculate the input, but given the input and the output, it is pretty easy to verify if the input leads to the output.”</p><p>We’ll remember this one property of the Magic Machines (or Hash Functions) through the rest of the post:</p><blockquote><em>Given an output, it is extremely difficult to calculate the input, but given an input and output, it is pretty easy to verify if the input leads to the&nbsp;output.</em></blockquote><h4>How to use these machines to seal a&nbsp;page?</h4><p>We’ll use this magic machine to&nbsp;<em>generate a seal</em>&nbsp;for our page. Like always, we’ll start with an imaginary situation.</p><p>Imagine I give you two boxes. The first box contains the number 20893. I, then, ask you, “Can you figure out a number that when added to the number in the first box and fed to the machine will give us a word that starts with three leading zeroes?”</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*0ChKQgKuRoOoFtj_jTMx2g.png\"></p><p>This is a similar situation as we saw previously and we have learned that the only way to calculate such a number is by trying every number available in the entire universe.</p><p>After several thousand attempts, we’ll stumble upon a number, say 21191, which when added to 20893 (i.e. 21191 + 20893 = 42084) and fed to the machine, will yield a word that satisfies our requirements.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*ewcdx7L6_D1RIvbPFrMYiw.png\"></p><p>In such a case, this number, 21191 becomes the seal for the number 20893. Assume there is a page that bears the number 20893 written on it. To seal that page (i.e. no one can change the contents of it), we will put a badge labeled ‘21191’ on top of it. As soon as the sealing number (i.e. 21191) is stuck on the page, the page is sealed.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*W5XSeKP6xoAQbxmmW4-dog.png\"></p><p>The sealed&nbsp;number</p><blockquote><strong><em>[Jargon Box]</em></strong><em>&nbsp;The sealing number is called ‘Proof Of Work,’ meaning that this number is the proof that efforts had been made to calculate it. We are good with calling it ‘sealing number’ for our purposes.</em></blockquote><p>If anyone wants to verify whether the page was altered, all he would have to do is — add the contents of the page with the sealing number and feed to the magic machine. If the machine gives out a word with three leading zeroes, the contents were untouched. If the word that comes out doesn’t meet our requirements, we can throw away the page because its contents were compromised, and are of no use.</p><p>We’ll use a similar sealing mechanism to seal all our pages and eventually arrange them in our respective folders.</p><h4>Finally, sealing our&nbsp;page…</h4><p>To seal our page that contains the transactions of the network, we’ll need to figure out a number that when appended to the list of transactions and fed to the machine, we get a word that starts with three leading zeroes on the right.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*ijsTUoELxn6zFkBa7r23VA.png\"></p><blockquote><strong><em>Note:</em></strong><em>&nbsp;I have been using the phrase ‘word starting with three leading zeroes’ only as an example. It illustrates how Hashing Functions work. The real challenges are much more complicated than this.</em></blockquote><p>Once that number is calculated after spending time and electricity on the machine, the page is sealed with that number. If ever, someone tries to change the contents of the page, the sealing number will allow anyone to verify the integrity of the page.</p><p>Now that we know about sealing the page, we will go back to the time when we had finished writing the tenth transaction on the page, and we ran out of space to write more.</p><p>As soon as everyone runs out of the page to write further transactions, they indulge in calculating the sealing number for the page so that it can be tucked away in the folder. Everyone in the network does the calculation. The first one in the network to figure out the sealing number announces it to everyone else.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*oMwunuVKyqWectTecENigQ.png\"></p><p>Immediately on hearing the sealing number, everyone verifies if it yields the required output or not. If it does, everyone labels their pages with this number and put it away in their folders.</p><p><strong>But what if for someone, say #7,</strong>&nbsp;the sealing number that was announced doesn’t yield the required output? Such cases are not unusual. The possible reasons for this could be:</p><ul><li>He might have misheard the transactions that were announced in the network</li><li>He might have miswritten the transactions that were announced in the network</li><li>He might have tried to cheat or be dishonest when writing transactions, either to favor himself or someone else in the network</li></ul><p>No matter what the reason is, #7 has only one choice — to discard his page and copy it from someone else so that he too can put it in the folder. Unless he doesn’t put his page in the folder, he cannot continue writing further transactions, thus, forbidding him to be part of the network.</p><blockquote><em>Whatever sealing number the majority agrees upon, becomes the honest sealing&nbsp;number.</em></blockquote><p><strong>Then why does everyone spend resources doing the calculation when they know that someone else will calculate and announce it to them? Why not sit idle and wait for the announcement?</strong></p><p>Great question. This is where the incentives come in the picture. Everyone who is the part of the Blockchain is eligible for rewards. The first one to calculate the sealing number gets rewarded with free money for his efforts (i.e. expended CPU power and electricity).</p><p>Simply imagine, if #5 calculates the sealing number of a page, he gets rewarded with some free money, say $1, that gets minted out of thin air. In other words, the account balance of #5 gets incremented with $1 without decreasing anyone else’s account balance.</p><p>That’s how Bitcoin got into existence. It was the first currency to be transacted on a Blockchain (i.e. distributed registers). And in return, to keep the efforts going on in the network, people were awarded Bitcoins.</p><p>When enough people possess Bitcoins, they grow in value, making other people wanting Bitcoins; making Bitcoins grow in value even further; making even more people wanting Bitcoins; making them grow in value even further; and so on.</p><blockquote><em>The rewards make everyone keep working in the&nbsp;network.</em></blockquote><p>And once everyone tucks away the page in their folders, they bring out a new blank page and repeat the whole process all over again — doing it forever.</p><blockquote><strong><em>[Jargon Box]</em></strong><em>&nbsp;Think of a single page as a Block of transactions and the folder as the Chain of pages (Blocks), therefore, turning it into a Blockchain.</em></blockquote><p>And that, my friends, is how Blockchain works.</p><p><br></p><p>Except that there’s one tiny thing I didn’t tell you. Yet.</p><p>Imagine there are five pages in the folder already — all sealed with a sealing number. What if I go back to the second page and modify a transaction to favor myself? The sealing number will let anyone detect the inconsistency in the transactions, right? What if I go ahead and calculate a new sealing number too for the modified transactions and label the page with that instead?</p><p>To prevent this problem of someone going back and modifying a page (Block) as well as the sealing number, there’s a little twist to how a sealing number is calculated.</p><h3>Protecting modifications to the sealing&nbsp;numbers</h3><p><strong>Remember how I told you that</strong>&nbsp;I had given you two boxes — one containing the number 20893 and another empty for you to calculate? In reality, to calculate the sealing number in a Blockchain, instead of two boxes, there are three — two pre-filled and one to be calculated.</p><p>And when the contents of all those three boxes are added and fed to the machine, the answer that comes out from the right side must satisfy the required conditions.</p><p>We already know that one box contains the list of transactions and one box will contain the sealing number. The third box contains the output of the magic machine for the previous page.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Vz0UOPPuWYz8YNRhy0NCNQ.png\"></p><p>With this neat little trick, we have made sure that every page depends on its previous page. Therefore, if someone has to modify a historical page, he would also have to change the contents and the sealing number of all the pages after that, to keep the chain consistent.</p><p>If one individual, out of the ten we imagined in the beginning, tries to cheat and modify the contents of the Blockchain (the folder containing the pages with the list of transactions), he would have to adjust several pages and also calculate the new sealing numbers for all those pages. We know how difficult it is to calculate the sealing numbers. Therefore, one dishonest guy in the network cannot beat the nine honest guys.</p><p>What will happen is, from the page the dishonest guy tries to cheat, he would be creating another chain in the network, but that chain would never be able to catch up with the honest chain — simply because one guy’s efforts and speed cannot beat cumulative efforts and speed of nine. Hence, guaranteeing that the longest chain in a network is the honest chain.</p><blockquote><em style=\"background-color: transparent;\">Longest chain is the honest&nbsp;chain.</em></blockquote><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/1000/1*CRmIEzvK0k1fM--onASiHQ.png\"></p><p>Longest chain is the honest&nbsp;chain.</p><p>When I told you that one dishonest guy cannot beat nine honest guys, did it ring any bell in your head?</p><h3>What if, instead of one, six guys turn dishonest?</h3><p><strong>In that case, the protocol will fall</strong>&nbsp;flat on its face. And it is known as “51% Attack”. If the majority of the individuals in the network decides to turn dishonest and cheat the rest of the network, the protocol will fail its purpose.</p><p>And that’s the only vulnerable reason why Blockchains might collapse if they ever will. Know that, it is unlikely to happen but we must all know the vulnerable points of the system. It is built on the assumption that the&nbsp;<em>majority of a crowd is always honest</em>.</p><p>And that, my friends, is all there is about Blockchains. If you ever find someone feeling left behind and wondering, “WTF is the Blockchain?” you know where you can point them to. Bookmark the link.</p>",
        "topic": "Cryptocurrency",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 9
    },
    {
        "title": "One problem to explain why AI works",
        "image": "https://saghen.com/uploads/problem-ai.png",
        "author": "Eric Dyer",
        "length": "48 mins",
        "previewcontent": "Ask your resident experts, Why does AI work? Readily, they’ll explain How it works, methods emptying in a mesmerizing jargonfall of gradient descent. But why? Why will an expensive and inscrutable machine create the knowledge I need to solve my problem? A glossary of technical terms, an architectural drawing, or a binder full of credentials will do little to insulate you from the fallout if you can’t stand up and explain Why.",
        "content": "<p>Ask your resident experts,&nbsp;<em>Why does AI work?&nbsp;</em>Readily, they’ll explain&nbsp;<em>How</em>&nbsp;it works, methods emptying in a mesmerizing jargonfall of gradient descent. But why? Why will an expensive and inscrutable machine create the knowledge I need to solve my problem? A glossary of technical terms, an architectural drawing, or a binder full of credentials will do little to insulate you from the fallout if you can’t stand up and explain&nbsp;<em>Why</em>.</p><p>The purpose of AI is to create machines that create good knowledge. Just as a theory of flight is essential to the success of flying machines, a theory of knowledge is essential to AI. And a theoretical basis for understanding AI has greater reach and explanatory power than the applied or technical discussions that dominate this subject.</p><p>As we’ll discover, there’s a deep problem at the center of the AI landscape. Two opposing perspectives on the problem give a simple yet far-reaching account of why AI works, the magnitude of the achievement, and where it might be headed.</p><h3>Part 1: Induction as the prevailing theory</h3><p>Many overlook the question because it’s obvious how knowledge is created:&nbsp;<em>We learn from observation</em>. This is called inductive reasoning, or induction for short. We observe some phenomena and derive general principles to form a theory. If every raven you’ve observed is black, it’s fair to conclude that all ravens are black. Over time, more black ravens support your theory. Induction is intuitively simple, even irresistible, making it the answer that most people carry.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*qTUF98ZisN85LYB2vbHrBA.png\"></p><p>Inductive process (<a href=\"https://books.google.ca/books/about/The_Fabric_of_Reality.html?id=Z7uFxViR19oC\" target=\"_blank\" style=\"color: inherit;\">David&nbsp;Deutsch</a>)</p><p>Machine learning, the most important domain in AI, is also inductive. Our intuitions about knowledge creation and the importance of machine learning inform our working hypothesis of why AI works:&nbsp;<em>It creates knowledge in the same way we all create knowledge, using common sense induction</em>.</p><blockquote><em>“Our best theories are not only truer than common sense, they make far more sense than common sense does.” David&nbsp;Deutsch</em></blockquote><p>But can you really trust induction to create&nbsp;<em>good</em>&nbsp;knowledge? Like all great explorations, to answer that question you first need to wander around a bit to get your bearings.</p><h4>At the Center of the AI Landscape</h4><p>In 1950,&nbsp;<strong>Alan Turing</strong>&nbsp;wrote a remarkably prescient paper on AI, considering the question of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence\" target=\"_blank\" style=\"color: inherit;\">whether machines can think</a>. You’re likely familiar with it for its discussion of the Turing Test. What I find most inspiring about that paper, however, is how comprehensively and enduringly Turing outlined not only the major objections to the feasibility of AI, but also the directions along which the problems might be explored. He identified two very different directions for AI, which serve as geographic coordinates of our landscape. Running north-south is the axis of human-like behaviours, like “the normal teaching of a child”; running east-west, processes of abstract thought, like “the playing of chess.” In the pursuit of AI, Turing opined, “both approaches should be tried.”</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*B9qgEpTXqpzPCRw6nuYMhg.png\"></p><p>Alan Turing, 1930 (public&nbsp;domain)</p><p>Over the intervening decades, people explored Turing’s landscape widely. In their&nbsp;<a href=\"http://aima.cs.berkeley.edu/\" target=\"_blank\" style=\"color: inherit;\">influential textbook on AI</a>,&nbsp;<strong>Stuart Russell and Peter Norvig</strong>&nbsp;categorize these explorations based on whether the machines are thinking or acting, humanly or rationally (since rationality is an ideal that humans never achieve!). It’s reminiscent of the Buddhist parable of the blind men and an elephant, where each approach is touching only a small part of the whole thing. But in AI, as in life, there are winners and loss functions. Some explorers found abundance; others endured harsh winters.</p><p>So which approach prevailed? Across the AI landscape, where are the thriving metropolises and the deserted wastelands? The notion of&nbsp;<em>one</em>&nbsp;prevailing approach is seriously oversimplified; the AI landscape is remarkably broad and diverse. Yet, those tribes generating the most interest, investment and activity establish landmarks of influence. Here, AI is most readily understood as machines acting rationally to get stuff done. Russell and Norvig weigh the pros and cons of different approaches to AI, concluding the&nbsp;<em>rational agents</em>approach is the best of the lot. “A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.” Questions of&nbsp;<em>good knowledge</em>&nbsp;are subordinated to questions of&nbsp;<em>good behavior</em>. While rational agents made landfall relatively recently, theirs are the gilded cities in AI.</p><p>While Russell and Norvig present a principled, top-down defense of rational agents, the choice is better understood as an exploration, the dogged pursuit of a vision. They summarize the foundations of AI across philosophy, mathematics, economics, neuroscience, psychology, computer engineering, control theory and cybernetics, and linguistics. (When your pursuit takes you across that many state lines, you’re dogged!) In a&nbsp;<a href=\"https://medium.com/inventing-intelligent-machines/prediction-is-the-essence-of-intelligence-42c786c3e5a9\" target=\"_blank\" style=\"color: inherit;\">previous post</a>, I’ve traced how the bottom-up consensus emerged, “a vision of AI as an autonomous, goal-seeking system. By design, this definition of intelligence was crafted within the expectations of how this vision of AI would be realized and measured.” Goal-seeking explorers creating goal-seeking AI.</p><p><a href=\"https://medium.com/inventing-intelligent-machines/prediction-is-the-essence-of-intelligence-42c786c3e5a9\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.9);\">Why Prediction is the Essence of Intelligence</a></p><p><br></p><p><a href=\"https://medium.com/inventing-intelligent-machines/prediction-is-the-essence-of-intelligence-42c786c3e5a9\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.68);\">Is it a coincidence that machine learning and intelligence are both rooted in prediction?</a></p><p><a href=\"https://medium.com/inventing-intelligent-machines/prediction-is-the-essence-of-intelligence-42c786c3e5a9\" target=\"_blank\" style=\"color: inherit; background-color: rgba(255, 255, 255, 0);\">medium.com</a></p><p>How might the prevailing tribes answer our question,&nbsp;<em>Why does AI work?</em>&nbsp;Well, it acts so as to achieve the best outcome, of course. What’s more, it works even in harsh, uncertain environments, without the benefit of a map or foreknowledge! But like indefatigable and philosophically precocious children, we can keep asking&nbsp;<em>Why</em>? Why does an autonomous goal-seeking agent create&nbsp;<em>good</em>&nbsp;knowledge?</p><h4>Induction as the Source of Knowledge</h4><p>Many would argue a focus on knowledge creation is a fatally narrow view of AI. Russell and Norvig caution, “intelligence requires action as well as reasoning.” What of autonomy and automation, decision-making and control, utility functions and payoffs, integration and engineering? Our paths will cross again, but knowledge comes first. It’s the ground, and whether soft or firm, it dictates whether your AI is in fact intelligent. They acknowledge the primacy of sound theoretical foundations. “The quest for ‘artificial flight’ succeeded when the Wright brothers and others stopped imitating birds and started using wind tunnels and learning about aerodynamics.” I take their analogy seriously: Theory leads practice, and theories of knowledge lead AI.</p><p>Russell and Norvig refer to the source of knowledge as induction, including computational approaches for how knowledge is extracted from observations. Induction is a&nbsp;<em>principle</em>&nbsp;of science and the prevailing theory of knowledge creation. Given sufficient data, all the knowledge a system needs to exhibit autonomous, good behaviour may be acquired through learning, given sufficient high quality data. Following numerous winters of hype and disappointments, pragmatic considerations reign. A flexible and efficient acquisition of knowledge, surmounting the “knowledge bottleneck”, is the central problem.</p><p>Note how the prevailing theory is wrapped in a method.&nbsp;<strong>Shai Shalev-Shwartz and Shai Ben-David</strong>&nbsp;<a href=\"http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/\" target=\"_blank\" style=\"color: inherit;\">explain the theory of machine learning</a>&nbsp;in explicitly methodological terms. “The development of tools for expressing domain expertise, translating it into a learning bias, and quantifying the effect of such a bias on the success of learning is a central theme of the theory of machine learning.” I’ll share another example of this schema at the close of this post.&nbsp;<span style=\"background-color: transparent;\">The reduction of theory to method is an idea we’ll encounter frequently as we move across the AI landscape.</span>&nbsp;It has antecedents in the Scientific Method and inspires new computational epistemologies for automated science that we’ll meet as we move further afield.</p><h4>The Leap From Philosophy</h4><p>Our introductory tour of the AI landscape would be reprehensibly incomplete if we didn’t stop to behold one final landmark, a majestic cliff in the study of knowledge creation. Russell and Norvig explain, “Philosophers staked out some of the fundamental ideas of AI, but the leap to a formal science required a level of mathematical formalization in three fundamental areas: logic, computation, and probability.” Philosophy without formalization is all well and good until you have to code it, and so they leapt.</p><p>Yet, formalisms are embraced within analytic philosophy so this requirement in itself doesn’t explain the leap. Russell and Norvig stress their short history is necessarily incomplete, but this isn’t a symptom of brevity. Rather theirs is an accurate portrait of an historical split, as if the foundational work in AI marks a break with modern philosophy. While that’s a broad brush, it does capture the popular sentiment. The dismissal of philosophy is widespread, particularly among technical people.</p><p>The computer scientist&nbsp;<strong>Scott Aaronson</strong>&nbsp;agrees that the original purpose behind the founding work in computer science was the clarification of philosophical issues. Yet, in his discussion of the intersections of&nbsp;<a href=\"https://arxiv.org/abs/1108.1791\" target=\"_blank\" style=\"color: inherit;\">computational complexity and philosophy</a>, he emphasizes that parallel investigations in technical disciplines don’t diminish the importance of philosophy or excuse the dismissal of philosophical pursuits. “Indeed, one of my hopes for this essay is that computer scientists, mathematicians, and other technical people who read it will come away with a better appreciation for the subtlety of some of the problems considered in modern analytic philosophy.” In a&nbsp;<a href=\"https://medium.com/inventing-intelligent-machines/machine-intelligence-and-epistemology-1ff3c75fa743\" target=\"_blank\" style=\"color: inherit;\">previous post</a>, I’ve argued that there is much to be gained by remaining open to the contributions of philosophy.</p><p><a href=\"https://medium.com/inventing-intelligent-machines/machine-intelligence-and-epistemology-1ff3c75fa743\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.9);\">Your AI Superpower: 8 reasons why knowledge about knowledge is a competitive weapon</a></p><p><br></p><p><a href=\"https://medium.com/inventing-intelligent-machines/machine-intelligence-and-epistemology-1ff3c75fa743\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.68);\">There’s nothing soft about the intersection of epistemology and machine intelligence.</a></p><p><a href=\"https://medium.com/inventing-intelligent-machines/machine-intelligence-and-epistemology-1ff3c75fa743\" target=\"_blank\" style=\"color: inherit; background-color: rgba(255, 255, 255, 0);\">medium.com</a></p><p>Did the “leap to formal science” leap over competing theories of knowledge creation? One problem in particular is anything but subtle, and resides right at the center of the AI landscape. The&nbsp;<em>principle</em>&nbsp;of induction is often conflated with the uniformity principle of nature, which in turn casts induction as a principle of science. Induction, however, is better understood as a&nbsp;<em>problem</em>, where it finds its historical roots and full context. Guidance on how to manage this problem is what fills the textbooks and directs methodology. And while there is much to learn from the prevailing approach, particularly in the values of pragmatism and experimentation, AI cannot be explained until the&nbsp;<em>problem</em>of induction is understood.</p><h4>The Problem of Induction</h4><p>The problem of induction has been debated over centuries, most notably in the writings of&nbsp;<strong>David Hume</strong>. While I could never do justice to that volume of criticism, I want to give you a sense through a few examples of how these issues erode the commonsensical allure of the theory. The problem is that induction&nbsp;<em>seems</em>&nbsp;to play a central role in science and everyday life, but it also seems prone to produce&nbsp;<em>bad</em>&nbsp;knowledge. Therefore, how can induction be justified?</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*kvQASmUoxoNFlhSUalbiGQ.png\"></p><p>David Hume by Allan Ramsay, 1766 (public&nbsp;domain)</p><p>Well, let me count the ways. No, I mean seriously, just count the ways. If your theory is that all ravens are black, you can keep counting ravens until you find a white one. For good measure, we might also count all the non-black things we see that are not ravens. White shoes aren’t black ravens, so they support our theory, too! (But of course, they also support the theory that ravens are blue.) This is the raven paradox, or Hempel’s paradox, named for its originator,&nbsp;<strong>Carl Hempel</strong>. In a future post, we’ll meet some of the clever people, including Bayesians, who chiselled this paradox down to size. Here, it’s sufficient to note that counting evidence to&nbsp;<em>confirm</em>&nbsp;your theory is like preaching to the cosmic choir.</p><p>Another striking wrinkle on the problem of induction is the so-called “New Riddle of Induction,” from the influential philosopher&nbsp;<strong>Nelson Goodman</strong>. His riddle introduced these imaginary “grue” and “bleen” objects that change colour over time, highlighting the difference between lawlike and non-lawlike statements, not to mention the ambiguities of language. How do we know some phenomena can be generalized to a lawlike regularity? How do we know what we’ve observed in the past will continue in the future?</p><p>Well, belief in the uniformity of nature underpins the entire scientific effort. When people speak about the<em>&nbsp;</em>principle of induction, this is usually what they’re really saying. What, you think the sun will stop rising? However, this uniformity clearly doesn’t extend to our&nbsp;<em>observations</em>&nbsp;of nature. The philosopher and mathematician&nbsp;<strong>Bertrand Russell</strong>&nbsp;famously explained this problem through the parable of a chicken that observed the farmer bringing him food every day. From these observations, the chicken induced the theory that the farmer would continue to feed him. The chicken’s inductive theory died violently with the chicken! So too have machine learning projects that failed to see bias in their data’s free lunch.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*eeanZP2Xh5Y_n7Gyf1wjbw.png\"></p><p>Betrand Russell, 1938 (public domain) and a chicken&nbsp;(<a href=\"https://www.flickr.com/photos/eurleif/43563205\" target=\"_blank\" style=\"color: inherit;\">Flickr</a>)</p><p><strong>John Vickers</strong>&nbsp;contrasts&nbsp;<a href=\"https://plato.stanford.edu/archives/spr2018/entries/induction-problem/\" target=\"_blank\" style=\"color: inherit;\">the problem of induction</a>&nbsp;with deductive reasoning, where according to the rules of logic, the premises imply the argument’s conclusion. “Not so for induction: There is no comprehensive theory of sound induction, no set of agreed upon rules that license good or sound inductive inference, nor is there a serious prospect of such a theory.”</p><p>Now, the prevailing AI tribes would beg to differ! There are sound inductive systems, manifest in powerful and fully autonomous machines. And they truly are marvels of science and engineering. But in order to understand the magnitude of these accomplishments, you must first recognize the thorny problem that induction poses. Attempts to&nbsp;<em>manage</em>&nbsp;the problem of induction are revealed as a central challenge of AI.</p><p>That said, Vickers is right about the comprehensive part. The problem of induction takes a mathematical form in&nbsp;<strong>David Wolpert and William Macread</strong>’s&nbsp;<a href=\"http://ieeexplore.ieee.org/document/585893/\" target=\"_blank\" style=\"color: inherit;\">no free lunch theorems</a>. They explain, “if an algorithm does particularly well on average for one class of problems then it must do worse on average over the remaining problems.” In other words, there is no&nbsp;<em>universal</em>learner that works well across&nbsp;<em>all</em>&nbsp;problems. Today’s AI is an idiot savant; extraordinary adept at specific problems but generally inept. At least for now.</p><p>Respecting the depth of the problem avoids the contentious idea that induction is a principle. Nature is uniform but observations are fuzzy. The principle that future observations resemble the past is an&nbsp;<em>assumption</em>&nbsp;that inductive systems&nbsp;<em>require</em>&nbsp;to work effectively. Unfortunately, the uniformity of nature says nothing about a particular set of observations, ravens or chickens.</p><p>So how do we cope with the problem of induction? We leverage existing knowledge. Shalev-Shwartz and Ben-David explain, “We can escape the hazards foreseen by the No-Free-Lunch theorem by using our prior knowledge about a specific learning task, to avoid the distributions that will cause us to fail when learning that task.” This is the essential connection between existing knowledge and learning. To observe&nbsp;<em>intelligently</em>&nbsp;requires explanations.</p><h3>Part 2: The power of explanations</h3><p>Now that we have some perspective on the centrality and problem of induction in AI, I want to turn to an opposing&nbsp;<em>anti-inductive</em>&nbsp;theory. Science is our most successful knowledge-creating enterprise.&nbsp;<strong>Karl Popper</strong>&nbsp;is one of the most influential thinkers in the philosophy of science. Therefore, it’s important, if not central, to consider how Popper’s philosophy explains why AI works.</p><blockquote><em>“I think that I have solved a major philosophical problem: the problem of induction.” Karl&nbsp;Popper</em></blockquote><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*PE8M3pX0kf6bMSS6nbzyOA.jpeg\"></p><p>Karl Popper, 1980s (<a href=\"https://www.flickr.com/photos/lselibrary/3833724834/in/set-72157623156680255/\" target=\"_blank\" style=\"color: inherit;\">LSE&nbsp;Library</a>)</p><p>Popper’s solution to the problem of induction is that knowledge is in fact&nbsp;<em>not</em>derived from experience. While it’s true that experience and experimentation play an important role in knowledge creation, his emphasis is on problems. We create explanations and conjectures about how the world works. (Conjectures are informed guesses; the bolder the better.) Competing explanations square off in rounds of criticism and experimentation. Popper emphasized that ravens may always be found to justify a theory. Rather, criticism and experimentation should be directed to finding evidence that&nbsp;<em>refutes</em>&nbsp;the theory, a process of falsification. Although theories are never justified, they may be corroborated if they survive genuine efforts of falsification. Popper solves the problem of induction by rejecting data as the foundation of science, induction as the method, and justification and prediction as the objectives.</p><p>To clarify the central role that explanations play in knowledge creation, compare the process of induction, introduced above, to Popper’s schema of problem-solving: When a problem is identified, solutions are conjectured; these conjectures are subjected to criticism and experimental tests, in an effort to root out errors in the theorized solutions; this introduces new problems to solve. Contrary to the much-bandied Scientific Method, science is an iterative process of problem-solving, not a strict methodology. This debate in the philosophy of science finds parallels in the future of AI. As we’ve seen, methodology figures prominently in AI and fuels the aspirations of machine learning as “automated science.”</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*vVaV0IFGjdeoQE8A008Vmw.png\"></p><p>Scientific discovery process, (<a href=\"https://books.google.ca/books/about/The_Fabric_of_Reality.html?id=Z7uFxViR19oC\" target=\"_blank\" style=\"color: inherit;\">David&nbsp;Deutsch</a>)</p><h4>The Anti-Induction Debate</h4><p>Despite his influence within the philosophy of science, the implications of Popper’s theory are often ignored in computer science. One explanation for this neglect may be that the majority of&nbsp;<em>philosophers</em>&nbsp;remain unconvinced by his arguments. A common criticism is that despite Popper’s efforts to distinguish his concept of corroboration from justification, people need justification as a basis for practical action. (Remember the advice of Russell and Norvig, that AI requires action as well as reasoning.) The psychological need for justification and the intuitive validity of induction impose serious impediments to anti-inductive theories of knowledge creation.</p><p>Other aspects of Popper’s philosophy are harder to ignore. He stressed (alongside several notable philosophers) that all knowledge creation is&nbsp;<em>theory-laden</em>; observations are never free of an underlying theory or explanation. Even if you believe the process&nbsp;<em>begins</em>&nbsp;with observations, the act of&nbsp;<em>observing</em>&nbsp;requires a point of view. It may seem observational, “the man is sitting on the bench”, but what caused you to look at the man? Language itself is theory-laden. Terms refer to concepts, which in turn point to other terms, in an infinite regress. What is a bench and sitting and why do they fit together? We&nbsp;<em>make</em>&nbsp;an observation, we don’t&nbsp;<em>take</em>&nbsp;it. Ask data scientists how much time they spend deciding what to observe and what to exclude, or how difficult it is to wrangle the ambiguities of language.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*YoJrEo7EJeNxFY4H7xpANw.jpeg\"></p><p>David Deutsch (<a href=\"http://www.daviddeutsch.org.uk/about-me/\" target=\"_blank\" style=\"color: inherit;\">Lulie&nbsp;Tanett</a>)</p><p>The centrality of explanations in knowledge creation is not a contentious idea, in and of itself.&nbsp;<strong>David Deutsch,&nbsp;</strong>a staunch Popperian and pioneer of quantum computation, argues that computational theory and epistemology (along with quantum theory and evolution) comprise the&nbsp;<a href=\"https://books.google.ca/books/about/The_Fabric_of_Reality.html?id=Z7uFxViR19oC\" target=\"_blank\" style=\"color: inherit;\">Fabric of Reality</a>. Responding to Nelson’s riddle, introduced above, Deutsch frames languages as theories in the service of problem-solving. “One of the most important ways in which languages solve these problems is to embody, implicitly, theories that are uncontroversial and taken for granted, while allowing things that need to be stated or argued about to be expressed succinctly and cleanly.”&nbsp;<strong>Welsey Salmon</strong>, in his&nbsp;<a href=\"https://www.upress.pitt.edu/BookDetails.aspx?bookId=35806\" target=\"_blank\" style=\"color: inherit;\">classic book on the subject</a>, asserted, “On one fundamental issue, the consensus has remained intact. Philosophers of very diverse persuasions continue to agree that a fundamental aim of science is to provide explanations of natural phenomena.”</p><p>Deutsch cautions that explanation is frequently conflated with prediction, which erodes this consensus. Within AI, the centrality of explanations in knowledge creation is&nbsp;<em>undeniably</em>&nbsp;contentious. A common criticism of machine learning is the lack of interpretability; learners as black box oracles. This problem is an active area of research, but for many, inexplicability is a feature, not a bug, pointing the way to new explanationless methods of scientific discovery. Comparing this process of&nbsp;<a href=\"http://comparing%20this%20process%20of%20trial%20and%20error%20to%20alchemy/\" target=\"_blank\" style=\"color: inherit;\">trial and error to alchemy</a>, the computer scientist&nbsp;<strong>Ali Rahimi</strong>&nbsp;expressed anguish over “an entire field that’s become a black box.” Is this a leap to a brave new science or the regressive impact of a flawed theory of knowledge? I explored this topic at length in a&nbsp;<a href=\"https://medium.com/inventing-intelligent-machines/machine-learning-alien-knowledge-and-other-ufos-1a44c66508d1\" target=\"_blank\" style=\"color: inherit;\">previous post</a>.</p><p><a href=\"https://medium.com/inventing-intelligent-machines/machine-learning-alien-knowledge-and-other-ufos-1a44c66508d1\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.9);\">Deep Learning: Is this the end of theory or a rallying cry for deep explanations?</a></p><p><br></p><p><a href=\"https://medium.com/inventing-intelligent-machines/machine-learning-alien-knowledge-and-other-ufos-1a44c66508d1\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.68);\">Deep learning generates observations we can’t explain. A response to David Weinberger.</a></p><p><a href=\"https://medium.com/inventing-intelligent-machines/machine-learning-alien-knowledge-and-other-ufos-1a44c66508d1\" target=\"_blank\" style=\"color: inherit; background-color: rgba(255, 255, 255, 0);\">medium.com</a></p><p>However seductive, the idea of explanationless theories fails in a fairly profound way. Not only is science neatly encapsulated as the pursuit of explanations, it is made possible only through the foundations of explanations. Whether in science or everyday life, people depend on long links of explanations they cannot directly observe or elucidate in any depth. Knowledge creators, whether humans or machines, cannot avoid explanations, even if they wistfully deny them.</p><p>But there is a more valid criticism of explanations. If there are&nbsp;<em>any</em>&nbsp;functional gaps in your solution, it bars the way to fully autonomous systems. So if induction is deemed essential to any widget or gear in your machine, the problem of induction may be an acceptable compromise. The need for justification, discussed above, is one perceived gap. A major&nbsp;<em>proponent</em>&nbsp;of Popper,&nbsp;<strong>David Miller</strong>, highlights&nbsp;<a href=\"http://www.scielo.org.co/scielo.php?pid=S0124-61272014000100002&amp;script=sci_arttext&amp;tlng=en\" target=\"_blank\" style=\"color: inherit;\">some hard questions</a>&nbsp;facing Popper’s theory. “It must nonetheless be conceded that Popper’s deductivism, in contrast to some forms of inductivism, and especially in contrast to Bayesianism, has no extensively developed account of what is usually called decision making under uncertainty and risk.” Another major gap in Popper’s philosophy is in the realm of creativity and discovery, where leaps in imagination lead to startlingly new conjectures and hypotheses. This is an area that Popper viewed as psychological and inherently subjective. Popper concluded (contrary to the title of one of his best known books) there is no logic of scientific discovery.</p><p>We’ll return to these questions of prediction, decision-making, discovery and creativity in future posts, as major explorations across the AI landscape. But before the question of&nbsp;<em>Why AI works</em>&nbsp;can be answered, there is one additional aspect of explanations that needs to be considered: If explanations are key to knowledge creation, how do you know your explanations are any good?</p><h4>Criteria for Good Explanations</h4><p>Philosophers have categorized many different forms of explanation, such as the degree to which an explanation covers the observations, explanations by analogy, and explanations of purpose rather than cause. In&nbsp;<a href=\"https://books.google.ca/books/about/The_Beginning_of_Infinity.html?id=jZHanN5_KPgC\" target=\"_blank\" style=\"color: inherit;\">The Beginning of Infinity: Explanations that Transform the World</a>, Deutsch stresses the criterion of variability, “for, whenever it is easy to vary an explanation without changing its predictions, one could just as easily vary it to make different predictions if they were needed.” Deutsch contrasts myths that explain the seasons with the scientific explanation based on the Earth’s axis of rotation and orbit around the sun. The myths are easy to vary: Nordic and Greek examples incorporate widely divergent details of gods, kidnapping, retributions and wars. The myths are essentially interchangeable. The scientific explanation, on the other hand, is hard to vary since each detail of the explanation is intricately connected to the phenomena it explains. Change a detail and the scientific explanation falls apart. An explanation becomes hard to vary when all the details in the theory play a functional role.</p><p>In her book,&nbsp;<a href=\"https://books.google.com/books/about/How_the_Laws_of_Physics_Lie.html?id=lIQKFs0_s18C\" target=\"_blank\" style=\"color: inherit;\">How the Laws of Physics Lie</a>,&nbsp;<strong>Nancy Cartwright</strong>&nbsp;credits&nbsp;<strong>Bas van Fraasen</strong>&nbsp;with formulating a particularly pointed criticism of explanations. “Van Fraassen asks, what has explanatory power to do with truth? He offers more a challenge than an argument: show exactly what about the explanatory relationship tends to guarantee that if x explains y and y is true, then x should be true as well. This challenge has an answer in the case of causal explanation, but only in the case of causal explanation.” A causal explanation details the specific chain of cause and effect that leads to an outcome. Causal explanations satisfy van Fraasen’s challenge, as well as Deutsch’s hard-to-vary criterion. All the details in a causal explanation play a functional role.</p><p>Good explanations are further constrained by their need to play nice with other good explanations. They must both cover the phenomena they purport to explain, as well as demonstrate an external coherence. You might think you have a groundbreaking new theory of quantum gravity, but it had better play nice with quantum mechanics and general relativity. Good luck with that!</p><p>In stark contrast to the glut of data and observations, hard-to-vary explanations are&nbsp;<em>hard to find</em>. This observation has important consequences in AI. First, it illuminates the dreadful conflation between explanations and observations. Observations are plentiful. Bad explanations are plentiful. But good, hard-to-vary explanations are exceedingly rare. Second, there exists criteria for good explanations, which in turn provide the means by which they may be sought and evaluated.</p><p>But of course, this is all just talkity talk when you need to create a practical, working solution!&nbsp;<strong>Judea Pearl</strong>, a pioneer in probabilistic approaches to AI and the development of Bayesian networks, is also a pragmatic AI theorist. In his&nbsp;<a href=\"https://books.google.com/books/about/Causality.html?id=wnGU_TsW3BQC\" target=\"_blank\" style=\"color: inherit;\">book on causality</a>, he reminds us of the basic “intuitions” behind AI. “An autonomous intelligent system attempting to build a workable model of its environment cannot rely exclusively on preprogrammed causal knowledge; rather, it must be able to translate direct observations to cause-and-effect relationships.”</p><p>You’ll recognize in Pearl’s advice the prevailing methodology of AI, introduced above: We need to build an autonomous intelligent system; pragmatically, it needs to be workable, end-to-end; and that solution&nbsp;<em>must</em>&nbsp;involve induction, an ability to translate direct observations to cause-and-effect relationships, “assuming that the bulk of human knowledge derives from passive observations.” Induction is the principle assumed, intuitive and self-evident, just common sense.</p><h3>Defying Common Sense: Why Does AI&nbsp;Work?</h3><p>Knowledge creation defies common sense. Induction isn’t a principle, it’s a Faustian bargain. But like any deal with the devil, it’s a choice made against a paucity of other choices. What does AI look like when it’s based on an anti-inductive theory of knowledge? We can generalize, extrapolate or analogize. We can inch step-by-step towards the best explanation. We can randomly mutate our ideas or throw shit against the wall. But feats of creativity, of bold conjecture, are still largely mysterious.</p><p>Wherever this mystery leads, look for explanations at the helm. Explanations figure prominently in the past, present and future of AI. The popular history of AI is that non-inductive approaches necessarily lead to brittle hand crafted systems of knowledge engineering. But on closer examination, explanations have been successfully operationalized in many guises, such as the inductive bias of a learner, the role of background knowledge in “priming the pump” of induction, the importance of sound priors for confronting the “curse of dimensionality”, and the venerable Occam’s razor.</p><p>The most imaginative solutions are increasingly focused on explanations. Explanatory factors enable rapid learning using only a handful of observations. Innovations in compositionality, distributed representations, and transfer learning mirror the integration of explanations across multiple domains. (Recall a key criterion of good explanations is their external coherence.) Explanations also figure prominently in the context of automated scientific discovery through heuristics and search strategies to narrow down a large space of possible hypotheses and new ideas. Generative approaches illustrate the power of explanatory models to&nbsp;<em>create</em>&nbsp;data based on explanations of their environments. These visionary approaches leap over the brittle corpses of knowledge engineering in surprising ways.</p><p>Explanations impose constraints on knowledge creation and constraints lead to creativity. In their discussion of the role of knowledge in learning, Russell and Norvig explain, “The modern approach is to design agents that&nbsp;<em>already know something&nbsp;</em>and are trying to learn some more. This may not sound like a terrifically deep insight, but it makes quite a difference to the way we design agents. It might also have some relevance to our theories about how science itself works.” Indeed, it’s why science works!</p><p>So why does AI work? Inductive systems work because the problem of induction&nbsp;<em>can be managed</em>. In many respects, research and engineering efforts are directed to minimizing the errors that travel with induction. With the incorporation of sound background knowledge and assumptions of uniformity (such as, the future will resemble the past), inductive technologies succeed. And since there is no universal solution, no free lunch, a deep understanding of the knowledge domain is paramount. This competitive advantage is often expressed as&nbsp;<em>privileged access to data</em>, but it’s better understood as the power of explanations to intelligently guide you to the right data.</p><p>A new perspective is gained when induction is cast as a problem to navigate rather than a principle unchallenged. While AI may ignore Popper, Popper reads deeply on AI. And just as various schools of philosophy converged on the consensus of explanations, various schools of AI are converging on the foundation of explanations to create&nbsp;<em>good</em>&nbsp;knowledge.</p><p><em>Special thanks to Kathryn Hume and David Deutsch for their feedback on earlier drafts of this post.</em></p><p><br></p><p>Thanks for reading! If you liked it, please hit the applause 👏 so others find it. I occasionally blog about startups, healthcare and AI, if you’d like to Follow me and our startup journey. You can also connect with me on&nbsp;<a href=\"https://twitter.com/petersweeney\" target=\"_blank\" style=\"color: inherit;\">Twitter</a>&nbsp;and&nbsp;<a href=\"https://www.linkedin.com/in/peterjsweeney/\" target=\"_blank\" style=\"color: inherit;\">LinkedIn</a>&nbsp;to share ideas or leave a comment below👇.</p><p><br></p><p>Aaronson, S. (2011). Why philosophers should care about computational complexity.&nbsp;<a href=\"https://arxiv.org/abs/1108.1791\" target=\"_blank\" style=\"color: inherit;\">https://arxiv.org/abs/1108.1791</a></p><p>Cartwright, N. (1983).&nbsp;<em>How the laws of physics lie.</em>&nbsp;Clarendon Press.</p><p>Cohnitz, D., &amp; Rossberg, M. (2016). Nelson Goodman.&nbsp;<a href=\"https://plato.stanford.edu/archives/win2016/entries/goodman/\" target=\"_blank\" style=\"color: inherit;\">https://plato.stanford.edu/archives/win2016/entries/goodman/</a></p><p>Deutsch, D. (1998).&nbsp;<em>The fabric of reality.</em>&nbsp;Penguin.</p><p>Deutsch, D. (2011).&nbsp;<em>The beginning of infinity.</em>&nbsp;Allen Lane.</p><p>Fetzer, J. (2017). Carl Hempel.&nbsp;<a href=\"https://plato.stanford.edu/archives/fall2017/entries/hempel/\" target=\"_blank\" style=\"color: inherit;\">https://plato.stanford.edu/archives/fall2017/entries/hempel/</a></p><p>Miller, D. (2014). Some hard questions for critical rationalism.&nbsp;<a href=\"http://www.scielo.org.co/scielo.php?pid=S0124-61272014000100002&amp;script=sci_arttext&amp;tlng=en\" target=\"_blank\" style=\"color: inherit;\">http://www.scielo.org.co/scielo.php?pid=S0124-61272014000100002&amp;script=sci_arttext&amp;tlng=en</a></p><p>Pearl, J. (2009).&nbsp;<em>Causality: models, reasoning, and inference</em>&nbsp;(2nd ed.)<em>.&nbsp;</em>Cambridge University Press.</p><p>Popper, K. R. (1968/2002).&nbsp;<em>The logic of scientific discovery.</em>&nbsp;Routledge.</p><p>Russell, S., &amp; Norvig, P. (2009).&nbsp;<em>Artificial intelligence: a modern approach</em>&nbsp;(3rd ed.). Pearson.</p><p>Salmon, W. C. (1989).&nbsp;<em>Four decades of scientific explanation.</em>&nbsp;University of Pittsburgh Press.</p><p>Sculley, D., Snoek, J., Wiltschko, A., Rahimi, A. (2018). Winner’s curse? On pace, progress, and empirical rigor.&nbsp;<a href=\"https://openreview.net/forum?id=rJWF0Fywf\" target=\"_blank\" style=\"color: inherit;\">https://openreview.net/forum?id=rJWF0Fywf</a></p><p>Shalev-Shwartz, S., &amp; Ben-David, S. (2014).&nbsp;<em>Understanding machine learning: from theory to algorithms.</em>&nbsp;New York: Cambridge University Press.</p><p>Sweeney, P. (2017). Why prediction is the essence of intelligence.&nbsp;<a href=\"https://medium.com/inventing-intelligent-machines/prediction-is-the-essence-of-intelligence-42c786c3e5a9\" target=\"_blank\" style=\"color: inherit;\">https://medium.com/inventing-intelligent-machines/prediction-is-the-essence-of-intelligence-42c786c3e5a9</a></p><p>Turing, A. M. (1950). Computing machinery and intelligence.&nbsp;<em>Mind</em>, 49, 433–460.</p><p>Vickers, J. (2014). The problem of induction.&nbsp;<a href=\"https://plato.stanford.edu/archives/spr2018/entries/induction-problem/\" target=\"_blank\" style=\"color: inherit;\">https://plato.stanford.edu/archives/spr2018/entries/induction-problem/</a></p><p>Wolpert, D., &amp; Macready, W. (1997). No free lunch theorems for optimization.&nbsp;<em>IEEE transactions on evolutionary computation</em>, 1(1), 67–82. doi:10.1109/4235.585893</p>",
        "topic": "Artificial Intelligence",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 8
    },
    {
        "title": "Minimalist Journaling: A Fun and Effective Tool for Tremendous Habit Change",
        "image": "https://saghen.com/uploads/style.jpeg",
        "author": "Eric Dyer",
        "length": "24 mins",
        "previewcontent": "“The key to pursuing excellence is to embrace an organic, long-term learning process, and not to live in a shell of static, safe mediocrity.” - Josh Waitzkin. Highly successful people share one common trait that might, at first, surprise you: consistency. Particularly, consistency in taking regular, small actions that, with time, get them to their goals.",
        "content": "<blockquote><em style=\"background-color: transparent;\">“The key to pursuing excellence is to embrace an organic, long-term learning process, and not to live in a shell of static, safe mediocrity.”</em></blockquote><blockquote><em style=\"background-color: transparent;\">- Josh&nbsp;Waitzkin</em></blockquote><p>Highly successful people share one common trait that might, at first, surprise you: consistency. Particularly, consistency in taking regular, small actions that, with time, get them to their goals.</p><p>But what does it take to be consistent ourselves?</p><p>A&nbsp;<a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.674\" target=\"_blank\" style=\"color: inherit;\">UCL study</a>&nbsp;shows that it takes an average of 66 days to build a habit — and it can take much longer if it’s a hard one to develop. That’s a long time! Consistent work on new habits is especially difficult if it takes time for changes to pay off, or if the goal requires us to put aside other pleasures for a time. As the authors of&nbsp;<a href=\"http://stealingfirebook.com/\" target=\"_blank\" style=\"color: inherit;\"><em>Stealing Fire</em></a>&nbsp;put it bluntly: people would “rather die than change.”</p><p>Consistency has always been a challenge for me. Despite defining clear goals for myself, I have always struggled to create the habits that would lead me to fulfill them. I had the motivation and time, yet I would consistently fail somewhere around day 10. Failure kept leaving me angry and frustrated, and compounded into a disbelief in my ability to succeed.</p><p>Working on consistency seemed unpleasant and verging on impossible. My motivation was gradually weakening, leaving me to comfort myself with snacks while binge-watching inspiring TED talks. “<em>Better than funny TV shows,”</em>&nbsp;I kept reassuring myself.</p><p>But I knew I wanted more. And that’s when I broke through. Ultimately, I created a new journaling habit designed specifically to support my consistency in working on new habits. In this article, I’ll show you how you can use this same approach to work on your own goals.</p><p><br></p><h3>Hack Your Mind: UI and OS&nbsp;Approach</h3><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/2000/1*4pYb_YzInzIkvewZSLcfYg.jpeg\"></p><p>Illustration by&nbsp;<a href=\"https://medium.com/@silviabastos6\" target=\"_blank\" style=\"color: rgb(0, 124, 190);\">Sílvia&nbsp;Bastos</a>.</p><p>The authors of&nbsp;<em>Stealing Fire</em>&nbsp;suggest that one of the ways we can increase our productivity is to intentionally repurpose our psychology to work like an intuitive dashboard —a sort of user interface (UI).</p><p>These researchers were studying non-ordinary states of consciousness in an attempt to understand how triggering those states intentionally might offer useful tools for boosting performance. Their metaphor for using these states was that we could use them in the same way that apps on your phone are used to accomplish specific tasks—without requiring that you re-wire the underlying operating system (OS).</p><p>By seeing our own mind’s “User Interface” potential, instead of getting lost in the complexity of the OS running our entire body, we could focus our energy on simple, effective activities — just like running intuitive apps.</p><p>This concept captured my attention; how could I use it to help me with my own habits?</p><p>An example: if you feel depressed and unmotivated, you have two choices:</p><p>(1) do nothing and feel overwhelmed with the complexity of your OS (and hope it will just miraculously fix itself), or</p><p>(2) simply run another “app”, such as engaging in&nbsp;<a href=\"https://www.cambridge.org/core/journals/public-health-nutrition/article/influence-of-physical-activity-on-mental-wellbeing/3C363AEECE5C8CAC490A585BA29E6BF8\" target=\"_blank\" style=\"color: inherit;\">physical exercise</a>&nbsp;or&nbsp;<a href=\"https://www.psychologytoday.com/us/blog/feeling-it/201309/20-scientific-reasons-start-meditating-today\" target=\"_blank\" style=\"color: inherit;\">meditation</a>&nbsp;(which are scientifically proven to have a positive impact on our mood).</p><p>Now, although this sounds great in theory, the problem with this approach is that most of us will only engage in activities such as exercise and meditation&nbsp;<em>after</em>&nbsp;we feel better, rather than&nbsp;<em>in order to</em>&nbsp;feel better.</p><p>This was it. I knew my problem, and I had a solution. In order to make it work, I just had to find a way to run those apps whenever my OS was facing a crisis. I needed a good UI to put those apps right in front of me when I needed them.</p><p>So I decided to invent my own dashboard.</p><p>How did I do that?</p><p>It’s simple: it started with grabbing a journal.</p><p><br></p><h3>Journaling, Consistency and Accountability</h3><p>According to&nbsp;<a href=\"https://www.researchgate.net/publication/228071867_From_Habits_to_Self-Regulation_How_Do_We_Change\" target=\"_blank\" style=\"color: inherit;\">research</a>, the recipe to achieve lasting change combines three major components:</p><ul><li>Awareness of the changes one desires to make.</li><li>Identifying potential problems and solutions.</li><li>Commitment to actually making the change.</li></ul><p><em>“How can I make sure I tick all these boxes in order to build habits that would last?”</em>&nbsp;As I asked myself this question, an obvious solution came to my mind immediately:</p><p><em>Journaling.</em></p><p>A&nbsp;<a href=\"https://nsuworks.nova.edu/cgi/viewcontent.cgi?referer=https://duckduckgo.com/&amp;httpsredir=1&amp;article=1310&amp;context=tqr\" target=\"_blank\" style=\"color: inherit;\">report</a>&nbsp;from Kent State University shows that journaling has many benefits, such as increasing our ability to evaluate experiences and clarifying thinking processes. I also knew from my own experience that whenever I took the time to journal my thoughts first thing in the morning, my whole day would become brighter, my problem-solving skills sharper, and my actions more in alignment with my goals and my sense of purpose. Tracking my performance on my goals acts as a form of self-accountability, reinforcing my commitment.</p><p>I designed a journaling system to help me remain aware of my goals, gain clarity over problems and solutions, and form strong personal accountability to help me stay committed.</p><p><br></p><h3>My Minimalist Journaling System</h3><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/2000/1*-jcHfQ4xMKwTFqgd9NZuIA.jpeg\"></p><p>In order for my new UI to work, it had to be intuitive, effortless, and, most importantly, deeply integrated with myself. In order for me to actually&nbsp;<em>use&nbsp;</em>it, it had to be&nbsp;<em>fun.</em></p><p>So how did I achieve this? It’s simple:&nbsp;<strong>I found a way to engage both my rational and emotional mind in the process.</strong></p><p>It takes only 5 minutes of my day, max, and yet it is the most powerful tool for consistency I have ever tried. I call it my “Minimalist Journaling System”.</p><p>This practice became my new UI. As soon as I started using it, everything changed: this system prompts me to set goals and track my progress, and broadens my perspective of the overall process. At the same time, it turns my emotions into fuel, giving me motivation, aesthetic pleasure and fun.</p><p>Read on for the details, and examples of how to apply it yourself.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/2000/1*S7RIUob65djqjRDXRB_JtQ.jpeg\"></p><p><br></p><h3>The Basics</h3><p><strong>It’s intuitive.</strong></p><p>Every morning I draw a square. Each square represents one day of my life. At the end of the day I fill in the square with information.</p><p><strong>It’s effortless.</strong></p><p>What I need is paper (my journal), a pen, and 5 minutes of my time every day.</p><p><strong>It gives me perspective.</strong></p><p>Each square has a unique ID number, indicating which day of my life it is (you can calculate it&nbsp;<a href=\"https://www.timeanddate.com/date/duration.html\" target=\"_blank\" style=\"color: inherit;\">here</a>).</p><p>Every morning when I write the number, I remind myself that every day is unique and will never happen again. Consequently, from the early start I’m in “<em>carpe diem</em>&nbsp;mode”, ready to live another fulfilling day.</p><p>On the other hand, since there are so many squares, I feel reassured that even if I fail, I can always start over. Every square is a new empty white canvas, giving me a chance to fill it with amazing content.</p><p><strong>It keeps me motivated.</strong></p><p>In the central part of each square, I record what I want to remember from that day. It can be an event, an achievement, a conversation, a feeling, or anything else that answers the question:</p><p>“<em>What would I like to remember this day for?</em>”</p><p>Some days I feel like I have done nothing and wasted my time, and in the evening I have nothing to record. This usually makes me feel really embarrassed, but I use that embarrassment as a weapon, as it boosts my motivation to make the following day outstanding.</p><p>Moreover, when I feel low or doubt my progress, I look back at all the squares and all the things worth remembering. This fills me with a profound sense of gratitude, which is&nbsp;<a href=\"https://upliftconnect.com/gratitude-experiment/\" target=\"_blank\" style=\"color: inherit;\">scientifically proven</a>&nbsp;to have astounding effects on our general well-being and motivation.</p><p><strong>It’s visually appealing.</strong></p><p>Squares are an incredibly simple visualization of data.</p><p>Since they are small, I’m forced to record only the essential. Furthermore, since what I track evolves over time, I need to constantly optimize the system itself, which keeps me focused and engaged.</p><p>Most importantly, I simply enjoy looking at all the squares together. Their visually pleasing aesthetic keeps bringing me back every day to draw yet another square.</p><p><strong>It’s fun.</strong></p><p>Squares have been so much fun to use that I haven’t skipped a single day since I started (half a year ago). This is crucial, as it removes mental blocks connected with habit building and consistency. My UI brings me so much pleasure that I simply cannot imagine myself skipping a square.</p><p><br></p><h3>The Details</h3><p>Here’s an example of how I set my goals, followed by how I track them in each square:</p><blockquote><strong><em>Between today and 31st of April I will:</em></strong></blockquote><blockquote><strong><em>Sharpen myself by intermittent fasting.</em></strong></blockquote><blockquote><em>Trackable step: Not eating after 18h00.</em></blockquote><blockquote><em>Visual tracking: “</em><strong><em>+</em></strong><em>” if successful, “</em><strong><em>–</em></strong><em>“ if unsuccessful.</em></blockquote><blockquote><strong><em>Improve my work by eliminating distractions.</em></strong></blockquote><blockquote><em>Trackable step: No email or social media outside of specific time slot.</em></blockquote><blockquote><em>Visual tracking: “♦” if unsuccessful</em></blockquote><blockquote><strong><em>Improve my relationships by replacing anger with compassion.</em></strong></blockquote><blockquote><em>Trackable step: Every time I feel angry before interacting ask myself — “Am I acting from a place of compassion?”.</em></blockquote><blockquote><em>Visual tracking: “♥” if successful</em></blockquote><p>And here’s step-by-step examples of how those (and other habits) show up in my squares:</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*EiV0GomWaEaVbPKp7Y_xNw.jpeg\"></p><ol><li><em>“What do I want to remember this day for?”</em></li><li>Number of days I have lived until today (“<em>Which day of my life is it today?</em>”)</li><li>If I travel, I write down where I traveled to.</li></ol><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*ZmRUxnFM1PCpU3Cc8NRzhQ.jpeg\"></p><p>4. This mark indicates that I was able to remember my dreams upon waking up…</p><p>5.&nbsp;… and this one that I had a lucid dream.</p><p>6. Marked if I had problems sleeping.</p><p>7. Time I woke up.</p><p>8. Time I went to sleep.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*ncPxgiMkh5yWLJ6pelJOXQ.jpeg\"></p><p>9. Indicates I had ‘self time’.</p><p>10. Number of meaningful interactions I had that day.</p><p>11. Indicates I wrote a hand-written letter that day.</p><p>12. “<em>Have I been acting from a place of compassion today?”</em>&nbsp;This is one of the focus areas of my current 30-day improvement plan.</p><p>13. “<em>What kind of learning did I engage in?”</em></p><p>R — reading, D — watching a documentary, L — other forms of learning.</p><p>14. Indicates I have meditated for at least 30 minutes.</p><p>15. Indicates that I used social media/email outside of allocated slot. This is another one of the focus areas of my current 30 day improvement plan.</p><p>16. Physical exercise section.</p><p>Y — yoga, S — swimming, H — hiking, O — cycling, E — workout, R — run, D — dance.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*XH1SX4GFuTMCvFYPMlYMXA.jpeg\"></p><p>17. “<em>What substances did I feed my body with?”</em></p><p>F — fruits, V — vegetables, N — nuts, A — animal products, C — coffee.</p><p>18. Indicates I ate only raw food.</p><p>19. Number of times I moved my bowels.</p><p>20.&nbsp;<em>Did I eat after 18h00?</em>&nbsp;“+” if successful, “–“ if unsuccessful. This is the last one of the focus areas of my current 30 day improvement plan.</p><p>21. Number of days eating raw in a row.</p><p>22. Indicates that I overate.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/2000/1*iZLKMcOVZPzdpYFwLE0mpA.jpeg\"></p><p><br></p><h3>What are the&nbsp;results?</h3><p>Over the first few months of using this system, I became an effective habit-building machine.</p><p>Let’s have a look at my daily workout habit since I started with this journaling practice.</p><p>After I had been tracking my daily workouts for 84 days, I noticed that I had skipped 34 of them, which left me with a failure rate of approximately 40%. It’s not an exceptional mark, but it’s better than what I would have been able to reach before applying this system — before, I never even managed to maintain an exercise routine for more than 2 weeks.</p><p>However, the insights brought by this journaling practice allowed me to take my progress even further.</p><p>As I tracked each specific exercise on my routine, I noticed that the main problem was that I didn’t enjoy the particular kind of workout I was doing. As I saw this, I knew that all I had to do was change it by implementing a routine that felt better for me and for my body (that’s when I stopped doing calisthenics and began my yoga practice).</p><p>After that,&nbsp;<strong>my failure rate dropped to 8%</strong>&nbsp;(6 sessions missed out of a total of 74).</p><p>Other than physical exercise, adopting the minimalist journalist system helped me to transform my diet (99 days eating raw food in 2018 so far), quit coffee addiction (I only had 9 cups in 2018 so far, while before I was having up to 3 cups a day for months) and meditate daily for 141 days with a failure rate of 8%.</p><p>That’s only a few out of my list of successes.</p><p>I was also able to identify certain patterns, such as feeling the most productive and balanced when waking up no later than 6am. It’s an invaluable piece of information which keeps me rising early every day.</p><p>The main benefit is that by keeping record of my daily habits, I keep myself accountable for my life. Squares don’t lie. They become my personal mirror reflecting my life back at me.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/2000/1*aThMZLGKJBcEDt0WKPOPPQ.jpeg\"></p><p>Illustration by&nbsp;<a href=\"https://medium.com/@silviabastos6\" target=\"_blank\" style=\"color: rgb(0, 124, 190);\">Sílvia&nbsp;Bastos</a>.</p><p>But the transformation goes even deeper.</p><p>I have always been very impatient, expecting immediate results — especially when it comes to myself. If I don’t succeed straight away, I lose focus and interest.</p><p>Tracking my daily progress over a long period of time made me aware of the activities that I want to add or remove from my life. I remained progress-oriented, while noticing that I’m in fact succeeding and becoming consistent.</p><p>Being successful in specific areas of my life in which before I would always fail has given me an unparalleled sense of confidence. I now know that I can rely on myself and that I do have the capacity to transform my habits (and my life) as I please. I trust myself that I can commit to anything I chose to.</p><p>It only takes a page or two of my squares.</p><p><br></p><h3>Prioritizing your&nbsp;goals</h3><p>I knew from the beginning that in order for the Minimalist Journaling System to work, it had to be based on a solid goal setting routine. However, I knew from my previous experience that having a lot of goals doesn’t work for me.</p><p>It doesn’t work for most people, and successful people learn to prioritze ruthlessly: for example, after a long and heated discussion with his employees, Steve Jobs wrote down the 10 top priorities for Apple on a whiteboard. And then he crossed out 7 of them.</p><p>Currently I use the “thirty day improvement plan” suggested by David Schwartz in his book&nbsp;<a href=\"https://www.amazon.com/Magic-Thinking-Big-David-Schwartz/dp/0671646788\" target=\"_blank\" style=\"color: inherit;\"><em>The Magic of Thinking Big</em></a> — but with a little twist. While Schwartz recommends focusing on 5 improvement areas every month, I realized that I achieve better results when focusing on only 3.</p><p>At the beginning of every month I write down the following statement on my notebook:</p><p><strong>“Between today and [last day of the month] I will:”</strong></p><p>Then I list three activities/habits on which I want to work on; one in each category.</p><p><strong>Sharpen myself by ___</strong></p><p><strong>Improve my work by ___</strong></p><p><strong>Improve my relationships by ___</strong></p><p>Next off I break down my goals into actionable steps, and I make every desired improvement trackable. This is a crucial point.</p><p>For each activity/habit I write down a step, which I can take every day (ideally) or in any other interval that makes sense. Then I find a way to visually track it and record it in the squares.</p><p>For example –</p><p><strong>Between today and 31st of April I will:</strong></p><p><strong>Sharpen myself by doing intermittent fasting.</strong></p><p>Trackable step: Not eating after 18h00.</p><p>Visual tracking: I draw a plus (+) if I was successful and a minus (-) if I wasn’t.</p><p>The final step is to track results. Whenever the month is finished, I review my improvement plan. It takes very little time, since I have been looking at the squares everyday and I instantly know to what degree I have been successful. I then decide to either set a new goal, modify the goal or keep the goal as it was. Then I move on to another month.</p><p><br></p><h3>Ready to make it&nbsp;yours?</h3><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/2000/1*b0gY3Rx8OXKdmdleBgyoCQ.jpeg\"></p><p>Illustration by&nbsp;<a href=\"https://medium.com/@silviabastos6\" target=\"_blank\" style=\"color: rgb(0, 124, 190);\">Sílvia&nbsp;Bastos</a>.</p><p>Before you begin drawing squares, remember that in order for your UI to work, it needs to become an integral part of your life.</p><p>Ask yourself:</p><p><em>“What is the most effortless and intuitive way I could track my results in order to build solid consistency over time?”</em></p><p>Whatever dashboard you create, be aware that what you track and how you track it will most likely evolve over time. That’s great news, as it means that you are progressing.</p><p>My own journey began with tracking a few simple activities, and with time I learned that it benefits me to track my sleeping patterns, diet, relationships, travels, exercise, and learning — among numerous other things. I am now able to pay attention to more components of my life, while using the same amount of time and energy.</p><p>Finally (and most importantly) — make it as much fun as possible. This is what will make you not want to skip a single day. Reaching your goals will still require work, but the journey can become wonderful in itself. You’re getting closer, one square at a time.</p>",
        "topic": "Psychology and Self",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 7
    },
    {
        "title": "What is “this” in JavaScript?",
        "image": "https://saghen.com/uploads/js-this.png",
        "author": "Eric Dyer",
        "length": "16 mins",
        "previewcontent": "this is quite a common thing in JavaScript, but there are a quite a few developers who have taken quite some time to fully understand what this keyword exactly does and where should it be used in your code. In this post I will help you understand this and its mechanism, in depth.",
        "content": "<p>If you have been building things using JavaScript libraries, you might have noticed a particular keyword called&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>.</p><p><code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;is quite a common thing in JavaScript, but there are a quite a few developers who have taken quite some time to fully understand what this keyword exactly does and where should it be used in your code.</p><p>In this post I will help you understand&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;and its mechanism, in depth.</p><p>Before diving in, make sure you have&nbsp;<strong>Node&nbsp;</strong>installed<strong>&nbsp;</strong>on your system. Then, open a command terminal and run the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node</code>&nbsp;command.</p><p><br></p><h3>“this” in Global Environment</h3><p>The working mechanism of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;is not always easy to understand. To understand how&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;works, we will start looking at&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;in different environments. Let’s start by looking at the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">global</code>&nbsp;environment first.</p><p>At the global level,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;is equivalent to a global object called&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">global</code>.</p><pre class=\"ql-syntax\" spellcheck=\"false\">&gt; <span class=\"hljs-keyword\">this</span> === <span class=\"hljs-built_in\">global</span><span class=\"hljs-literal\">true</span></pre><p>But this is true only inside&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node</code>. If we try to run this same code inside a JavaScript file, we will get the output as false.</p><p>To test this, create a file called&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">index.js</code>&nbsp;with the following code inside it:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-keyword\">this</span> === <span class=\"hljs-built_in\">global</span>);</pre><p>Then run this file using the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node</code>&nbsp;command:</p><pre class=\"ql-syntax\" spellcheck=\"false\">$ node index.js<span class=\"hljs-literal\">false</span></pre><p><span style=\"background-color: transparent;\">The reason for this is that inside a JavaScript file,&nbsp;</span><code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code><span style=\"background-color: transparent;\">&nbsp;equates to</span><code style=\"background-color: rgba(0, 0, 0, 0.05);\">module.exports</code><span style=\"background-color: transparent;\">&nbsp;and not&nbsp;</span><code style=\"background-color: rgba(0, 0, 0, 0.05);\">global</code><span style=\"background-color: transparent;\">.</span></p><p><br></p><h3>“this” inside Functions</h3><p>The value of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;inside a function is usually defined by the function’s call. So,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;can have different values inside it for each execution of the function.</p><p>In your&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">index.js</code>&nbsp;file, write a very simple function that simply checks if&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>is equal to the global object.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> <span class=\"hljs-title\">rajat</span>() </span>{<span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-keyword\">this</span> === global)}rajat()</pre><p>If we run this code using&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node</code>, we will the output as&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">true</code>. But we add&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">\"use strict\"</code>&nbsp;at the top of the file and run it again, we will get a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">false</code>&nbsp;output because now the value of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;is&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">undefined</code>.</p><p>To further explain this, let’s create a simple function that defines a Superhero’s real name and hero name.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> <span class=\"hljs-title\">Hero</span>(<span class=\"hljs-params\">heroName, realName</span>) </span>{<span class=\"hljs-keyword\">this</span>.realName = realName;<span class=\"hljs-keyword\">this</span>.heroName = heroName;}<span class=\"hljs-keyword\">const</span> superman= Hero(<span class=\"hljs-string\">\"Superman\"</span>, <span class=\"hljs-string\">\"Clark Kent\"</span>);<span class=\"hljs-built_in\">console</span>.log(superman);</pre><p>Note that this function is not written in&nbsp;<strong>strict mode</strong>. Running this code in&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node</code>&nbsp;will not get us the value of “Superman” and “Clark Kent” as we expected, but it will instead just give us an&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">undefined</code>.</p><p>The reason behind this is that since the function is not written in&nbsp;<strong>strict mode</strong>,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;refers to the global object.</p><p>If we run this code in&nbsp;<strong>strict mode</strong>, we will get an error because JavaScript does not allow us to assign properties&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">realName</code>&nbsp;and&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">heroName</code>&nbsp;to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">undefined</code>. This actually is a good thing because it prevents us from creating global variables.</p><p>Lastly, writing the function’s name in uppercase means that we need to call it as a constructor using the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">new</code>&nbsp;operator. Replace the last two lines of the above code snippet with this:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-keyword\">const</span> superman = <span class=\"hljs-keyword\">new</span> Hero(<span class=\"hljs-string\">\"Superman\"</span>, <span class=\"hljs-string\">\"Clark Kent\"</span>);console.<span class=\"hljs-built_in\">log</span>(superman);</pre><p>Run the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node index.js</code>&nbsp;command again, and you will now get the expected output.</p><p><br></p><h3>“this” inside constructors</h3><p>JavaScript does not have any special constructor functions. All we can do is convert a function call into a constructor call using&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">new</code>&nbsp;operator as shown in the above section.</p><p>When a constructor call is made, a new object is created and set as the function’s&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;argument. The object is then implicitly returned from the function, unless we have another object that is being returned explicitly.</p><p>Inside the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">hero</code>&nbsp;function write the following&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">return</code>&nbsp;statement:</p><pre class=\"ql-syntax\" spellcheck=\"false\">return {<span class=\"hljs-attribute\">heroName</span>: <span class=\"hljs-string\">\"Batman\"</span>,realName: <span class=\"hljs-string\">\"Bruce Wayne\"</span>,};</pre><p>If we run the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node</code>&nbsp;command now, we will see that the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">above</code>&nbsp;return statement overwrites the constructor call.</p><p>The only scenario where the return statement doesn’t overwrite the constructor call is if the return statement tries to return anything that is not an object. In this case, the object will contain the original values.</p><p><br></p><h3>“this” in&nbsp;Methods</h3><p>When calling a function as a method of an object,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;refers to the object, which is then known as the receiver of the function call.</p><p>Here, I have a method&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue</code>&nbsp;inside an object called&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">hero</code>. The&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue</code>‘s&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value then refers to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">hero</code>&nbsp;itself. So&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">hero</code>&nbsp;here will be know as the receiver of the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue</code>&nbsp;method’s call.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-keyword\">const</span> hero = {<span class=\"hljs-attr\">heroName</span>: <span class=\"hljs-string\">\"Batman\"</span>,dialogue() {<span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-string\">`I am <span class=\"hljs-subst\">${<span class=\"hljs-keyword\">this</span>.heroName}</span>!`</span>);}};hero.dialogue();</pre><p>This is very simply example. But in the real-world cases it can get very hard for our method to keep track of the receiver. Write the following snippet at the end of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">index.js</code>.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-keyword\">const</span> saying = hero.dialogue();saying();</pre><p>Here, I am storing the reference to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue</code>&nbsp;inside another variable and calling the variable as a function. Run this with&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node</code>&nbsp;and you will see that&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;returns an&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">undefined</code>&nbsp;because the method has lost track of the receiver.&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;now refers to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">global</code>&nbsp;instead of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">hero</code>.</p><p>The loss of receiver usually happens when we are passing a method as a callback to another. We can either solve this by adding a wrapper function or by using&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">bind</code>&nbsp;method to tie our&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;to a specific object.</p><p><br></p><h3>call() and&nbsp;apply()</h3><p>Though a function’s&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value is set implicitly, we can also call function with explicit&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;argument&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">call()</code>&nbsp;and&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">apply()</code>.</p><p>Lets restructure the previous sections code snippet like this:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> <span class=\"hljs-title\">dialogue</span> () </span>{<span class=\"hljs-built_in\">console</span>.log (<span class=\"hljs-string\">`I am <span class=\"hljs-subst\">${<span class=\"hljs-keyword\">this</span>.heroName}</span>`</span>);}<span class=\"hljs-keyword\">const</span> hero = {<span class=\"hljs-attr\">heroName</span>: <span class=\"hljs-string\">'Batman'</span>,};</pre><p>We need to connect the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue</code>&nbsp;function with the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">hero</code>&nbsp;object as a receiver. To do so, we can either use&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">call()</code>&nbsp;or&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">apply()</code>&nbsp;like this:</p><pre class=\"ql-syntax\" spellcheck=\"false\">dialogue.call(hero)<span class=\"hljs-regexp\">//</span> <span class=\"hljs-keyword\">or</span>dialogue.apply(hero)</pre><p>But if you are using&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">call</code>&nbsp;or&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">apply</code>&nbsp;outside of&nbsp;<strong>strict mode</strong>, then passing&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">null</code>&nbsp;or&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">undefined</code>&nbsp;using&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">call</code>&nbsp;or&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">apply</code>&nbsp;will be ignored by the JavaScript engine. This is one of the reasons why it is usually suggested to always write our code in strict mode.</p><p><br></p><h3>bind()</h3><p>When we pass a method as a callback to another function, there is always a risk of losing the intended receiver of the method, making the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;argument set to the global object instead.</p><p>The&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">bind()</code>&nbsp;method allows us to permanently tie a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;argument to a value. So in the below code snippet,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">bind</code>&nbsp;will create a new&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue</code>&nbsp;function and set its&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">hero</code>.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-keyword\">const</span> hero = {<span class=\"hljs-attr\">heroName</span>: <span class=\"hljs-string\">\"Batman\"</span>,dialogue() {<span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-string\">`I am <span class=\"hljs-subst\">${<span class=\"hljs-keyword\">this</span>.heroName}</span>`</span>);}};setTimeOut(hero.dialogue.bind(hero), <span class=\"hljs-number\">1000</span>);</pre><p>By doing so, our&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;cannot be changed by even&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">call</code>&nbsp;or&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">apply</code>&nbsp;methods.</p><p><br></p><h3>Catching “this” inside an Arrow&nbsp;Function</h3><p>Using&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;with an arrow function is quite different from using it with any other kind of JavaScript function. An arrow function uses the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value from its enclosing execution context, since it does have one of its own.</p><p>An arrow function permanently captures the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value, preventing&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">apply</code>or&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">call</code>&nbsp;from changing it later on.</p><p>To explain how&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;works with regards to the arrow functions, let’s write the arrow function shown below:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-keyword\">const</span> batman = <span class=\"hljs-keyword\">this</span>;<span class=\"hljs-keyword\">const</span> bruce = <span class=\"hljs-function\"><span class=\"hljs-params\">()</span> =&gt;</span> {<span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-keyword\">this</span> === batman);};bruce();</pre><p><br></p><p>Here, we are storing the value of a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;in a variable and then comparing the value with a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value that is inside an arrow function. Running&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node index.js</code>&nbsp;in our terminal should give us&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">true</code>&nbsp;as output.</p><p>An arrow function’s&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value cannot be set explicitly. Also, the arrow function will ignored any attempt from us at passing a value to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;using methods like&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">call</code>,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">apply</code>, and&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">bind</code>. An arrow function will refer to the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;value that was set when the arrow function was created.</p><p>An arrow function can also not be used as a constructor. Hence, we cannot assign properties to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;inside an arrow function.</p><p>So what can arrow functions do in regards to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>?</p><p>Arrow functions can help us access&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;within a callback. To explain how this is done. Take a look at the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">counter</code>&nbsp;object that I have written below:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-keyword\">const</span> counter = {<span class=\"hljs-attr\">count</span>: <span class=\"hljs-number\">0</span>,increase() {setInterval(<span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span>() </span>{<span class=\"hljs-built_in\">console</span>.log(++<span class=\"hljs-keyword\">this</span>.count);}, <span class=\"hljs-number\">1000</span>);}}counter.increase();</pre><p>Running this code using&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">node index.js</code>&nbsp;will only give an increase list of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">NaN</code>s. This is because&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this.count</code>&nbsp;is not referring to the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">counter</code>&nbsp;object. It actually refers to the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">global</code>&nbsp;object.</p><p>To make this counter work, lets rewrite it using an arrow function.</p><pre class=\"ql-syntax\" spellcheck=\"false\">const counter = {count: <span class=\"hljs-number\">0</span>,increase () {setInterval (<span class=\"hljs-function\"><span class=\"hljs-params\">()</span> =&gt;</span> {<span class=\"hljs-built_in\">console</span>.log (++<span class=\"hljs-keyword\">this</span>.count);}, <span class=\"hljs-number\">1000</span>);},};counter.increase ();</pre><p>Our callback now uses&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;binding from the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">increase</code>&nbsp;method, and the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">counter</code>&nbsp;now works as it should.</p><p><strong>Note</strong>: Do not try to write&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this.count + 1</code>&nbsp;instead of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">++this.count</code>. The former of these two will only increase the value of count once, and return the that value on each iteration.</p><p><br></p><h3>“this” in&nbsp;Classes</h3><p>Classes are one of the most important parts of any JavaScript apps. Lets see how&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;behaves inside a class.</p><p>A class generally contains a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">constructor</code>, where&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;would refer to any newly created object.</p><p>But in case of methods,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;can also refer to any other value if the method is called as an ordinary function. And just like a method, classes can also lose track of the receiver.</p><p>Let’s re-create the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">Hero</code>&nbsp;functions that we have seen earlier as a class. This class will contain a constructor and a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue()</code>&nbsp;method. Finally, we create an instance of this class and call the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue</code>&nbsp;method.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Hero</span> </span>{<span class=\"hljs-keyword\">constructor</span>(heroName) {<span class=\"hljs-keyword\">this</span>.heroName = heroName;}dialogue() {<span class=\"hljs-built_in\">console</span>.log(<span class=\"hljs-string\">`I am <span class=\"hljs-subst\">${<span class=\"hljs-keyword\">this</span>.heroName}</span>`</span>)}}<span class=\"hljs-keyword\">const</span> batman = <span class=\"hljs-keyword\">new</span> Hero(<span class=\"hljs-string\">\"Batman\"</span>);batman.dialogue();</pre><p><code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;inside the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">constructor</code>&nbsp;refers to the newly created instance of that&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">class</code>. When we call&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">batman.dialogue()</code>, we invoke&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue()</code>&nbsp;as a method with&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">batman</code>&nbsp;as a receiver.</p><p>But if we store a reference to the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue()</code>&nbsp;method, and later invoke it as a function, we once again lose the receiver of the method and the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>argument now refers to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">undefined</code>.</p><pre class=\"ql-syntax\" spellcheck=\"false\">const <span class=\"hljs-keyword\">say</span> = batman.dialogue();<span class=\"hljs-keyword\">say</span>();</pre><p>The reason for error is that JavaScript classes are implicitly in strict mode. We are invoking&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">say()</code>&nbsp;as an function without any autobinding. To solve this, we will need to manually&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">bind()</code>&nbsp;to tie this&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">dialogue()</code>&nbsp;function to&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">batman</code>.</p><pre class=\"ql-syntax\" spellcheck=\"false\">const <span class=\"hljs-keyword\">say</span> = batman.dialogue.bind(batman);<span class=\"hljs-keyword\">say</span>();</pre><p>We can also do this binding inside the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">constructor</code>&nbsp;method.</p><p><br></p><h3>To sum it&nbsp;up…</h3><p>We need to use&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;in JavaScript like we need to pronouns in English. Take these two sentences.</p><ul><li>Rajat loves DC Comics.</li><li>Rajat also loves Marvel movies.</li></ul><p>We use pronouns to combine these two sentences. so these two sentences now become:</p><blockquote><em>Rajat loves DC Comics, and&nbsp;</em><strong><em>he</em></strong><em>&nbsp;also loves Marvel Comics</em></blockquote><p>This short grammar lesson perfectly explains the importance of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;in JavaScript. Just like how the pronoun&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">he</code>&nbsp;connects the two sentences,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>acts as a shortcut to refer the same thing again.</p><p>I hope this post helped you clear any confusions you had about&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">this</code>&nbsp;in JavaScript and you now where and how to use this simple but extremely important keyword in your JavaScript code.</p>",
        "topic": "Programming",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 6
    },
    {
        "title": "Putting comments in code: the good, the bad, and the ugly.",
        "image": "https://saghen.com/uploads/comments.jpeg",
        "author": "Eric Dyer",
        "length": "10 mins",
        "previewcontent": "Documentation comments are intended for anyone who is likely to consume your source code, but not likely to read through it. If you are building a library or framework that other developers will use, you need some form of API documentation. The further removed from the source code your API documentation is, the more likely it is to become outdated or inaccurate over time. A good strategy to mitigate this is to embed the documentation directly into the code and then use a tool to extract it.",
        "content": "<p>Stop me if you’ve heard this one before…</p><blockquote><em style=\"background-color: transparent;\">“Good code is self-documenting.”</em></blockquote><p>In 20+ years of writing code for a living, this is the one phrase I’ve heard the most.</p><p>It’s&nbsp;<em>cliché.</em></p><p>And like many clichés, it has a kernel of truth to it. But this truth has been so abused that most people who utter the phrase have no idea what it really means.</p><p>Is it true?&nbsp;<strong>Yes</strong>.</p><p>Does it mean you should never comment your code?&nbsp;<strong>No</strong>.</p><p>In this article we’ll look at the good, the bad, and the ugly when it comes to commenting your code.</p><p>For starters, there are really two different types of code comments. I call them&nbsp;<strong>documentation comments</strong>&nbsp;and&nbsp;<strong>clarification comments</strong>.</p><h3>Documentation Comments</h3><p>Documentation comments are intended for anyone who is likely to consume your source code, but not likely to read through it. If you are building a library or framework that other developers will use, you need some form of API documentation.</p><p>The further removed from the source code your API documentation is, the more likely it is to become outdated or inaccurate over time. A good strategy to mitigate this is to embed the documentation directly into the code and then use a tool to extract it.</p><p>Here’s an example of a documentation comment from a popular JavaScript library called&nbsp;<a href=\"https://lodash.com/\" target=\"_blank\" style=\"color: inherit;\">Lodash</a>.</p><iframe class=\"ql-video\" frameborder=\"0\" allowfullscreen=\"true\" src=\"https://medium.freecodecamp.org/media/47143a7aa1ec51cd56f7530c242fd938?postId=be9cc65fbf83\" height=\"250\" width=\"700\"></iframe><p><br></p><p>If you&nbsp;<a href=\"https://lodash.com/docs/#countBy\" target=\"_blank\" style=\"color: inherit;\">compare these comments to their online documentation</a>, you’ll see it’s an exact match.</p><p>If you write documentation comments you should ensure that they follow a consistent standard and that they are easily distinguishable from any inline clarification comments you may also want to add. Some popular and well supported standards and tools include&nbsp;<a href=\"http://usejsdoc.org/\" target=\"_blank\" style=\"color: inherit;\">JSDoc</a>&nbsp;for JavaScript,&nbsp;<a href=\"https://github.com/dotnet/docfx\" target=\"_blank\" style=\"color: inherit;\">DocFx</a>&nbsp;for dotNet, and&nbsp;<a href=\"http://www.oracle.com/technetwork/java/javase/documentation/index-jsp-135444.html\" target=\"_blank\" style=\"color: inherit;\">JavaDoc</a>&nbsp;for Java.</p><p>The downside of these kinds of comments is that they can make your code very “noisy” and harder to read for anyone who is actively involved in maintaining it. The good news is that most code editors support “code folding” which allows us to collapse the comments so we can focus on the code.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*o9d-IZKFtlHf4ycY_n4H2Q.gif\"></p><p>Collapsing comments with code folding in Visual Studio&nbsp;Code.</p><h3>Clarification comments</h3><p>Clarification comments are intended for anyone (including your future self) who may need to maintain, refactor, or extend your code.</p><p>Often, a clarification comment is a code smell. It tells you that your code is too complex. You should strive to remove clarification comments and simplify the code instead because, “good code is self-documenting.”</p><p>Here’s an&nbsp;<a href=\"http://stackoverflow.com/a/766363\" target=\"_blank\" style=\"color: inherit;\">example</a>&nbsp;of a bad — though very entertaining — clarification comment.</p><pre class=\"ql-syntax\" spellcheck=\"false\">/* * Replaces with spaces * the braces <span class=\"hljs-keyword\">in</span> cases * <span class=\"hljs-built_in\">where</span> braces <span class=\"hljs-keyword\">in</span> places * cause stasis. **/ <span class=\"hljs-variable\">$str</span> = str_replace(array(<span class=\"hljs-string\">\"{\"</span>,<span class=\"hljs-string\">\"}\"</span>),<span class=\"hljs-string\">\" \"</span>,<span class=\"hljs-variable\">$str</span>); </pre><p>Rather than decorating a slightly confusing statement with a clever rhyme — in&nbsp;<em>amphibrach dimeter</em>, no less — the author would have been far better off spending time on a function that makes the code itself easier to read and understand. Maybe a function named,&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">removeCurlyBraces</code>&nbsp;called from another function named&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">sanitizeInput</code>?</p><p>Don’t get me wrong, there are times — especially when you are slogging through a crushing workload — where injecting a bit of humor can be good for the soul. But when you write a funny comment to make up for bad code, it actually makes people less likely to refactor and fix the code later.</p><p>Do you really want to be the one responsible for robbing all future coders of the joy of reading that clever little rhyme? Most coders would chuckle and move on, ignoring the code smell.</p><p>There are also times when you come across a comment that is redundant. If the code is already simple and obvious, there’s no need to add a comment.</p><p>Like, don’t do this nonsense:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-comment\">/* set the value of the age integer to 32 */</span> <span class=\"hljs-keyword\">int</span> age = <span class=\"hljs-number\">32</span>; </pre><p>Still, there are times when no matter what you do to the code itself, a clarification comment is still warranted.</p><p>Usually this happens when you need to add some context to a non-intuitive solution.</p><p>Here’s a good example from Lodash:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-function\">function <span class=\"hljs-title\">addSetEntry</span>(<span class=\"hljs-params\"><span class=\"hljs-keyword\">set</span>, <span class=\"hljs-keyword\">value</span></span>) </span>{ <span class=\"hljs-comment\">/* Don't return `set.add` because it's not chainable in IE 11. */</span> <span class=\"hljs-keyword\">set</span>.<span class=\"hljs-keyword\">add</span>(<span class=\"hljs-keyword\">value</span>); <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">set</span>; } </pre><p>There are also times when — after a lot of thought and experimentation — it turns out that the seemingly naive solution to a problem is actually the best. In those scenarios it is almost inevitable that some other coder will come around thinking they are much smarter than you are and start messing with the code, only to discover that your way was the best way all along.</p><p>Sometimes that other coder is your future self.</p><p>In those cases, it’s best to save everyone the time and embarrassment and leave a comment.</p><p>The&nbsp;<a href=\"http://stackoverflow.com/a/482129\" target=\"_blank\" style=\"color: inherit;\">following mock-comment</a>&nbsp;captures this scenario perfectly:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-comment\">/** Dear maintainer: Once you are done trying to 'optimize' this routine, and have realized what a terrible mistake that was, please increment the following counter as a warning to the next guy: total_hours_wasted_here = 42 **/</span> </pre><p>Again, the above is more about being funny than being helpful. But you SHOULD leave a comment warning others not to pursue some seemingly obvious “better solution,” if you’ve already tried and rejected it. And when you do, the comment should specify what solution you tried and why you decided against it.</p><p>Here’s a simple example in JavaScript:</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-comment\">/* don't use the global isFinite() because it returns true for null values */</span> Number.isFinite(<span class=\"hljs-keyword\">value</span>) </pre><h3>The Ugly</h3><p>So, we’ve looked at the good and the bad, but what about the ugly?</p><p><br></p><p>Unfortunately, there are times in any job where you’ll find yourself frustrated and when you write code for a living, it can be tempting to vent that frustration in code comments.</p><p>Work with enough code bases and you’ll come across comments that range from cynical and depressing to dark and mean spirited.</p><p>Things like the&nbsp;<a href=\"http://stackoverflow.com/a/185550\" target=\"_blank\" style=\"color: inherit;\">seemingly harmless</a>…</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-comment\">/* This code sucks, you know it and I know it. Move on and call me an idiot later. */</span> </pre><p>…to the&nbsp;<a href=\"http://stackoverflow.com/a/184673\" target=\"_blank\" style=\"color: inherit;\">downright mean</a></p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-comment\">/* Class used to workaround Richard being a f***ing idiot */</span> </pre><p>These things may seem funny or may help release a bit of frustration in the moment, but when they make it into production code they end up making the coder who wrote them and their employer look unprofessional and bitter.</p><p>Don't do this.</p>",
        "topic": "Programming",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 5
    },
    {
        "title": "Designing very large (JavaScript) applications",
        "image": "https://saghen.com/uploads/js_apps.png",
        "author": "Eric Dyer",
        "length": "40 mins",
        "previewcontent": "I used to build very large JavaScript applications. I don’t really do that anymore, so I thought it was a good time to give a bit of a retrospective and share what I learned. Yesterday I was having a beer at the conference party and I was asked: “Hey Malte, what actually gives you the right, the authority, to talk about the topic?” and I suppose answering this is actually on topic for this talk, although I usually find it a bit weird to talk about myself. So, I build this JavaScript framework at Google.",
        "content": "<p>Hello, I used to build very large JavaScript applications. I don’t really do that anymore, so I thought it was a good time to give a bit of a retrospective and share what I learned. Yesterday I was having a beer at the conference party and I was asked: “Hey Malte, what actually gives you the right, the authority, to talk about the topic?” and I suppose answering this is actually on topic for this talk, although I usually find it a bit weird to talk about myself. So, I build this JavaScript framework at Google. It is used by Photos, Sites, Plus, Drive, Play, the search engine, all these sites. Some of them are pretty large, you might have used a few of them.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*v0r4OVf-RXr9ePakdmv5LQ.png\"></p><p>Slide text: I thought React was&nbsp;good.</p><p>This Javascript framework is not open source. The reason it is not open source is that it kind of came out at the same time as React and I was like “Does the world really need another JS framework to choose from?”. Google already has a few of those–Angular and Polymer–and felt like another one would confuse people, so I just thought we’d just keep it to ourselves. But besides not being open source, I think there is a lot to learn from it and it is worth sharing the things we learned along the way.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*LL3uYYDMT5uIFRxR_7JxPQ.png\"></p><p>Picture of lots of&nbsp;people.</p><p>So, let’s talk about very large applications and the things they have in common. Certainly that there might be a lot of developers. It might be a few dozens or even more–and these are humans with feelings and interpersonal problems and you may have to factor that in.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*WEH24kaBbar8-1gzN_AO3w.png\"></p><p>Picture of very old building.</p><p>And even if your team is not as big, maybe you’ve been working on the thing for a while, and maybe you’re not even the first person maintaining it, you might not have all the context, there might be stuff that you don’t really understand, there might be other people in your team that don’t understand everything about the application. These are the things we have to think about when we build very large applications.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*fzb42X35lNGmkQHhJLhEBQ.png\"></p><p>Tweet saying: A team of senior engineers without junior engineers is a team of engineers.</p><p>Another thing I wanted to do here is to give this a bit of context in terms of our careers. I think many of us would consider themselves senior engineers. Or we are not quite there yet, but we want to become one. What I think being senior means is that I’d be able to solve almost every problem that somebody might throw at me. I know my tools, I know my domain. And the other important part of that job is that I make the junior engineers eventually be senior engineers.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*xpRJ1dXHMlFq1V4oDKU__w.png\"></p><p>Slide text: Junior -&gt; Senior -&gt;&nbsp;?</p><p>But what happens is that at some point we may wonder “what might be the next step?”. When we reached that seniority stage, what is the next thing we are going to do? For some of us the answer may be management, but I don’t think that should be the answer for everyone, because not everyone should be a manager, right? Some of us are really great engineers and why shouldn’t we get to do that for the rest of our lives?</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*wL5wiTWICj1keue9YZOAhQ.png\"></p><p>Slide text: “I know how I would solve the&nbsp;problem”</p><p>I want to propose a way to level up above that senior level. The way I would talk about myself as a senior engineer is that I’d say “I know how I would solve the problem” and because I know how I would solve it I could also teach someone else to do it.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*UyLoKH7y54JAYigVlwCJpQ.png\"></p><p>Slide text: “I know how others would solve the&nbsp;problem”</p><p>And my theory is that the next level is that I can say about myself “I know how&nbsp;<em>others&nbsp;</em>would solve the problem”.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*zBBGLRIZw94gp54pspvx-g.png\"></p><p>Slide text: “I can anticipate how API choices and abstractions impact the way other people would solve the problem.”</p><p>Let’s make that a bit more concrete. You make that sentence: “I can anticipate how the API choices that I’m making, or the abstractions that I’m introducing into a project, how they impact how other people would solve a problem.” I think this is a powerful concept that allows me to reason about how the choices I’m making impact an application.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*LnDv6Ry0Hq2MaQEARaD8rg.png\"></p><p>Slide text: An application of&nbsp;empathy.</p><p>I would call this an application of empathy. You’re thinking with other software engineers and you’re thinking about how what you do and the APIs that you are giving them, how they impact how they write software.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*pnYiZTAfQqsbeS7kVkLe_g.png\"></p><p>Slide text: Empathy on easy&nbsp;mode.</p><p>Luckily this is empathy on easy mode. Empathy is generally hard, and this is still very hard. But at least the people that you are having empathy with, they are also other software engineers. And so while they might be very different from you, they at least have in common that they are building software. This type of empathy is really something you can get quite good at as you gain more experience.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Op0wLWIqwZ-A5iSuWrqtKA.png\"></p><p>Slide text: Programming model</p><p>Thinking about these topics there is one really important term that I want to talk about, which is the programming model–a word that I’m going to use a lot. It stands for “given a set of APIs, or of libraries, or of frameworks, or of tools–how do people write software in that context.” And my talk is really about, how subtle changes in APIs and so forth, how they impact the programming model.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*zuLA-tH9b8k4i1yfKMScmA.png\"></p><p>Slide text: Programming model impact examples: React, Preact, Redux, Date picker from npm,&nbsp;npm</p><p>I want to give a few examples of things that impact the programming model: Let’s say you have an Angular project and you say “I’m going to port this to React” that is obviously going to change how people write software, right? But then you’re like “Ah, 60KB for a bit of virtual DOM munging, let’s switch to Preact”–that is an API compatible library, it is not going to change how people write software, just because you make that choice. Maybe then you’re like “this is all really complex, I should have something orchestrating how my application works, I’m going to introduce Redux.”–that is going to change how people write software. You then get this requirement “we need a date picker” and you go to npm, there are 500 results, you pick one. Does it really matter which one you pick? It definitely won’t change how you write software. But having npm at your fingertips, this vast collection of modules, having that around absolutely changes how you write software. Of course, these are just a few examples of things that might or might impact how people write software.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*KfcGnWC3WcwBqGYLPiybgw.png\"></p><p>Slide text: Code splitting</p><p>Now I want to talk about one aspect that all large JavaScript applications have in common, when you deliver them to users: Which is that they eventually get so big that you don’t want to deliver them all at once. And for this we’ve all introduced this technique called code splitting. What code splitting means is that you define a set of bundles for your application. So, you’re saying “Some users only use this part of my app, some users use another part”, and so you put together bundles that only get downloaded when the part of an application that a user is actually dealing with is executed. This is something all of us can do. Like many things it was invented by the closure compiler–at least in the JavaScript world. But I think the most popular way of doing code splitting is with webpack. And if you are using RollupJS, which is super awesome, they just recently added support for it as well. Definitely something y’all should do, but there are some things to think about when you introduce this to an application, because it does have impact on the programming model.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*vAR8HCbwiwX8bVa0xIsk6g.png\"></p><p>Slide text: Sync -&gt;&nbsp;Async</p><p>You have things that used to be sync that now become async. Without code splitting your application is nice and simple. There is this one big thing. It starts up, and then it is stable, you can reason about it, you don’t have to wait for stuff. With code splitting, you might sometimes say “Oh, I need that bundle”, so you now need to go to the network, and you have to factor in that this can happen, and so the applications becomes more complex.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*DqT7As1rm_M9cxyW1RIW6w.png\"></p><p>Slide text:&nbsp;Human</p><p>Also, we have humans entering the field, because code splitting requires you to define bundles, and it requires you to think about when to load them, so these humans, engineers on your team, they now have to make decisions what is going into which bundle and when to load that bundle. Every time you have a human involved, that clearly impacts the programming model, because they have to think about such things.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*0jNa8A5ciY6pCJCN65vLiA.png\"></p><p>Slide text: Route based code splitting</p><p>There is one very established way that solves this problem, that gets the human out of the mess when doing code splitting, which is called route based code splitting. If you’re not using code splitting yet, that is probably how you should do it as a first cut. Routes are the baseline URL structure of your application. You might, for example, have your product pages on `/product/` and you might have your category pages somewhere else. You just make each route one bundle, and your router in your application now understands there is code splitting. And whenever the user goes to a route, the router loads the associated bundle, and then within that route you can forget about code splitting existing. Now you are back to the programming model that is almost the same as having a big bundle for everything. It is a really nice way to do this, and definitely a good first step.</p><p>But the title of this talk is designing&nbsp;<strong>VERY</strong>&nbsp;large JavaScript applications, and they quickly become so big that a single bundle per route might not be feasible anymore, because the routes themselves become very big. I actually have a good example for an application that is big enough.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*ox94bGuhxWXE-OubL7St6w.png\"></p><p>Google Search query screenshot for “public speaking&nbsp;101”</p><p>I was figuring out how to become a public speaker coming up to this talk, and I get this nice list of blue links. You could totally envision that this page fits well into a single route bundle.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*P-XiIPnuzq9_KLA1nG-uRA.png\"></p><p>Google Search query screenshot for&nbsp;“weath”</p><p>But then I was wondering about the weather because California had a rough winter, and suddenly there was this completely different module. So, this seemingly simple route is more complicated than we thought.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Y7e5LoeBggY01aRkJAiwWA.png\"></p><p>Google Search query screenshot for “20 usd to&nbsp;aud”</p><p>And then I was invited to this conference, and was checking out how much 1 US dollar is in Australian dollars, and there is this complex currency converter. Obviously there is about 1000s more of these specialized modules, and it infeasible to put them all in one bundle, because that bundle would be a few megabytes in size, and users would become really unhappy.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*qZhd4a0S-CCB5mUiN3fo5Q.png\"></p><p>Slide text: Lazy load at component level?</p><p>So, we can’t just use route based code splitting, we have to come up with a different way of doing it. Route based code splitting was nice, because you split your app at the coarsest level, and everything further down could ignore it. Since I like simple things, how about doing super fine-grained instead of super coarse-grained splitting. Let’s think about what would happen if we lazy loaded every single component of our website. That seems really nice from an efficiency point of view when you only think about bandwidth. It might be super bad from other point of views like latency, but it is certainly worth a consideration.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Lr2hIk4eH9uU33e77zeSmA.png\"></p><p>Slide text: React component statically depend on their children.</p><p>But let’s imagine, for example, your application uses React. And in React components statically depend on their children. That means if you stop doing that because you are lazy loading your children, then it changes your programming model, and things stop being so nice.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*SWkk2vyn344qCNCPSIkXPA.png\"></p><p>ES6 import&nbsp;example.</p><p>Let’s say you have a currency converter component that you want to put on your search page, you import it, right? That is the normal way of doing it in ES6 modules.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*RxlHaYEav0OaODKYKiUubw.png\"></p><p>Loadable component example.</p><p>But if you want to lazy load it, you get code like this where you use dynamic import, which is a new fancy thing to lazy load ES6 modules and you wrap it in a loadable component. There are certainly 500 million ways to do this, and I am not a React expert, but all of these will change how you write the application.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*N5AMAbobPjsO_lXCPt9-ZA.png\"></p><p>Slide text: Static -&gt;&nbsp;Dynanic</p><p>And things aren’t as nice anymore–something that was static, now becomes dynamic, which is another red flag for the programming model changing.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*j9OB_yjli59MZMyIs9V0_A.png\"></p><p>Slide text: Who decides what to lazy load&nbsp;when?</p><p>You have to suddenly wonder: “Who decides what to lazy load when” because that is going to impact the latency of your application.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*rsJ-C7ph0BrJiwTjHKv6_w.png\"></p><p>Slide text: Static or&nbsp;dynamic?</p><p>The human is there again and they have to think about “there is static import, there is dynamic import, when do I use which?”. Getting this wrong is really bad because one static import, when it should have been dynamic suddenly may put stuff into the same bundle that shouldn’t be. These are the things that are going to go wrong when you have a lot of engineers over long periods of time.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*QGoX4bYhEAuNjuKwQhQ0hg.png\"></p><p>Slide text: Split logic and rendering</p><p>Now I’m going to talk about how Google actually does this and what is one way to get a good programming model, while also achieving good performance. What we do is we take our components and we split them by rendering logic, and by application logic, like what happens when you press a button on that currency converter.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*vMskVnAwJgkZmvl4E-8E4Q.png\"></p><p>Slide text: Only load logic if it was rendered.</p><p>So, now we have two separate things, and we only ever load the application logic for a component when we previously rendered it. This turns out to be a very simple model, because you can simply server side render a page, and then whatever was actually rendered, triggers downloading the associated application bundles. This puts the human out of the system, as loading is triggered automatically by rendering.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Doqt-GOkUp13Qgk5r7WR1g.png\"></p><p>Slide text: Currency converter on search result&nbsp;page.</p><p>This model may seem nice, but it does have some tradeoffs. If you know how server side rendering typically works in frameworks like React or Vue.js, what they do is a process called hydration. The way hydration works, is you server side render something, and then on the client you render it again, which means you have to load the code to render something that is already on the page, which is incredibly wasteful both in terms of loading the code and in terms of executing it. It is a bunch of wasted bandwidth, it is a bunch of wasted CPU–but it is really nice, because you get to ignore on the client side that you server side rendered something. The method we use at Google is not like that. So, if you design this very large application, you have think about: Do I take that super fast method that is more complicated, or do I go with hydration which is less efficient, but such a nice programming model? You will have to make this decision.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*uteTbmuKZF1wGvoysgsBYw.png\"></p><p>Slide text: 2017 Happy New&nbsp;Year</p><p>My next topic is my favorite problem in computer science–which is not naming things, although I probably gave this a bad name. It is the&nbsp;<em>“2017 holiday special problem”</em>. Who here has ever written some code, and now it is no longer needed but it is still in your codebase?&nbsp;… This happens, and I think CSS is particularly famous for it. You have this one big CSS file. There is this selector in there. Who really knows whether that still matches anything in your app? So, you end up just keeping it there. I think the CSS community is at the forefront of a revolution, because they realized this is a problem, and they created solutions like CSS-in-JS. With that you have a single file component, the 2017HolidaySpecialComponent, and you can say “it is not 2017 anymore” and you can delete the whole component and everything is gone in one swoop. That makes it very easy to delete code. I think this is a very big idea, and it should be applied to more than just CSS.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*rkAN_sLohIO63JCOTZ1JgA.png\"></p><p>Slide text: Avoid central configuration at all&nbsp;cost</p><p>I want to give a few examples of this general idea that you want to avoid central configuration of your application at all cost, because central configuration, like having a central CSS file, makes it very hard to delete code.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*-OoPTo-xaxFr2YOGGFnapw.png\"></p><p>Slide text: routes.js</p><p>I was talking before about routes in your application. Many applications would have a file like “routes.js” that has all your routes, and then those routes map themselves to some root component. That is an example of central configuration, something you do not want in a large application. Because with this some engineer says “Do I still need that root component? I need to update that other file, that is owned by some other team. Not sure I’m allowed to change it. Maybe I’ll do it tomorrow”. With that these files becomes addition-only.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*NsqgsGwmgEcy_PedNzmnbQ.png\"></p><p>Slide text: webpack.config.js</p><p>Another example of this anti-pattern is the webpack.config.js file, where you have this one thing that is assumed to build your entire application. That might go fine for a while, but eventually needing to know about every aspect of what some other team did somewhere in the app just doesn’t scale. Once again, we need a pattern to emerge how to decentralize the configuration of our build process.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*L7ZmdS2JvqwWJySz-X50xw.png\"></p><p>Slide text: package.json</p><p>Here is a good example: package.json, which is used by npm. Every package says “I have these dependencies, this is how you run me, this is how you build me”. Obviously there can’t be one giant configuration file for all of npm. That just wouldn’t work with hundreds of thousands of files. It would definitely get you a lot of merge conflicts in git. Sure, npm is very big, but I’d argue that many of our applications get big enough that we have to worry about the same kind of problems and have to adopt the same kind of patterns. I don’t have all the solutions, but I think that the idea that CSS-in-JS brought to the table is going to come to other aspects of our applications.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*E_g_WgMXGuJtyG-F4AGTNg.png\"></p><p>Slide text: Dependency trees</p><p>More abstractly I would describe this idea that we take responsibility for how our application is designed in the abstract, how it is organized, as<em>&nbsp;taking responsibility of shaping the dependency tree of our application</em>. When I say “dependency” I mean that very abstractly. It could be module dependencies, it could be data dependencies, service dependencies, there are many different kinds.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*DfOMmyxC4guVZkyQ4IlF7g.png\"></p><p>Slide text: Example dependency tree with router and 3 root components.</p><p>Obviously, we all have super complicated applications, but I’m going to use a very simple example. It has only 4 components. It has a router that knows how to go from one route of your application to the next, and it has a few root components, A, B, and C.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*CivPR-20NP0dXlIkWfBk6w.png\"></p><p>Slide text: The central import&nbsp;problem.</p><p>As I mentioned before this has the central import problem.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Y9AgFj90bpFsKq6e7o7Jbw.png\"></p><p>Slide text: Example dependency tree with router and 3 root components. Router imports root components.</p><p>Because the router now has to import all the root components, and if you want to delete one of them you have to go to the router, you have to delete the import, you have to delete the route, and eventually you have the holiday special 2017 problem.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*isSwE9e1XLiEw9sbZHwmQQ.png\"></p><p>Slide text: Import -&gt;&nbsp;Enhance</p><p>We at Google have come up with a solution for this, that I want to introduce to you, which I don’t think we have ever talked about. We invented a new concept. It is called enhance. It is something you use instead of import.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*7yPG-uXeixsnQk3k-X9UXw.png\"></p><p>Slide text: Import -&gt;&nbsp;Enhance</p><p>In fact, it is the opposite of import. It is a reverse dependency. If you enhance a module, you make that module have a dependency on you.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*bDH4yzG0mrrYlrs2C9twsA.png\"></p><p>Slide text: Example dependency tree with router and 3 root components. Root components enhance&nbsp;router.</p><p>Looking at the dependency graph, what happens it that there are still the same components, but the arrows point in the opposite direction. So, instead of the router importing the root component, the root components announce themselves using enhance to the router. This means I can get rid of a root component by just deleting the file. Because it is no longer enhancing the router, that is the only operation you have to do to delete the component.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*HDW95QuGKQCsXqwXiUtB5g.png\"></p><p>Slide text: Who decides when to use&nbsp;enhance?</p><p>That is really nice, if it wasn’t for the humans again. They now have to think about “Do I import something, or do I use enhance? Which one do I use under which circumstances?”.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Hr47VQZYSKiBuDap2XgbbQ.png\"></p><p>Image: Danger. Hazardous chemicals.</p><p>This is particular bad case of this problem, because the power of enhancing a module, of being able to make everything else in the system have a dependency on you is very powerful and very dangerous if gotten wrong. It is easy to imagine that this might lead to really bad situations. So, at Google we decided it is a nice idea, but we make it illegal, nobody gets to use it–with one exception: generated code. It is a really good fit for generated code actually, and it solves some of the inherent problems of generated code. With generated code you sometimes have to import files you can’t even see, have to guess their names. If, however, the generated file is just there in the shadows and enhances whatever it needs, then you don’t have these problems. You never have to know about these files at all. They just magically enhance the central registry.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*od_6cmgitlBJk1g9QxU7Ng.png\"></p><p>Slide text: Single file component pointing to its parts that enhance a&nbsp;router.</p><p>Let’s take a look at a concrete example. We have our single file component here. We run a code generator on it and we extract this little route definition file from it. And that route file just says “Hey Router, here I am, please import me”. And obviously you can use this pattern for all kinds of other things. Maybe you are using GraphQL and your router should know about your data dependency, then you can just use the same pattern.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Tg_CvUNzT9K0tbzIVC79kw.png\"></p><p>Slide text: The base&nbsp;bundle</p><p>Unfortunately this is not all we need to know. There is my second favorite problem in computer science which I call the “<em>Base bundle pile of trash”</em>. The base bundle in your graph of bundles in your application is the one bundle that will always get loaded–independent of how the user interacts with the application. So, it is particularly important, because if it is big, then everything further down will also be big. If it small, then dependent bundles at least have a chance of being small as well. A little anecdote: At some point I joined the Google Plus JavaScript infrastructure team, and I found out that their base bundle had 800KB of JavaScript. So, my warning to you is: If you want to be more successful than Google Plus, don’t have 800KB of JS in your base bundle. Unfortunately it is very easy to get to such a bad state.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*wW_u72nFdPiKjEINH4ubDg.png\"></p><p>Slide text: Base bundle pointing to 3 different dependencies.</p><p>Here is an example. Your base bundle needs to depend on the routes, because when you go from A to B, you need to already know the route for B, so it has to always be around. But what you really don’t want in the base bundle is any form of UI code, because depending on how a user enters your app, there might be different UI. So, for example the date picker should absolutely not be in your base bundle, and neither should the checkout flow. But how do we prevent that? Unfortunately imports are very fragile. You might innocently import that cool&nbsp;<em>util</em>&nbsp;package, because it has a function to make random numbers. And now somebody says “I need a utility for self driving cars” and suddenly you import the machine learning algorithms for self driving cars into your base bundle. Things like that can happen very easily since imports are transitive, and so things tend to pile up over time.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*myk-tffGyQx74OIZT4n0mw.png\"></p><p>Slide text: Forbidden dependency tests.</p><p>The solution we found for this are&nbsp;<em>forbidden dependency tests</em>. Forbidden dependency tests are a way to assert that for example your base bundle does not depend on any UI.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*vDtioYTfzhCB9e7jc9A4pg.png\"></p><p>Slide text: Assert that base bundle does not depend on React.Component</p><p>Let’s take a look at a concrete example. In React every component needs to inherit from React.Component. So&nbsp;, if your goal is that no UI could ever be in the base bundle just add this one test that asserts that React.Component is not a transitive dependency of your base bundle.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*s5rDafWJi90dcrlEQSAepg.png\"></p><p>Forbidden dependencies crossed&nbsp;out.</p><p>Looking at the previous example again, you just get a test failure when someone wants to add the date picker. And these test failures are typically very easy to fix right then, because usually that person didn’t really mean to add the dependency–it just crept in through some transitive path. Compare this to when this dependency would have been around for 2 years because you didn’t have a test. In those cases it is typically extremely hard to refactor your code to get rid of the dependency.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*ONmcxDRRdY9DpR8QfwMj4g.png\"></p><p>Slide text: The most natural&nbsp;path</p><p>Ideally though, you find that most natural path.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*7XRIRO-_Y165Gn7Zff_fKQ.png\"></p><p>Slide text: Most straightforward way must be the right&nbsp;way.</p><p><span style=\"background-color: transparent;\">You want to get to a state where whatever the engineers on your team do, the most straightforward way is also the right way–so that they don’t get off the path, so that they naturally do the right thing.</span></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*T6E-ExC2HWa0X--OiJ_vAA.png\"></p><p>Slide text: Otherwise add a test that ensure the right&nbsp;way,</p><p>This might not always be possible. In that case just add a test. But this is not something that many people feel empowered to do. But&nbsp;<strong>please feel empowered to add tests to your application that ensure the major invariants of your infrastructure</strong>. Tests are not only for testing that your math functions do the right thing. They are also for infrastructure and for the major design features of your application.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*y3COuLXS8b1vAQQESjp30Q.png\"></p><p>Slide text: Avoid human judgement outside of application domain.</p><p>Try to avoid human judgement whenever possible outside of the application domain. When working on an application we have to understand the business, but not every engineer in your organization can and will understand how code splitting works. And they don’t need to do that. Try to introduce these thing into your application in a way that is fine when not everybody understands them and keeps the complexity in their heads.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*CqeGbdnSFMRPtZWPIRZCvw.png\"></p><p>Slide text: Make it easy to delete&nbsp;code.</p><p>And really just make it easy to delete code. My talk is called “building very large JavaScript applications”. The best advice I can give: Don’t let your applications get very large. The best way to not get there is to delete stuff before it is too late.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Mt_beSIamHND0E6NjBBetA.png\"></p><p>Slide text: No abstraction is better than the wrong abstraction.</p><p>I want to address just one more point, which is that people sometimes say that having no abstractions at all is better than having the wrong abstractions. What this really means is that the cost of the wrong abstraction is very high, so be careful. I think this is sometimes misinterpreted. It does not mean that you should have no abstractions. It just means you have to be very careful.</p><blockquote><em>We have to become good at finding the right abstractions.</em></blockquote><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*oNXlH0ththqRlPeRm2z0Sw.png\"></p><p>Slide text: Empathy and experience -&gt; Right abstractions.</p><h3>As I was saying at the start of the presentation: The way to get there is to use empathy and think with your engineers on your team about how they will use your APIs and how they will use your abstractions. Experience is how you flesh out that empathy over time. Put together, empathy and experience is what enables you to choose the right abstractions for your application</h3>",
        "topic": "Programming",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 4
    },
    {
        "title": "Why is Python so slow?",
        "image": "https://saghen.com/uploads/python-is-slow.jpg",
        "author": "Eric Dyer",
        "length": "17 mins",
        "previewcontent": "How does Java compare in terms of speed to C or C++ or C# or Python? The answer depends greatly on the type of application you’re running. No benchmark is perfect, but The Computer Language Benchmarks Game is a good starting point.",
        "content": "<p>Python is booming in popularity. It is used in DevOps, Data Science, Web Development and Security. It does not, however, win any medals for speed.</p><blockquote><em>How does Java compare in terms of speed to C or C++ or C# or Python? The answer depends greatly on the type of application you’re running. No benchmark is perfect, but The Computer Language Benchmarks Game is&nbsp;</em><a href=\"http://algs4.cs.princeton.edu/faq/\" target=\"_blank\" style=\"color: inherit;\"><em>a good starting&nbsp;point</em></a><em>.</em></blockquote><p>I’ve been referring to the Computer Language Benchmarks Game for over a decade; compared with other languages like Java, C#, Go, JavaScript, C++, Python is&nbsp;<a href=\"https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/python.html\" target=\"_blank\" style=\"color: inherit;\">one of the slowest</a>. This includes&nbsp;<a href=\"https://en.wikipedia.org/wiki/Just-in-time_compilation\" target=\"_blank\" style=\"color: inherit;\">JIT</a>&nbsp;(C#, Java) and&nbsp;<a href=\"https://en.wikipedia.org/wiki/Ahead-of-time_compilation\" target=\"_blank\" style=\"color: inherit;\">AOT</a>&nbsp;(C, C++) compilers, as well as interpreted languages like JavaScript.</p><p><em>NB: When I say “Python”, I’m talking about the reference implementation of the language, CPython. I will refer to other runtimes in this article.</em></p><blockquote><em>I want to answer this question:&nbsp;When Python completes a comparable application 2–10x slower than another language,&nbsp;why is it slow&nbsp;and can’t we&nbsp;make it&nbsp;faster?</em></blockquote><p>Here are the top theories:</p><ul><li>“<em>It’s the GIL (Global Interpreter Lock)</em>”</li><li>“<em>It’s because its interpreted and not compiled</em>”</li><li>“<em>It’s because its a dynamically typed language</em>”</li></ul><p>Which one of these reasons has the biggest impact on performance?</p><p><br></p><h3>“It’s the&nbsp;GIL”</h3><p>Modern computers come with CPU’s that have multiple cores, and sometimes multiple processors. In order to utilise all this extra processing power, the Operating System defines a low-level structure called a thread, where a process (e.g. Chrome Browser) can spawn multiple threads and have instructions for the system inside. That way if one process is particularly CPU-intensive, that load can be shared across the cores and this effectively makes most applications complete tasks faster.</p><p>My Chrome Browser, as I’m writing this article, has&nbsp;<strong>44</strong>&nbsp;threads open. Keep in mind that the structure and API of threading are different between POSIX-based (e.g. Mac OS and Linux) and Windows OS. The operating system also handles the scheduling of threads.</p><p>IF you haven’t done multi-threaded programming before, a concept you’ll need to quickly become familiar with locks. Unlike a single-threaded process, you need to ensure that when changing variables in memory, multiple threads don’t try and access/change the same memory address at the same time.</p><p>When CPython creates variables, it allocates the memory and then counts how many references to that variable exist, this is a concept known as reference counting. If the number of references is 0, then it frees that piece of memory from the system. This is why creating a “temporary” variable within say, the scope of a for loop, doesn’t blow up the memory consumption of your application.</p><p>The challenge then becomes when variables are shared within multiple threads, how CPython locks the reference count. There is a “global interpreter lock” that carefully controls thread execution. The interpreter can only execute one operation at a time, regardless of how many threads it has.</p><p><br></p><h4>What does this mean to the performance of Python application?</h4><p>If you have a single-threaded, single interpreter application.&nbsp;<strong>It will make no difference to the speed</strong>. Removing the GIL would have no impact on the performance of your code.</p><p><br></p><p>If you wanted to implement concurrency within a single interpreter (Python process) by using threading, and your threads were IO intensive (e.g. Network IO or Disk IO), you would see the consequences of GIL-contention.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/0*S_iSksY5oM5H1Qf_.png\"></p><p>From David Beazley’s GIL visualised post&nbsp;<a href=\"http://dabeaz.blogspot.com/2010/01/python-gil-visualized.html\" target=\"_blank\" style=\"color: inherit;\">http://dabeaz.blogspot.com/2010/01/python-gil-visualized.html</a></p><p>If you have a web-application (e.g. Django) and you’re using WSGI, then each request to your web-app is a&nbsp;<strong>separate</strong>&nbsp;Python interpreter, so there is only 1 lock&nbsp;<em>per</em>&nbsp;request. Because the Python interpreter is slow to start, some WSGI implementations have a “Daemon Mode”&nbsp;<a href=\"https://www.slideshare.net/GrahamDumpleton/secrets-of-a-wsgi-master\" target=\"_blank\" style=\"color: inherit;\">which keep Python process(es) on the go for you.</a></p><h4>What about other Python runtimes?</h4><p><a href=\"http://doc.pypy.org/en/latest/faq.html#does-pypy-have-a-gil-why\" target=\"_blank\" style=\"color: inherit;\">PyPy has a GIL</a>&nbsp;and it is typically &gt;3x faster than CPython.</p><p><a href=\"http://www.jython.org/jythonbook/en/1.0/Concurrency.html#no-global-interpreter-lock\" target=\"_blank\" style=\"color: inherit;\">Jython does not have a GIL</a>&nbsp;because a Python thread in Jython is represented by a Java thread and benefits from the JVM memory-management system.</p><p><br></p><h4>How does JavaScript do&nbsp;this?</h4><p>Well, firstly all Javascript engines&nbsp;<a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management\" target=\"_blank\" style=\"color: inherit;\">use mark-and-sweep Garbage Collection</a>. As stated, the primary need for the GIL is CPython’s memory-management algorithm.</p><p>JavaScript does not have a GIL, but it’s also&nbsp;<strong>single</strong>-threaded so it doesn’t require one. JavaScript’s event-loop and Promise/Callback pattern are how asynchronous-programming is achieved in place of concurrency. Python has a similar thing with the asyncio event-loop.</p><p><br></p><h3>“It’s because its an interpreted language”</h3><p>I hear this a lot and I find it a gross-simplification of the way CPython actually works. If at a terminal you wrote&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">python myscript.py</code>&nbsp;then CPython would start a long sequence of reading, lexing, parsing, compiling, interpreting and executing that code.</p><p><br></p><p>If you’re interested in how that process works, I’ve written about it before:</p><p><a href=\"https://hackernoon.com/modifying-the-python-language-in-7-minutes-b94b0a99ce14\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.9);\">Modifying the Python language in 6 minutes</a></p><p><a href=\"https://hackernoon.com/modifying-the-python-language-in-7-minutes-b94b0a99ce14\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.68);\">This week I raised my first pull-request to the CPython core project, which was declined&nbsp;:-( but as to not completely…</a></p><p><br></p><p>An important point in that process is the creation of a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">.pyc</code>&nbsp;file, at the compiler stage, the bytecode sequence is written to a file inside&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">__pycache__/</code>on Python 3 or in the same directory in Python 2. This doesn’t just apply to your script, but all of the code you imported, including 3rd party modules.</p><p>So most of the time (unless you write code which you only ever run once?), Python is interpreting bytecode and executing it locally. Compare that with Java and C#.NET:</p><blockquote><em>Java compiles to an “Intermediate Language” and the Java Virtual Machine reads the bytecode and&nbsp;</em><strong><em>just-in-time</em></strong><em>&nbsp;compiles it to machine code. The&nbsp;.NET CIL is the same, the&nbsp;.NET Common-Language-Runtime, CLR, uses just-in-time compilation to machine code.</em></blockquote><p>So, why is Python so much slower than both Java and C# in the benchmarks if they all use a virtual machine and some sort of Bytecode? Firstly,&nbsp;.NET and Java are JIT-Compiled.</p><p><br></p><p>JIT or Just-in-time compilation requires an intermediate language to allow the code to be split into chunks (or frames). Ahead of time (AOT) compilers are designed to ensure that the CPU can understand every line in the code before any interaction takes place.</p><p>The JIT itself does not make the execution any faster, because it is still executing the same bytecode sequences. However, JIT enables optimizations to be made at runtime. A good JIT optimizer will see which parts of the application are being executed a lot, call these “hot spots”. It will then make optimizations to those bits of code, by replacing them with more efficient versions.</p><p>This means that when your application does the same thing again and again, it can be significantly faster. Also, keep in mind that Java and C# are strongly-typed languages so the optimiser can make many more assumptions about the code.</p><p><strong>PyPy has a JIT</strong>&nbsp;and as mentioned in the previous section, is significantly faster than CPython. This performance benchmark article goes into more detail —</p><p><a href=\"https://hackernoon.com/which-is-the-fastest-version-of-python-2ae7c61a6b2b\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.9);\">Which is the fastest version of Python?</a></p><p><br></p><p><a href=\"https://hackernoon.com/which-is-the-fastest-version-of-python-2ae7c61a6b2b\" target=\"_blank\" style=\"background-color: rgba(255, 255, 255, 0); color: rgba(0, 0, 0, 0.68);\">Of course, “it depends”, but what does it depend on and how can you assess which is the fastest version of Python for…</a></p><p><a href=\"https://hackernoon.com/which-is-the-fastest-version-of-python-2ae7c61a6b2b\" target=\"_blank\" style=\"color: inherit; background-color: rgba(255, 255, 255, 0);\">hackernoon.com</a></p><h4>So why doesn’t CPython use a&nbsp;JIT?</h4><p>There are downsides to JITs: one of those is startup time. CPython startup time is already comparatively slow, PyPy is 2–3x slower to start than CPython. The Java Virtual Machine is notoriously slow to boot. The&nbsp;.NET CLR gets around this by starting at system-startup, but the developers of the CLR also develop the Operating System on which the CLR runs.</p><p><br></p><p>If you have a single Python process running for a long time, with code that can be optimized because it contains “hot spots”, then a JIT makes a lot of sense.</p><p>However, CPython is a&nbsp;<strong>general-purpose</strong>&nbsp;implementation. So if you were developing command-line applications using Python, having to wait for a JIT to start every time the CLI was called would be horribly slow.</p><p>CPython has to try and serve as many use cases as possible. There was the possibility of&nbsp;<a href=\"https://www.slideshare.net/AnthonyShaw5/pyjion-a-jit-extension-system-for-cpython\" target=\"_blank\" style=\"color: inherit;\">plugging a JIT into CPython</a>&nbsp;but this project has largely stalled.</p><blockquote><em>If you want the benefits of a JIT and you have a workload that suits it, use&nbsp;PyPy.</em></blockquote><h3><br></h3><h3>“It’s because its a dynamically typed language”</h3><p>In a “Statically-Typed” language, you have to specify the type of a variable when it is declared. Those would include C, C++, Java, C#, Go.</p><p><br></p><p>In a dynamically-typed language, there are still the concept of types, but the type of a variable is dynamic.</p><pre class=\"ql-syntax\" spellcheck=\"false\"><span class=\"hljs-attr\">a</span> = <span class=\"hljs-number\">1</span> <span class=\"hljs-attr\">a</span> = <span class=\"hljs-string\">\"foo\"</span> </pre><p>In this toy-example, Python creates a second variable with the same name and a type of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">str</code>&nbsp;and deallocates the memory created for the first instance of&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">a</code></p><p>Statically-typed languages aren’t designed as such to make your life hard, they are designed that way because of the way the CPU operates. If everything eventually needs to equate to a simple binary operation, you have to convert objects and types down to a low-level data structure.</p><p>Python does this for you, you just never see it, nor do you need to care.</p><p>Not having to declare the type isn’t what makes Python slow, the design of the Python language enables you to make almost anything dynamic. You can replace the methods on objects at runtime, you can monkey-patch low-level system calls to a value declared at runtime. Almost anything is possible.</p><p>It’s this design that makes it&nbsp;<strong>incredibly hard</strong>&nbsp;to optimise Python.</p><p>To illustrate my point, I’m going to use a syscall tracing tool that works in Mac OS called Dtrace. CPython distributions do not come with DTrace builtin, so you have to recompile CPython. I’m using 3.6.6 for my demo</p><p><br></p><pre class=\"ql-syntax\" spellcheck=\"false\">wget https:<span class=\"hljs-comment\">//github.com/python/cpython/archive/v3.6.6.zip</span> unzip v3<span class=\"hljs-number\">.6.6</span>.zip cd v3<span class=\"hljs-number\">.6.6</span> ./configure --<span class=\"hljs-keyword\">with</span>-dtrace make </pre><p>Now&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">python.exe</code>&nbsp;will have Dtrace tracers throughout the code.&nbsp;<a href=\"https://github.com/paulross/dtrace-py#the-lightning-talk\" target=\"_blank\" style=\"color: inherit;\">Paul Ross wrote an awesome Lightning Talk on Dtrace</a>. You can&nbsp;<a href=\"https://github.com/paulross/dtrace-py/tree/master/toolkit\" target=\"_blank\" style=\"color: inherit;\">download DTrace starter files</a>&nbsp;for Python to measure function calls, execution time, CPU time, syscalls, all sorts of fun. e.g.</p><p><code style=\"background-color: rgba(0, 0, 0, 0.05);\">sudo dtrace -s toolkit/&lt;tracer&gt;.d -c ‘../cpython/python.exe script.py’</code></p><p>The&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">py_callflow</code>&nbsp;tracer shows all the function calls in your application</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*Lz4UdUi4EwknJ0IcpSJ52g.gif\"></p><p>So, does Python’s dynamic typing make it slow?</p><ul><li>Comparing and converting types is costly, every time a variable is read, written to or referenced the type is checked</li><li>It is hard to optimise a language that is so dynamic. The reason many alternatives to Python are so much faster is that they make compromises to flexibility in the name of performance</li><li>Looking at&nbsp;<a href=\"http://cython.org/\" target=\"_blank\" style=\"color: inherit;\">Cython</a>, which combines C-Static Types and Python to optimise code where the types are known<a href=\"http://notes-on-cython.readthedocs.io/en/latest/std_dev.html\" target=\"_blank\" style=\"color: inherit;\">&nbsp;can provide&nbsp;</a>an&nbsp;<strong>84x performance</strong>improvement.</li></ul><p><br></p><h3>Conclusion</h3><blockquote><em>Python is primarily slow because of its dynamic nature and versatility. It can be used as a tool for all sorts of problems, where more optimised and faster alternatives are probably available.</em></blockquote><p>There are, however, ways of optimising your Python applications by leveraging async, understanding the profiling tools, and consider using multiple-interpreters.</p><p>For applications where startup time is unimportant and the code would benefit a JIT, consider PyPy.</p><p><br></p><h4><span style=\"background-color: transparent;\">For parts of your code where performance is critical and you have more statically-typed variables, consider using&nbsp;</span><a href=\"http://cython.org/\" target=\"_blank\" style=\"background-color: transparent; color: inherit;\">Cython</a><span style=\"background-color: transparent;\">.</span></h4>",
        "topic": "Programming",
        "comments": [],
        "dateposted": "July 22, 2018",
        "id": 3
    },
    {
        "title": "People Who Have “Too Many Interests” Are More Likely To Be Successful According To Research",
        "image": "https://saghen.com/uploads/polymath.jpeg",
        "author": "Eric Dyer",
        "length": "31 mins",
        "previewcontent": "If being a generalist was the path to mediocrity, why did the most comprehensive study of the most significant scientists in all of history uncover that 15 of the 20 were polymaths? Newton. Galileo. Aristotle. Kepler. Descartes. Huygens. Laplace. Faraday. Pasteur. Ptolemy. Hooke. Leibniz. Euler. Darwin. Maxwell — all polymaths.",
        "content": "<p><strong>The most comprehensive case that has ever been made for why nearly everyone should become a polymath in a modern knowledge economy.</strong></p><blockquote><em>“Jack of all trades, master of&nbsp;none.”</em></blockquote><p>The warning against being a generalist has persisted for&nbsp;<a href=\"http://snip.ly/rrLW\" target=\"_blank\" style=\"color: inherit;\">hundreds of years in dozens of languages</a>. “Equipped with knives all over, yet none is sharp,” warn people in China. In Estonia, it goes, “Nine trades, the tenth one — hunger.”</p><p>Yet, many of the most impactful individuals&nbsp;, both contemporary and historical, have been generalists: Elon Musk, Steve Jobs, Richard Feynman, Ben Franklin, Thomas Edison, Leonardo Da Vinci, and Marie Curie to name just a few.</p><p><br></p><p>What’s going on here?</p><p>If being a generalist was the path to mediocrity, why did the most&nbsp;<a href=\"https://amzn.to/2GGPOtw\" target=\"_blank\" style=\"color: inherit;\">comprehensive study</a>&nbsp;of the most significant scientists in all of history uncover that 15 of the 20 were polymaths? Newton. Galileo. Aristotle. Kepler. Descartes. Huygens. Laplace. Faraday. Pasteur. Ptolemy. Hooke. Leibniz. Euler. Darwin. Maxwell — all polymaths.</p><p>If being a generalist was so ineffective, why are the founders of the five largest companies in the world — Bill Gates, Steve Jobs, Warren Buffett, Larry Page, and Jeff Bezos — all polymaths (<a href=\"https://medium.com/the-mission/the-5-hour-rule-if-youre-not-spending-5-hours-per-week-learning-you-re-being-irresponsible-791c3f18f5e6\" target=\"_blank\" style=\"color: inherit;\">who also follow the 5-hour rule</a>)? Are these legends just genius anomalies? Or are they people we could and should imitate in order to be successful in a modern knowledge economy?</p><p>If being a generalist is an ineffective career path, why do&nbsp;<a href=\"https://www.researchgate.net/profile/Robert_Root-Bernstein/publication/226640428_Multiple_Giftedness_in_Adults_The_Case_of_Polymaths/links/00b7d5272912c07169000000/Multiple-Giftedness-in-Adults-The-Case-of-Polymaths.pdf\" target=\"_blank\" style=\"color: inherit;\">10+ academic studies</a>&nbsp;find a correlation between the number of interests/competencies someone develops and their creative impact?</p><p><br></p><h3>The Era of the Modern&nbsp;Polymath</h3><blockquote><em>“The future belongs to the integrators.” — Educator Ernest&nbsp;Boyer</em></blockquote><p><strong style=\"background-color: transparent;\">I define a modern polymath is someone who becomes competent in at least three diverse domains and integrates them into a top 1-percent skill set.</strong></p><p>In another words, they bring the best of what humanity has discovered from across fields to help them be more effective in their core field. Hence the T-shape below. Specialists, on the other hand, just focus on knowledge from their own field.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/600/0*ZkBqv5AXfSXNH8Au.\"></p><p>Since Malcolm Gladwell’s book,&nbsp;<em>Outliers</em>, popularized the concept, many now believe that to become world-class in a skill, they must complete 10,000 hours of deliberate practice in order to beat the competition, going as deep as possible into one field. Modern polymaths go against the grain of this popular advice, building atypical combinations of skills and knowledge&nbsp;<em>across</em>&nbsp;fields and then integrating them to create breakthrough ideas and even brand new fields and industries where there is&nbsp;<em>little competition</em>.</p><p>For example, people have studied biology and sociology for hundreds of years. But no one had ever studied them together and synthesized them into a new discipline until researcher EO Wilson pioneered the field of sociobiology in the 1970s. We also have modern tech heroes like Steve Jobs (<a href=\"https://medium.com/the-mission/the-number-one-predictor-of-career-success-according-to-network-science\" target=\"_blank\" style=\"color: inherit;\">who I write about here</a>) who famously combined design with hardware and software.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/600/1*5vrZstJtHDkfz2TxfnAI_A.png\"></p><p>Elon Musk (<a href=\"https://medium.com/@michaeldsimmons/how-elon-musk-learns-faster-and-better-than-everyone-else-a010a4f586ef\" target=\"_blank\" style=\"color: inherit;\">who I write about here</a>) has combined an understanding of physics, engineering, programming, design, manufacturing, and business to create several multibillion-dollar companies in completely different fields. He not only makes atypical combinations of skills, he also makes atypical combinations of personality traits.</p><p>Charles Darwin, creator of one of the most important theories in history — the theory of evolution — was a polymath too. Steven Johnson, author of&nbsp;<a href=\"http://amzn.to/2G6JxVy\" target=\"_blank\" style=\"color: inherit;\">Where Good Ideas Come From</a>&nbsp;(one of my top five favorite books of all-time), brilliantly describes Darwin’s first scientific breakthrough:</p><blockquote><em>The idea itself drew on a coffeehouse of different disciplines: to solve the mystery, he had to think like a naturalist, a marine biologist, and a geologist all at once. He had to understand the life cycle of coral colonies, and observe the tiny evidence of organic sculpture on the rocks of the Keeling Islands; he had to think on the immense time scales of volcanic mountains rising and falling into the sea… To understand the idea in its full complexity required a kind of probing intelligence, willing to think across those different disciplines and scales.</em></blockquote><p>A more everyday example is my longtime friend Elizabeth Saunders. Elizabeth combined her passions for writing, Christianity, and time management into a thriving coaching business based on principles of Christianity that she promotes&nbsp;<a href=\"https://www.amazon.com/Divine-Time-Management-Trusting-Loving/dp/1478974362\" target=\"_blank\" style=\"color: inherit;\">through books and articles</a>. There is a whole cottage industry around time management, but there are almost no resources on divine time management.</p><p>In order to become an effective online writer, I’ve deliberately combined academic research, digital journalism, and growth hacking into one skillset. I didn’t go to college for any of these skills, but practiced them over time and received coaching on them. My observation is that academics often look down on journalists; journalists look down on marketers; and marketers look down on journalists and academics. What many fail to see is that each brings something valuable to the table and that all of these skills combined lead to great ideas seen by large audiences.</p><p><br></p><h3>Why Being A Modern Polymath Is The New&nbsp;Normal</h3><blockquote><em>“Study the science of art. Study the art of science. Develop your senses — especially learn how to see. Realize that everything connects to everything else.”</em></blockquote><blockquote><em>— Leonardo Da&nbsp;Vinci</em></blockquote><p>Polymaths have existed forever — indeed they are often the ones who’ve advanced Western civilization more than any others — but they’ve been called different things throughout history. This timeline shows the evolution over time.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/0*1ICacI1xzTAWU8lW.\"></p><p>But is this a recipe that most people should follow?</p><p>There are several significant changes trending in our knowledge economy right now, which are flipping the conventional wisdom on the value of specialization on its head. In today’s world, diverse interests are not a curse, they’re a blessing. Being a polymath instead of a specialist is an advantage, not a weakness.</p><p>People who love learning across fields can use that tendency to be more financially successful and impactful in their career.</p><p>What follows is the most comprehensive case for becoming a polymath that has ever been created to my knowledge. Then, at the end of the article, I share a resource with you that will help you become a successful polymath.</p><h3>Polymath Advantage 1: Creating an atypical combination of two or more skills that you’re merely competent can lead to a world-class skill&nbsp;set.</h3><p>Scott Adams, the creator of Dilbert, one of the most popular comic strips of all time, wasn’t the funniest person in the world. He wasn’t the best cartoonist in the world, and he wasn’t the most experienced employee (he was only in his 20s when he started Dilbert). But by combining his humor and illustration skills while focusing on business culture, he became the best in the world in his niche. In an insightful blog post,&nbsp;<a href=\"http://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html\" target=\"_blank\" style=\"color: inherit;\">he nails how he did it</a>&nbsp;and how you can too:</p><p><br></p><blockquote><em>If you want something extraordinary [in life], you have two paths:</em></blockquote><blockquote><em>1. Become the best at one specific thing.</em></blockquote><blockquote><em>2. Become very good (top 25%) at two or more things.</em></blockquote><blockquote><em>The first strategy is difficult to the point of near impossibility. Few people will ever play in the NBA or make a platinum album. I don’t recommend anyone even try.</em></blockquote><blockquote><em>The second strategy is fairly easy. Everyone has at least a few areas in which they could be in the top 25% with some effort. In my case, I can draw better than most people, but I’m hardly an artist. And I’m not any funnier than the average standup comedian who never makes it big, but I’m funnier than most people. The magic is that few people can draw well and write jokes. It’s the combination of the two that makes what I do so rare. And when you add in my business background, suddenly I had a topic that few cartoonists could hope to understand without living it.</em></blockquote><p><br></p><h3>Polymath Advantage 2: Most creative breakthroughs come via making atypical combinations of&nbsp;skills.</h3><p>We can see the power of atypical combinations when we look back at the most influential papers throughout the history of science. Researcher Brian Uzzi, a professor at the Northwestern University Kellogg School of Management, analyzed more than 26 million scientific papers going back hundreds of years and found that the most impactful papers&nbsp;<a href=\"http://www.kellogg.northwestern.edu/faculty/uzzi/htm/papers/Science-2013-Uzzi-468-72.pdf\" target=\"_blank\" style=\"color: inherit;\">often have teams with atypical combinations of backgrounds</a>. In&nbsp;<a href=\"https://insight.kellogg.northwestern.edu/article/a_virtuous_mix_allows_innovation_to_thrive\" target=\"_blank\" style=\"color: inherit;\">another comprehensive study</a>&nbsp;performed by Uzzi, he compared the results of academic papers by the number of citations they received and the other papers they cited. A fascinating pattern emerged. The top performing studies cited atypical combinations of other studies (90 percent conventional citations from their own field and 10 percent from other fields).</p><p><br></p><h3>Polymath Advantage 3: It’s easier and faster than ever to become competent in a new&nbsp;skill.</h3><p>Want to learn a new, valuable skill to add to your toolbox? It’s never been easier:</p><ol><li><strong>The quality of knowledge in every domain is improving.&nbsp;</strong>Researchers and practitioners are systematically improving and testing every field of knowledge to make it more robust. Cumulatively, old fallacious ideas are being discredited and new ideas are being added. The technology field is smarter than it was 20 years ago, for example. So are the fields of physics and biology.</li><li><strong>Second, there is an abundance of free or affordable content from the world’s top experts in every medium you can think of.</strong>&nbsp;Need a community and expert coaching? There are now hundreds of thousands of online courses and billions of online videos. This is the golden era for people who value learning, are willing to invest in themselves, and who are disciplined enough to take action on their own.</li></ol><p><br></p><p>My favorite example of high-quality, easy-to-access knowledge is a 12-year-old girl named&nbsp;<a href=\"https://www.youtube.com/watch?v=OgzdDp5qfdI\" target=\"_blank\" style=\"color: inherit;\">Adilyn Malcolm</a>, who learned how to dubstep dance in a matter of months by constantly watching short clips of others online, practicing, and repeating until she mastered each segment and could perform an entire dance flawlessly.</p><p><br></p><iframe class=\"ql-video\" frameborder=\"0\" allowfullscreen=\"true\" src=\"https://www.youtube.com/embed/OgzdDp5qfdI\"></iframe><p><br></p><p>Imagine Adilyn trying to learn how dubstep before Youtube. There probably wouldn’t have been a local dance studio that specialized in dubstep. If one did, the teacher likely would not have been world-class. Next, Adilyn wouldn’t have been able to obsessively spend hours learning about it. If any dubstep videos did exist, she would’ve had to convince her parents to spend $20 a piece on them. YouTube, on the other hand, provided Adilyn with a chance to learn from many world-class teachers and performers at no cost and on her own schedule. Today, a search on Youtube for “learn dubstep”&nbsp;<a href=\"https://www.youtube.com/results?search_query=learn+dubstep\" target=\"_blank\" style=\"color: inherit;\">returns over 1 million results</a>!</p><p>And if that’s not impressive enough, consider 13-year-old&nbsp;<a href=\"https://www.youtube.com/watch?v=mmQG_BCiVHU\" target=\"_blank\" style=\"color: inherit;\">Michael Sayman</a>. He taught himself how to code via Google. One of his mobile games became one of the top 100 apps in the world, beating out Starbucks and Yelp. Or watch 11-year-old&nbsp;<a href=\"https://www.youtube.com/watch?v=UJ3u5w9NYjQ\" target=\"_blank\" style=\"color: inherit;\">Amira Willighagen</a>&nbsp;masterfully sing opera after teaching herself with YouTube videos for four years. Something big is happening here, and these young prodigies are the harbingers of it.</p><p>As Isaac Newton famously proclaimed, “If I have seen further it is by standing on the shoulders of giants.” In today’s era, we have more shoulders to stand on than ever.</p><p><br></p><h3>Polymath Advantage 4: It’s easier than ever to pioneer a new field, industry, or skill&nbsp;set.</h3><p>While the explosion of knowledge is making it impossible or at least more difficult for anyone to know everything, it has also made it easier to find one big, atypical combination of fields or skills. It’s easier than ever to be a polymath. Here’s why:</p><p>First, one of the main ways that new skill sets, industries, and fields emerge is by combining them with old ones:</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*xbeu5OFSq1Ehsozr6EeIng.png\"></p><p>Second, the&nbsp;<a href=\"http://blogs.nature.com/news/2014/05/global-scientific-output-doubles-every-nine-years.html\" target=\"_blank\" style=\"color: inherit;\">number of new academic fields</a>&nbsp;and business industries is increasing exponentially.</p><p>And finally, as the number of new skills increases, the number of possible combinations increases exponentially. Every new chunk of knowledge can theoretically be combined with every other knowledge chunk. Every new breakthrough creates the potential for exponentially more breakthroughs.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/0*SwYJtk6lCpZ43WsE.\"></p><p>If you have one building block (A), you can only make one combination (A). If you have two (A &amp; B), then you can make three combinations (A, B, A+B). Once you get to four building blocks, you get to 15 possible combinations, and the numbers grow dramatically from there. Now consider that there are thousands and thousands of disciplines, industries, and skills. Each new one creates the potential for tens of thousands more.</p><p>Below are a few of the many thousands of fields that were created very recently through combination:</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*lgh7uSPmVeVa8AlUgox6Xg.png\"></p><p><strong>Bottom line:&nbsp;</strong>when I was in high school, I remember&nbsp;<a href=\"http://amzn.to/2FOp4Uq\" target=\"_blank\" style=\"color: inherit;\">reading</a>&nbsp;how a young Leonardo Da Vinci was frustrated that he was born in a period where everything worth being discovered had already been discovered. This quote stuck with me, because it was written by one of the greatest inventors in human history. It’s helpful for us to remember Da Vinci’s quote, because it’s just as true today. Almost ALL of the potential discovery that humanity will do is in the future.</p><p><br></p><h3>Polymath Advantage 5: It future-proofs Your&nbsp;career.</h3><blockquote><em>“It is not the strongest or the most intelligent who will survive but those who can best manage change.” -Charles&nbsp;Darwin</em></blockquote><p>What do the following six professions have in common?</p><ol><li>App developer</li><li>Social media manager</li><li>Driverless car engineer</li><li>Cloud computing specialist</li><li>Big data scientist</li><li>YouTube content creator</li></ol><p>Answer: None of them existed 15 years ago. Imagine the power you’d have if you could go back in time, master these skills, and then be one of the best in the world at them when they hit big? We actually don’t have to guess. You’d stand a good chance of being a millionaire. The headline below shows just how valuable a driverless car engineer is.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/0*SxtWh_5wtrHItFvW.\"></p><p>So what skills are going to be valuable in 20 years? Do you know?</p><p>No? Neither do I. Neither does anybody.</p><p>So the question arises, how do we make investments in knowledge now that will pay off far into the future?</p><p>I’d make the case that a polymath is much better positioned than a specialist. A polymath can take the skills that she or he has learned and combine them in new ways quickly to master new fields. On the other hand, a specialist whose fields becomes obsolete would likely take much more time to adapt to the change and have to start back at the beginning.</p><p>In an environment of accelerating change, we’re going to have to become polymaths to survive. We’re going to have a dozen careers. Each one is going to require new skills.</p><p><br></p><h3>Polymath Advantage 6: It sets you up to solve more complex problems.</h3><p>Many of the largest problems that face society and individuals benefit from solutions that integrate multiple disciplines.</p><p>Let’s take obesity as an example. As the chart below shows, diet and obesity account for four out of the top fifteen causes of death in the United States. Millions of deaths that are completely preventable.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/0*azW0XeVLvI0hnl8c.\"></p><p>From the outside, you could easily say that solving the obesity crisis is an easy problem. Just eat less and exercise more. Right? Not quite.</p><p>The chart below from the&nbsp;<a href=\"https://www.amazon.com/Diversity-Bonus-Knowledge-Compelling-Interests/dp/0691176884/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=1515502694&amp;sr=8-1\" target=\"_blank\" style=\"color: inherit;\">Diversity Bonus</a>&nbsp;book by researcher Scott Page shows a portion of just how complex the obesity epidemic is. As you can see, many different fields are needed to solve this problem: exercise physiology, genetics, behavioral psychology, sociology, economics, marketing, general psychology, education system, nutrition.</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/0*BsJg1QQn4eXc5Wj4.\"></p><p><br></p><h3>Polymath Advantage 7: It helps you stand out and compete in the global&nbsp;economy.</h3><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/0*VLhNxbX8C8VG9PHa.\"></p><p>One of the most fundamental mental models from economics is supply and demand (<a href=\"http://www.mentalmodelclub.com/\" target=\"_blank\" style=\"color: inherit;\">see more valuable mental models</a>). It’s relevant to the job market, to goods and services, to the world of ideas, and to many other places.</p><p>In this model, there are two ways to increase how much of a price premium you command:</p><ol><li>Decrease the supply (move the blue curve to the left).</li><li>Increase the demand (move the red curve to the right).</li></ol><p>You can have the most valuable skill set in the world, but if everyone also has that skill set, then you’re a commodity.&nbsp;<strong>By becoming a polymath and developing a unique skill set that few others have, then you’ll be able to differentiate yourself and charge more.</strong></p><p>Want a quick test to see if you have rare and valuable knowledge? Then ask yourself the same question that self-made billionaire Peter Thiel, one of the top investors in Silicon Valley, asks candidates he might hire and founders he might fund, “What’s the one thing you believe is true that no one else agrees with you on?” This simple question very quickly tells you whether or not you have rare and valuable ideas. If you can’t come up with anything, it tells you that you might not be as an original thinker as thought you were.</p><p>This mental model is widely shared among the world’s top investors and performers as the following quotes demonstrate:</p><p><em>“You want to be greedy when others are fearful. You want to be fearful when others are greedy. It’s that simple.” — Warren Buffett, founder of Berkshire Hathaway</em></p><p><em>“In order to get into the top of the performance distribution, you have to escape from the crowd.” — Howard Marks, founder of Oaktree Capital ($2+ billion net worth)</em></p><p><em>“You can’t make money agreeing with the consensus view.” — Ray Dalio, founder of Bridgewater Associates (largest hedge fund in the world)</em></p><p><em>“The best projects are likely to be overlooked, not trumpeted by a crowd; the best problems to work on are often the ones nobody else even tries to solve.” — Peter Thiel, founder of PayPal and billionaire investor ($3.3 billion net worth)</em></p><p><em>“You have to be odd to be number 1.” -Dr. Seuss</em></p><p><em>The weakness of an art is its dogma. And when I’m competing against an individual from a different discipline, I try to find the dogma of that discipline. When I’m competing with someone within a discipline, I try to find their personal dogma. — Josh Waitzkin, Chess Grandmaster &amp; World Tai Chi Champion</em></p><p><br></p><h3>Bottom Line: Make Yourself Anti-Fragile</h3><p>Being a polymath will be the new normal, and polymaths who synthesize diverse skills to create breakthrough innovations and solve complex problems will have a huge impact. Generalists who fail to synthesize their knowledge into value for others stand to flounder in their career, perhaps having an impressive encyclopedic knowledge, but no real impact.</p><p><br></p><p>Meanwhile, specialists risk getting trapped by their success. They build up a narrow skill set and reputation and become highly paid for it. But their careers are fragile. As their professions disappear or evolve, it becomes almost impossible to switch without having to start over.</p><p>Polymaths, on the other hand, are what Nassim Taleb calls “anti-fragile.” Changes to the environment make them stronger. As new paradigms of business emerge or their passions grow, they can quickly combine their existing skill sets in a myriad of ways.</p><p>Now that you see how important it is to become a modern polymath, the next logical question is: how?</p><p>I created a resource to help you with just that…</p><p><br></p><h3>How To Become a Modern&nbsp;Polymath</h3><blockquote><em>“The greatest scientists are artists as well.” — Einstein</em></blockquote><p>The idea of becoming a modern polymath can be overwhelming. Where do you start? What field do you learn first? How do you find the time? How do you translate what you learn into real world value?”</p><p>When I first started learning across fields, I stumbled. I remember, for example, picking up textbook on biology, which I hadn’t studied since high school, and trying to apply it to my life. It was slow and not that useful. In other words, I picked the wrong discipline (for me) to start with, and I used the wrong method to learn it. After a lot of trial and error, I learned techniques that make going across fields faster and easier</p><p>During the hundreds of hours I’ve spent researching how to be a polymath and interviewing polymaths, one key that I’ve discovered is mental models.</p><p>First, mental models transcend disciplines. They are the invisible links that connect disciplines together:</p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*C0F66T0B3dbodXSvdQuhVg.png\"></p><p>For example, once you learn the “80/20 Rule,” which states that, in many domains, 20 percent of your efforts produce 80 percent of your results, you can use this mental model to improve efficiency and impact in every area of your life as well as every field you study forever. You can identify the 20% of relationships that cause 80% of your feeling of connection. You can identify the 20% of clients that create 80% of your business. You can identify the 20% of tasks that create 80% of your productivity. And so on!</p><p>Furthermore, mental models help you learn multiple skills much more quickly, because they gave your a stable base of useful and universal knowledge that you can use for the rest of your life. Therefore, when you go into any new discipline, even though you may not have direct experience with that field, you’ll quickly notice mental models you can use.</p><p>In short,&nbsp;<a href=\"https://medium.com/the-mission/this-is-exactly-how-you-should-train-yourself-to-be-smarter-infographic-86d0d42ad41c\" target=\"_blank\" style=\"color: inherit;\">mental models are key to becoming a better polymath</a>.</p>",
        "topic": "Psychology and Learning",
        "comments": [],
        "dateposted": "July 21, 2018",
        "id": 2
    },
    {
        "title": "How it feels to learn JavaScript in 2016",
        "image": "https://saghen.com/uploads/javascript-in-2016.png",
        "author": "Eric Dyer",
        "length": "25 mins",
        "previewcontent": "The following is inspired by the article “It’s the future” from Circle CI. You can read the original here. This piece is just an opinion, and like any JavaScript framework, it shouldn’t be taken too seriously.",
        "content": "<p><em>No JavaScript frameworks were created during the writing of this article.</em></p><p><em>The following is inspired by the article “It’s the future” from Circle CI. You can read the original&nbsp;</em><a href=\"https://circleci.com/blog/its-the-future/\" target=\"_blank\" style=\"color: inherit;\"><em>here</em></a><em>. This piece is just an opinion, and like any JavaScript framework, it shouldn’t be taken too seriously.</em></p><p>Hey, I got this new web project, but to be honest I haven’t coded much web in a few years and I’ve heard the landscape changed a bit. You are the most up-to date web dev around here right?</p><p><em>-The actual term is Front End engineer, but yeah, I’m the right guy. I do web in 2016. Visualisations, music players, flying drones that play football, you name it. I just came back from JsConf and ReactConf, so I know the latest technologies to create web apps.</em></p><p>Cool. I need to create a page that displays the latest activity from the users, so I just need to get the data from the REST endpoint and display it in some sort of filterable table, and update it if anything changes in the server. I was thinking maybe using jQuery to fetch and display the data?</p><p><em>-Oh my god no, no one uses jQuery anymore. You should try learning React, it’s 2016.</em></p><p>Oh, OK. What’s React?</p><p><em>-It’s a super cool library made by some guys at Facebook, it really brings control and performance to your application, by allowing you to handle any view changes very easily.</em></p><p>That sounds neat. Can I use React to display data from the server?</p><p><em>-Yeah, but first you need to add React and React DOM as a library in your webpage.</em></p><p>Wait, why two libraries?</p><p><em>-So one is the actual library and the second one is for manipulating the DOM, which now you can describe in JSX.</em></p><p>JSX? What is JSX?</p><p><em>-JSX is just a JavaScript syntax extension that looks pretty much like XML. It’s kind of another way to describe the DOM, think of it as a better HTML.</em></p><p>What’s wrong with HTML?</p><p><em>-It’s 2016. No one codes HTML directly anymore.</em></p><p>Right. Anyway, if I add these two libraries then I can use React?</p><p><em>-Not quite. You need to add Babel, and then you are able to use React.</em></p><p>Another library? What’s Babel?</p><p><em>-Oh, Babel is a transpiler that allows you to target specific versions of JavaScript, while you code in any version of JavaScript. You don’t HAVE to include Babel to use ReactJS, but unless you do, you are stuck with using ES5, and let’s be real, it’s 2016, you should be coding in ES2016+ like the rest of the cool kids do.</em></p><p>ES5? ES2016+? I’m getting lost over here. What’s ES5 and ES2016+?</p><p><em>-ES5 stands for ECMAScript 5. It’s the edition that has most people target since it has been implemented by most browsers nowadays.</em></p><p>ECMAScript?</p><p><em>-Yes, you know, the scripting standard JavaScript was based on in 1999 after its initial release in 1995, back then when JavaScript was named Livescript and only ran in the Netscape Navigator. That was very messy back then, but thankfully now things are very clear and we have, like, 7 editions of this implementation.</em></p><p>7 editions. For real. And ES5 and ES2016+ are?</p><p><em>-The fifth and seventh edition respectively.</em></p><p>Wait, what happened with the sixth?</p><p><em>-You mean ES6? Yeah, I mean, each edition is a superset of the previous one, so if you are using ES2016+, you are using all the features of the previous versions.</em></p><p>Right. And why use ES2016+ over ES6 then?</p><p><em>-Well, you COULD use ES6, but to use cool features like async and await, you need to use ES2016+. Otherwise you are stuck with ES6 generators with coroutines to block asynchronous calls for proper control flow.</em></p><p>I have no idea what you just said, and all these names are confusing. Look, I’m just loading a bunch of data from a server, I used to be able to just include jQuery from a CDN and just get the data with AJAX calls, why can’t I just do that?</p><p><em>-It’s 2016 man, no one uses jQuery anymore, it ends up in a bunch of spaghetti code. Everyone knows that.</em></p><p>Right. So my alternative is to load three libraries to fetch data and display a HTML table.</p><p><em>-Well, you include those three libraries but bundle them up with a module manager to load only one file.</em></p><p>I see. And what’s a module manager?</p><p><em>-The definition depends on the environment, but in the web we usually mean anything that supports AMD or CommonJS modules.</em></p><p>Riiight. And AMD and CommonJS are…?</p><p><em>-Definitions. There are ways to describe how multiple JavaScript libraries and classes should interact. You know, exports and requires? You can write multiple JavaScript files defining the AMD or CommonJS API and you can use something like Browserify to bundle them up.</em></p><p>OK, that makes sense… I think. What is Browserify?</p><p><em>-It’s a tool that allows you to bundle CommonJS described dependencies to files that can be run in the browser. It was created because most people publish those dependencies in the npm registry.</em></p><p>npm registry?</p><p><em>-It’s a very big public repository where smart people put code and dependencies as modules.</em></p><p>Like a CDN?</p><p><em>-Not really. It’s more like a centralised database where anyone can publish and download libraries, so you can use them locally for development and then upload them to a CDN if you want to.</em></p><p>Oh, like Bower!</p><p><em>-Yes, but it’s 2016 now, no one uses Bower anymore.</em></p><p>Oh, I see… so I need to download the libraries from npm then?</p><p><em>-Yes. So for instance, if you want to use React&nbsp;, you download the React module and import it in your code. You can do that for almost every popular JavaScript library.</em></p><p>Oh, like Angular!</p><p><em>-Angular is so 2015. But yes. Angular would be there, alongside VueJS or RxJS and other cool 2016 libraries. Want to learn about those?</em></p><p>Let’s stick with React, I’m already learning too many things now. So, if I need to use React I fetch it from this npm and then use this Browserify thing?</p><p><em>-Yes.</em></p><p>That seems overly complicated to just grab a bunch of dependencies and tie them together.</p><p><em>-It is, that’s why you use a task manager like Grunt or Gulp or Broccoli to automate running Browserify. Heck, you can even use Mimosa.</em></p><p>Grunt? Gulp? Broccoli? Mimosa? The heck are we talking about now?</p><p><em>-Task managers. But they are not cool anymore. We used them in like, 2015, then we used Makefiles, but now we wrap everything with Webpack.</em></p><p>Makefiles? I thought that was mostly used on C or C++ projects.</p><p><em>-Yeah, but apparently in the web we love making things complicated and then going back to the basics. We do that every year or so, just wait for it, we are going to do assembly in the web in a year or two.</em></p><p>Sigh. You mentioned something called Webpack?</p><p><em>-It’s another module manager for the browser while being kind of a task runner as well. It’s like a better version of Browserify.</em></p><p>Oh, Ok. Why is it better?</p><p><em>-Well, maybe not better, it’s just more opinionated on how your dependencies should be tied. Webpack allows you to use different module managers, and not only CommonJS ones, so for instance native ES6 supported modules.</em></p><p>I’m extremely confused by this whole CommonJS/ES6 thing.</p><p><em>-Everyone is, but you shouldn’t care anymore with SystemJS.</em></p><p>Jesus christ, another noun-js. Ok, and what is this SystemJS?</p><p><em>-Well, unlike Browserify and Webpack 1.x, SystemJS is a dynamic module loader that allows you to tie multiple modules in multiple files instead of bundling them in one big file.</em></p><p>Wait, but I thought we wanted to build our libraries in one big file and load that!</p><p><em>-Yes, but because HTTP/2 is coming now multiple HTTP requests are actually better.</em></p><p>Wait, so can’t we just add the three original libraries for React??</p><p><em>-Not really. I mean, you could add them as external scripts from a CDN, but you would still need to include Babel then.</em></p><p>Sigh. And that is bad right?</p><p><em>-Yes, you would be including the entire babel-core, and it wouldn’t be efficient for production. On production you need to perform a series of pre-tasks to get your project ready that make the ritual to summon Satan look like a boiled eggs recipe. You need to minify assets, uglify them, inline css above the fold, defer scripts, as well as-</em></p><p>I got it, I got it. So if you wouldn’t include the libraries directly in a CDN, how would you do it?</p><p><em>-I would transpile it from Typescript using a Webpack + SystemJS + Babel combo.</em></p><p>Typescript? I thought we were coding in JavaScript!</p><p><em>-Typescript IS JavaScript, or better put, a superset of JavaScript, more specifically JavaScript on version ES6. You know, that sixth version we talked about before?</em></p><p>I thought ES2016+ was already a superset of ES6! WHY we need now this thing called Typescript?</p><p><em>-Oh, because it allows us to use JavaScript as a typed language, and reduce run-time errors. It’s 2016, you should be adding some types to your JavaScript code.</em></p><p>And Typescript obviously does that.</p><p><em>-Flow as well, although it only checks for typing while Typescript is a superset of JavaScript which needs to be compiled.</em></p><p>Sigh… and Flow is?</p><p><em>-It’s a static type checker made by some guys at Facebook. They coded it in OCaml, because functional programming is awesome.</em></p><p>OCaml? Functional programming?</p><p><em>-It’s what the cool kids use nowadays man, you know, 2016? Functional programming? High order functions? Currying? Pure functions?</em></p><p>I have no idea what you just said.</p><p><em>-No one does at the beginning. Look, you just need to know that functional programming is better than OOP and that’s what we should be using in 2016.</em></p><p>Wait, I learned OOP in college, I thought that was good?</p><p><em>-So was Java before being bought by Oracle. I mean, OOP was good back in the days, and it still has its uses today, but now everyone is realising modifying states is equivalent to kicking babies, so now everyone is moving to immutable objects and functional programming. Haskell guys had been calling it for years, -and don’t get me started with the Elm guys- but luckily in the web now we have libraries like Ramda that allow us to use functional programming in plain JavaScript.</em></p><p>Are you just dropping names for the sake of it? What the hell is Ramnda?</p><p><em>-No. Ramda. Like Lambda. You know, that David Chambers’ library?</em></p><p>David who?</p><p><em>-David Chambers. Cool guy. Plays a mean Coup game. One of the contributors for Ramda. You should also check Erik Meijer if you are serious about learning functional programming.</em></p><p>And Erik Meijer is…?</p><p><em>-Functional programming guy as well. Awesome guy. He has a bunch of presentations where he trashes Agile while using this weird coloured shirt. You should also check some of the stuff from Tj, Jash Kenas, Sindre Sorhus, Paul Irish, Addy Osmani-</em></p><p>Ok. I’m going to stop you there. All that is good and fine, but I think all that is just so complicated and unnecessary for just fetching data and displaying it. I’m pretty sure I don’t need to know these people or learn all those things to create a table with dynamic data. Let’s get back to React. How can I fetch the data from the server with React?</p><p><em>-Well, you actually don’t fetch the data with React, you just display the data with React.</em></p><p>Oh, damn me. So what do you use to fetch the data?</p><p><em>-You use Fetch to fetch the data from the server.</em></p><p>I’m sorry? You use Fetch to fetch the data? Whoever is naming those things needs a thesaurus.</p><p><em>-I know right? Fetch it’s the name of the native implementation for performing XMLHttpRequests against a server.</em></p><p>Oh, so AJAX.</p><p><em>-AJAX is just the use of XMLHttpRequests. But sure. Fetch allows you to do AJAX based in promises, which then you can resolve to avoid the callback hell.</em></p><p>Callback hell?</p><p><em>-Yeah. Every time you perform an asynchronous request against the server, you need to wait for its response, which then makes you to add a function within a function, which is called the callback pyramid from hell.</em></p><p>Oh, Ok. And this promise thing solves it?</p><p><em>-Indeed. By manipulating your callbacks through promises, you can write easier to understand code, mock and test them, as well as perform simultaneous requests at once and wait until all of them are loaded.</em></p><p>And that can be done with Fetch?</p><p><em>-Yes, but only if your user uses an evergreen browser, otherwise you need to include a Fetch polyfill or use Request, Bluebird or Axios.</em></p><p>How many libraries do I need to know for god’s sake? How many are of them?</p><p><em>-It’s JavaScript. There has to be thousands of libraries that all do the same thing. We know libraries, in fact, we have the best libraries. Our libraries are huuuge, and sometimes we include pictures of Guy Fieri in them.</em></p><p>Did you just say Guy Fieri? Let’s get this over with. What these Bluebird, Request, Axios libraries do?</p><p><em>-They are libraries to perform XMLHttpRequests that return promises.</em></p><p>Didn’t jQuery’s AJAX method start to return promises as well?</p><p><em>-We don’t use the “J” word in 2016 anymore. Just use Fetch, and polyfill it when it’s not in a browser or use Bluebird, Request or Axios instead. Then manage the promise with await within an async function and boom, you have proper control flow.</em></p><p>It’s the third time you mention await but I have no idea what it is.</p><p><em>-Await allows you to block an asynchronous call, allowing you to have better control on when the data is being fetch and overall increasing code readability. It’s awesome, you just need to make sure you add the stage-3 preset in Babel, or use syntax-async-functions and transform-async-to-generator plugin.</em></p><p>This is insane.</p><p><em>-No, insane is the fact you need to precompile Typescript code and then transpile it with Babel to use await.</em></p><p>Wat? It’s not included in Typescript?</p><p><em>-It does in the next version, but as of version 1.7 it only targets ES6, so if you want to use await in the browser, first you need to compile your Typescript code targeting ES6 and then Babel that shit up to target ES5.</em></p><p>At this point I don’t know what to say.</p><p><em>-Look, it’s easy. Code everything in Typescript. All modules that use Fetch compile them to target ES6, transpile them with Babel on a stage-3 preset, and load them with SystemJS. If you don’t have Fetch, polyfill it, or use Bluebird, Request or Axios, and handle all your promises with await.</em></p><p>We have very different definitions of easy. So, with that ritual I finally fetched the data and now I can display it with React right?</p><p><em>-Is your application going to handle any state changes?</em></p><p>Err, I don’t think so. I just need to display the data.</p><p><em>-Oh, thank god. Otherwise I would had to explain you Flux, and implementations like Flummox, Alt, Fluxible. Although to be honest you should be using Redux.</em></p><p>I’m going to just fly over those names. Again, I just need to display data.</p><p><em>-Oh, if you are just displaying the data you didn’t need React to begin with. You would had been fine with a templating engine.</em></p><p>Are you kidding me? Do you think this is funny? Is that how you treat your loved ones?</p><p><em>-I was just explaining what you could use.</em></p><p>Stop. Just stop.</p><p><em>-I mean, even if it’s just using templating engine, I would still use a Typescript + SystemJS + Babel combo if I were you.</em></p><p><span style=\"background-color: transparent;\">I need to display data on a page, not perform Sub Zero’s original MK fatality.</span>Just tell me what templating engine to use and I’ll take it from there.</p><p><em>-There’s a lot, which one you are familiar with?</em></p><p>Ugh, can’t remember the name. It was a long time ago.</p><p><em>-jTemplates? jQote? PURE?</em></p><p>Err, doesn’t ring a bell. Another one?</p><p><em>-Transparency? JSRender? MarkupJS? KnockoutJS? That one had two-way binding.</em></p><p>Another one?</p><p><em>-PlatesJS? jQuery-tmpl? Handlebars? Some people still use it.</em></p><p>Maybe. Are there similar to that last one?</p><p><em>-Mustache, underscore? I think now even lodash has one to be honest, but those are kind of 2014.</em></p><p>Err.. maybe it was newer.</p><p><em>-Jade? DustJS?</em></p><p>No.</p><p><em>-DotJS? EJS?</em></p><p>No.</p><p><em>-Nunjucks? ECT?</em></p><p>No.</p><p><em>-Mah, no one likes Coffeescript syntax anyway. Jade?</em></p><p>No, you already said Jade.</p><p><em>-I meant Pug. I meant Jade. I mean, Jade is now Pug.</em></p><p>Sigh. No. Can’t remember. Which one would you use?</p><p><em>-Probably just ES6 native template strings.</em></p><p>Let me guess. And that requires ES6.</p><p><em>-Correct.</em></p><p>Which, depending on what browser I’m using needs Babel.</p><p><em>-Correct.</em></p><p>Which, if I want to include without adding the entire core library, I need to load it as a module from npm.</p><p><em>-Correct.</em></p><p>Which, requires Browserify, or Wepback, or most likely that other thing called SystemJS.</p><p><em>-Correct.</em></p><p>Which, unless it’s Webpack, ideally should be managed by a task runner.</p><p><em>-Correct.</em></p><p>But, since I should be using functional programming and typed languages I first need to pre-compile Typescript or add this Flow thingy.</p><p><em>-Correct.</em></p><p>And then send that to Babel if I want to use await.</p><p><em>-Correct.</em></p><p>So I can then use Fetch, promises, and control flow and all that magic.</p><p><em>-Just don’t forget to polyfill Fetch if it’s not supported, Safari still can’t handle it.</em></p><p>You know what. I think we are done here. Actually, I think I’m done. I’m done with the web, I’m done with JavaScript altogether.</p><p><em>-That’s fine, in a few years we all are going to be coding in Elm or WebAssembly.</em></p><p>I’m just going to move back to the backend. I just can’t handle these many changes and versions and editions and compilers and transpilers. The JavaScript community is insane if it thinks anyone can keep up with this.</p><p><em>-I hear you. You should try the Python community then.</em></p><p>Why?</p><p><em>-Ever heard of Python 3?</em></p>",
        "topic": "Web Development",
        "dateposted": "July 20, 2018",
        "id": 1
    },
    {
        "title": "JavaScript: What’s new in ECMAScript 2018 (ES2018)?",
        "image": "https://cdn-images-1.medium.com/max/800/1*2USQFRPHkmpnXI8Ty-OloA.png",
        "author": "Eric Dyer",
        "length": "6 mins",
        "previewcontent": "At the latest TC39 meeting the new features that will make it into the “ECMAScript® 2018 Language Specification” (ES2018) have been selected. All proposals that have reached stage-4 since the consolidation of ES2017 got selected. This post gives one a quick look at the features that made it into ES2018.",
        "content": "<p>At the latest TC39 meeting the new features that will make it into the&nbsp;<strong>“ECMAScript® 2018 Language Specification”</strong>&nbsp;(ES2018) have been selected. All proposals that have reached stage-4 since the consolidation of&nbsp;<a href=\"https://www.bram.us/2017/07/18/es2017-es8-language-features/\" target=\"_blank\" style=\"color: inherit;\">ES2017</a>&nbsp;got selected. This post gives one a quick look at the features that made it into ES2018.</p><p><br></p><h2><strong><em>❓ Stage-4&nbsp;</em></strong></h2><p><em>The TC39 Committee has&nbsp;</em><a href=\"https://tc39.github.io/process-document/\" target=\"_blank\" style=\"color: inherit;\"><em>a 5 stage process in place, ranging from stage-0 to stage-4</em></a><em>, by which it develops a new language feature. Stage-4 is the “Finished” phase. A list of Stage-4 proposals is&nbsp;</em><a href=\"https://github.com/tc39/proposals/blob/master/finished-proposals.md\" target=\"_blank\" style=\"color: inherit;\"><em>available on GitHub</em></a><em>.</em></p><p><br></p><h2>Object Rest/Spread Properties</h2><p>When destructuring an object,&nbsp;<a href=\"https://github.com/tc39/proposal-object-rest-spread\" target=\"_blank\" style=\"color: inherit;\">Object Rest Properties</a>&nbsp;allow you to collect the remaining properties of an object onto a new object. Think of it as a magic magnet attracting all leftovers.</p><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*B9x6JBbf8RvAbtNDecUhLQ.png\"></p><p><br></p><p><span style=\"color: rgba(0, 0, 0, 0.84); background-color: rgb(255, 255, 255);\">I use this one myself a lot, especially in a React (Native) context where I pluck certain values from&nbsp;</span><code style=\"color: rgba(0, 0, 0, 0.84); background-color: rgba(0, 0, 0, 0.05);\">this.props</code><span style=\"color: rgba(0, 0, 0, 0.84); background-color: rgb(255, 255, 255);\">&nbsp;for internal use, and then forward on all other props to the returned child component by spreading them again.</span></p><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*sLrYwcDW3G20NBPBiAIZFw.png\"></p><p><br></p><p><span style=\"color: rgba(0, 0, 0, 0.84); background-color: rgb(255, 255, 255);\">Additionally, if you turn your thinking-logic around a bit, Object Rest Properties provide you with a good way to&nbsp;</span><a href=\"https://www.bram.us/2018/01/10/javascript-removing-a-property-from-an-object-immutably-by-destructuring-it/\" target=\"_blank\" style=\"color: inherit; background-color: rgb(255, 255, 255);\">remove a property from an object in an immutable way</a><span style=\"color: rgba(0, 0, 0, 0.84); background-color: rgb(255, 255, 255);\">.</span></p><p><br></p><h2>Asynchronous Iteration</h2><p>With&nbsp;<a href=\"https://github.com/tc39/proposal-async-iteration\" target=\"_blank\" style=\"color: inherit;\">Asynchronous Iteration</a>&nbsp;we get asynchronous iterators and asynchronous iterables. Asynchronous iterators just like regular iterators, except their&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">next()</code>method returns a promise for a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">{ value, done }</code>&nbsp;pair. To consume asynchronous iterables, we can now use the&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">await</code>&nbsp;keyword with&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">for&nbsp;… of</code>loops.</p><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*C_7kNH0_rFeicKi9tObdZw.png\"></p><p><br></p><h2>Promise.prototype.finally()</h2><p><code style=\"color: inherit; background-color: rgb(240, 240, 240);\"><a href=\"https://github.com/tc39/proposal-promise-finally\" target=\"_blank\">Promise.prototype.finally()</a></code>&nbsp;finalizes the whole promises implementation, allowing you to register a callback to be invoked when a promise is settled (either fulfilled, or rejected).</p><p>A typical use case is to hide a spinner after a&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">fetch()</code>&nbsp;request: instead of duplicating the logic inside the last&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">.then()</code>&nbsp;and&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">.catch()</code>, one can now place it inside&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">.finally()</code></p><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*0zLMfcqCqEc5avr8d84xTQ.png\"></p><p><br></p><h2>RegExp related&nbsp;features</h2><p>In total 4&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">RegExp</code>&nbsp;related proposals made it into ES2018:</p><ul><li><code style=\"color: inherit; background-color: rgb(240, 240, 240);\"><a href=\"https://github.com/tc39/proposal-regexp-dotall-flag\" target=\"_blank\">s</a></code><a href=\"https://github.com/tc39/proposal-regexp-dotall-flag\" target=\"_blank\" style=\"color: inherit;\">&nbsp;(</a><code style=\"color: inherit; background-color: rgb(240, 240, 240);\"><a href=\"https://github.com/tc39/proposal-regexp-dotall-flag\" target=\"_blank\">dotAll</a></code><a href=\"https://github.com/tc39/proposal-regexp-dotall-flag\" target=\"_blank\" style=\"color: inherit;\">) flag for regular expressions</a></li><li><a href=\"https://github.com/tc39/proposal-regexp-named-groups\" target=\"_blank\" style=\"color: inherit;\">RegExp named capture groups</a></li><li><a href=\"https://github.com/tc39/proposal-regexp-lookbehind\" target=\"_blank\" style=\"color: inherit;\">RegExp Lookbehind Assertions</a></li><li><a href=\"https://github.com/tc39/proposal-regexp-unicode-property-escapes\" target=\"_blank\" style=\"color: inherit;\">RegExp Unicode Property Escapes</a></li></ul><p>I especially digg the “RegExp named capture groups” feature, as it improves readability:</p><p><br></p><p style=\"text-align: center;\"><img src=\"https://cdn-images-1.medium.com/max/800/1*GuYqQQ29T3eULUlUFLOR0g.png\"></p><p><br></p><p>More info on these features can be found at Mathias Bynens — one of the driving forces behind these proposals — his blog:&nbsp;<a href=\"https://mathiasbynens.be/notes/es-regexp-proposals\" target=\"_blank\" style=\"color: inherit;\">ECMAScript regular expressions are getting better!</a></p><p><br></p><h2>Other new&nbsp;Features</h2><p>To top it off&nbsp;<a href=\"https://github.com/tc39/proposal-template-literal-revision\" target=\"_blank\" style=\"color: inherit;\">a tweak to template literals</a>&nbsp;landed: when using tagged template literals the restriction on escape sequences are removed, thus allowing things like&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">xerxes</code>. Before this tweak an error would be thrown because&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">x</code>&nbsp;is the start of a hex escape with&nbsp;<code style=\"background-color: rgba(0, 0, 0, 0.05);\">erxes</code>&nbsp;not being a valid hex value.</p><p><br></p><p><strong><em>❓ Tagged template literal</em></strong></p><p><em>As per&nbsp;</em><a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\" target=\"_blank\" style=\"color: inherit;\"><em>MDN</em></a><em>: If there is an expression preceding the template literal, the template string is called a “tagged template literal”. In that case, the tag expression (usually a function) gets called with the processed template literal, which you can then manipulate before outputting.</em></p><p><br></p><h2>What now?</h2><p>Do note that not all these features are readily available in all browsers. Meaning that they’re Stage-4 means that they are finished, and that browser vendors should implement them&nbsp;<em>(some already have, others are in the process)</em>.</p><p>As for the future, I’m already looking forward at what’s next to come for JavaScript. Things like the&nbsp;<a href=\"https://www.bram.us/2017/01/30/javascript-null-propagation-operator/\" target=\"_blank\" style=\"color: inherit;\">Optional Chaining Operator</a>&nbsp;already get me very excited 😊</p><p><em>💻 The examples embedded in this post are part of a talk on ESNext named&nbsp;</em><strong><em>“What’s next for JavaScript?”</em></strong><em>, which I recently gave at a&nbsp;</em><a href=\"https://fronteers.nl/vereniging/commissies/belgie\" target=\"_blank\" style=\"color: inherit;\"><em>Fronteers België</em></a><em>meetup. I’m currently still in the process of preparing the slides for publication. I’m available for bringing this talk at your meetup/conference.</em></p><p><em>💡 This post&nbsp;</em><a href=\"https://www.bram.us/2018/01/30/whats-new-in-ecmascript2018/\" target=\"_blank\" style=\"color: inherit;\"><em>first appeared on my blog bram.us</em></a><em>. You can follow it via&nbsp;</em><a href=\"https://www.bram.us/feed/\" target=\"_blank\" style=\"color: inherit;\"><em>RSS</em></a><em>,&nbsp;</em><a href=\"https://www.twitter.com/bramusblog/\" target=\"_blank\" style=\"color: inherit;\"><em>Twitter</em></a><em>, and&nbsp;</em><a href=\"https://www.facebook.com/bramusblog\" target=\"_blank\" style=\"color: inherit;\"><em>Facebook</em></a><em>.</em></p>",
        "topic": "Programming",
        "dateposted": "July 19, 2018",
        "id": 0,
        "comments": [
            {
                "author": "Liam Dyer",
                "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
                "date": "July 19, 2018"
            },
            {
                "author": "Liam Dyer",
                "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
                "date": "July 19, 2018"
            },
            {
                "author": "Liam Dyer",
                "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.",
                "date": "July 19, 2018"
            }
        ]
    }
]